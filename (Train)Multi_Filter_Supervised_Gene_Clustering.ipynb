{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "(Train)Multi-Filter Supervised Gene Clustering.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOlDro+YBTCXNmShfdMvJnv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abhik-99/MFSGC/blob/master/(Train)Multi_Filter_Supervised_Gene_Clustering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KulkCG_T2428",
        "colab_type": "text"
      },
      "source": [
        "#(Train)Multi-filtering Supervised Gene Clustering.\n",
        "\n",
        "##Current Status:-\n",
        "Implementing Signal to Noise Ratio and Finalizing Details.\n",
        "_\n",
        "\n",
        "**Please Run the Dataset Splitter before running this Notebook.** Provide the \n",
        "*DATASET_train.csv* generated from the Dataset Splitter Notebook as the \n",
        "input to this Notebook at cell 4 as an upload."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5LLEvRnaEAi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "190715a7-ec27-41c2-b9fd-67977f64e4d6"
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "!pip install skfeature-chappers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: skfeature-chappers in /usr/local/lib/python3.6/dist-packages (1.0.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zpGfAP5tOQd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "from google.colab import files\n",
        "\n",
        "import json\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.feature_selection import chi2\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "\n",
        "from scipy.sparse import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wA04M9dZU_wY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Uncomment the line below if you have already used the dataset splitter else\n",
        "#use the original dataset\n",
        "#files.upload()\n",
        "\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "#2. Get the file\n",
        "downloaded = drive.CreateFile({'id':'1rO5EEvsoRJl2VVUB3ywKUd3kNiQ24oy3'}) # replace the id with id of file you want to access\n",
        "# For Leukemia- 1xcL-LT-E_gUqWLlqqeVJP1DVHHpiAGe_\n",
        "# For Colon - 1AUOto0GhTHW9fX52XSsf9kzYJS5ggv0G\n",
        "# for Prostate - 13Hf7uGbyJ1sWYo8KDRDL8scm-2Fs9_gd\n",
        "# For Lung- 1xuLzTWDGUbr4x3Pq1dnJj08MZqBB5I3U\n",
        "# for Rahc - 1oaOATE0D_f8MGPIMJOMXYVt0hBUWNCKV\n",
        "# for Raoa - 1d2vhPcT3I7ZFcAGOQYVLGB3Jx_vEMata\n",
        "# for Rbreast - 1Vf-h8zfVP_twMXivcJJtbWtjThShUHvn\n",
        "# for SRBCT - 1rO5EEvsoRJl2VVUB3ywKUd3kNiQ24oy3\n",
        "# for MLL - 1rS7x4x_DhrUzaBhrgKMQH3uIaLJdPgW3\n",
        "# for Breast - 1enhhyA4u2ByvOjnF81WoHflVNpXtfKpu\n",
        "downloaded.GetContentFile('data.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKx2JKDPaD8w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "8861fd59-bab0-4fdd-de3f-b5768e4cb426"
      },
      "source": [
        "#DATASET is the name of the dataset being used.\n",
        "DATASET=\"RAHC\"\n",
        "\n",
        "#NEIGHBOURS determines neighbours arg for ReliefF\n",
        "#for any dataset which contains any class sample \n",
        "# <10, make it less than 10. Eg of such dataset - SRBCT\n",
        "NEIGHBOURS = 3 \n",
        "\n",
        "#p is the number of top genes taken after sorting the filter scores\n",
        "p=800\n",
        "\n",
        "#uncomment the line below if using the dataset splitter else leave it commented \n",
        "#data_df = pd.read_csv(\"%s_train.csv\"%(DATASET),index_col=0)\n",
        "\n",
        "#uncomment the lines below if using the original dataset\n",
        "dataset = pd.read_table(\"data.txt\",header=None)\n",
        "data_df = dataset\n",
        "\n",
        "\n",
        "\n",
        "target = data_df.iloc[:,-1]\n",
        "feature = pd.DataFrame(data_df.iloc[:,:-1].values,dtype='float')\n",
        "m,n = feature.shape\n",
        "print(m,n)\n",
        "print(feature.head())\n",
        "print(\"Number of classes - \")\n",
        "classes = np.unique(target)\n",
        "for x in classes:\n",
        "  print(\"Class -\",x,\"Number of Sampples -\", len(np.where(target == x)[0]))\n",
        "\n",
        "feature_norm=pd.DataFrame(MinMaxScaler().fit_transform(feature))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "63 2308\n",
            "     0       1       2       3     ...    2304    2305    2306    2307\n",
            "0  3.2025  0.0681  1.0460  0.1243  ...  0.1521  0.3175  0.7240  0.2044\n",
            "1  1.6547  0.0710  1.0409  0.0520  ...  0.1932  0.4140  1.2708  0.2990\n",
            "2  3.2779  0.1160  0.8926  0.1014  ...  0.2156  0.3227  1.2142  0.2230\n",
            "3  1.0060  0.1906  0.4302  0.1035  ...  0.2758  0.3016  0.7235  0.0871\n",
            "4  2.7098  0.2367  0.3693  0.2190  ...  0.6412  0.3552  1.3928  0.2157\n",
            "\n",
            "[5 rows x 2308 columns]\n",
            "Number of classes - \n",
            "Class - 0.0 Number of Sampples - 23\n",
            "Class - 1.0 Number of Sampples - 8\n",
            "Class - 2.0 Number of Sampples - 12\n",
            "Class - 3.0 Number of Sampples - 20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akTt6mw0SHA9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#utility function\n",
        "def plot_feature(feature, target, c = ['r', 'b', 'g', 'y']):\n",
        "  import matplotlib.pyplot as plt\n",
        "  from matplotlib import style\n",
        "  import numpy as np\n",
        "  style.use('ggplot')\n",
        "  for idx, each in enumerate(np.unique(target)):\n",
        "    y = feature[np.where(target == each)[0]]\n",
        "    x = len(y)\n",
        "    plt.scatter(range(1, x+1), y, color = c[idx])\n",
        "    plt.plot(range(1, x+1), y, color = c[idx])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmPvz9Ke2tlb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#construction of ReliefF function\n",
        "\n",
        "\"\"\"\n",
        "Given a dataset, number of random instances to pick form the dataset and\n",
        "number of features to consider in each iteration (k), the function returns the weigths of the attributes\n",
        "of the dataset.\n",
        "These weigths can then be used as the final results out of the ReliefF algorithm\n",
        "\n",
        "Paper-\n",
        "\n",
        "Marko Robnik-ˇSikonja and Igor Kononenko. Theoretical and empirical analysis of relieff\n",
        "and rrelieff. Machine learning, 53(1-2):23–69, 2003.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "def hit_miss_calculator(target,instance,k = 10, hit = True, c = None, ):\n",
        "    m=len(target)\n",
        "    upper,lower=instance-1,instance+1\n",
        "    hits=[]\n",
        "    hit_flag=False\n",
        "    #finds k nearest hits\n",
        "    while(not hit_flag):\n",
        "      #print(upper,lower)\n",
        "      if(len(hits)>=k):\n",
        "        hit_flag = True\n",
        "        break\n",
        "      if upper < 0 and lower > m:\n",
        "        hit_flag = True\n",
        "        break\n",
        "      if(upper>=0):\n",
        "        if((target[upper]==target[instance]) and hit):\n",
        "          hits.append(upper)\n",
        "        elif((target[upper]!=target[instance]) and (not hit) and target[upper]==c):\n",
        "          hits.append(upper)\n",
        "        upper-=1          \n",
        "      if(lower<m):\n",
        "        if((target[lower]==target[instance]) and hit):\n",
        "          hits.append(lower)\n",
        "        elif((target[lower]!=target[instance]) and (not hit) and target[lower]==c):\n",
        "          hits.append(lower)\n",
        "        lower+=1\n",
        "    hits.sort()\n",
        "    return hits\n",
        "\n",
        "\n",
        "def reliefF(feature,target,k=10,repetitions=10, seed = 0):\n",
        "  np.random.seed(seed)\n",
        "  if len(feature.shape)>1:\n",
        "    m,n=feature.shape\n",
        "  else:\n",
        "    m=len(feature)\n",
        "    n=1\n",
        "  #print(m,n)\n",
        "  observations=list(range(m))\n",
        "  classes=np.unique(target)\n",
        "  weights=np.zeros(n)\n",
        "  d=(np.max(feature,axis=0)-np.min(feature,axis=0))*m*k\n",
        "\n",
        "  for i in range(repetitions):\n",
        "    instance=np.random.choice(observations,1)[0]\n",
        "    #print(\"Iteration\",i)\n",
        "    #print(instance)\n",
        "    hits=hit_miss_calculator(target,instance,k)\n",
        "    hit_class_prob=len(np.where(target==target[instance])[0])/m\n",
        "    #print(\"\\nHit Probability -\",hit_class_prob)\n",
        "    #print(\"Repetition\",i,\"Class\",target[instance],\"Hits -\",hits)\n",
        "\n",
        "    miss={}\n",
        "    miss_class_prob={}\n",
        "\n",
        "    for each_class in classes:\n",
        "      if(each_class != target[instance]):\n",
        "        miss[each_class]=hit_miss_calculator(target,instance,k,False,each_class)\n",
        "        class_prob=len(np.where(target==each_class)[0])/m\n",
        "        #print(each_class,class_prob)\n",
        "        miss_class_prob[each_class]=hit_class_prob/(1 - (class_prob))\n",
        "\n",
        "    #print(\"Repetition\",i,\"Miss-\",miss,\"Miss Class Probability -\",miss_class_prob)\n",
        "    \n",
        "    for hit in hits:\n",
        "      if len(feature.shape)>1:\n",
        "        weights-=np.subtract(feature.iloc[instance,:],feature.iloc[hit,:])/d\n",
        "      else:\n",
        "        weights-=np.subtract(feature.iloc[instance],feature.iloc[hit])/d\n",
        "    for each_class in miss:\n",
        "      for each_miss in miss[each_class]:\n",
        "        if len(feature.shape)>1:\n",
        "          weights+=(np.subtract(feature.iloc[instance,:],feature.iloc[each_miss,:])/d)*miss_class_prob[each_class]\n",
        "        else:\n",
        "          weights+=(np.subtract(feature.iloc[instance],feature.iloc[each_miss])/d)*miss_class_prob[each_class]\n",
        "    \n",
        "    \n",
        "  return weights.tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3Yq8gnsaRFw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#This function discretizes the given features into 3 categories\n",
        "def discretize_feature(feature):\n",
        "  \n",
        "  mean=np.mean(feature)\n",
        "  std=np.std(feature)\n",
        "  discretized=np.copy(feature)\n",
        "  \n",
        "  discretized[np.where(feature<(mean+std/2)) ,]=2#within 1/2 std div\n",
        "  discretized[np.where(feature>(mean-std/2)),]=2#within 1/2 std div\n",
        "  \n",
        "  discretized[np.where(feature>(mean+std/2)),]=0#greater than half\n",
        "  discretized[np.where(feature<(mean-std/2)),]=1#less than half\n",
        "  \n",
        "  return discretized\n",
        "\n",
        "def Xfreq(x):\n",
        "  xL={}\n",
        "  for e in x:\n",
        "    if e not in xL:\n",
        "      xL[e]=0\n",
        "    else:\n",
        "      xL[e]+=1\n",
        "  for e in xL:\n",
        "    xL[e]/=len(x)\n",
        "  return xL\n",
        "\n",
        "def XYfreq(x,y):\n",
        "  freq={}\n",
        "  \n",
        "  rX=np.unique(x)\n",
        "  rY=np.unique(y)\n",
        "      \n",
        "  for e in rX:\n",
        "    for f in rY:\n",
        "      freq[(e,f)]=round(len(np.where(y[np.where(x==e)[0]]==f)[0])/len(x),4)\n",
        "       \n",
        "  return freq\n",
        "\n",
        "def mutual_info(x,y):\n",
        "\n",
        "  xFreq=Xfreq(x)\n",
        "  yFreq=Xfreq(y)\n",
        "  joint=XYfreq(x,y)\n",
        "  \n",
        "  Xentropy=0\n",
        "  for e in xFreq:\n",
        "    if xFreq[e]!=0:\n",
        "      Xentropy-=xFreq[e]*np.log2(xFreq[e])\n",
        "      \n",
        "  Yentropy=0\n",
        "  for e in yFreq:\n",
        "    if yFreq[e]!=0:\n",
        "      Yentropy-=yFreq[e]*np.log2(yFreq[e])\n",
        "      \n",
        "  jentropy=0\n",
        "  for e in xFreq:\n",
        "    for f in yFreq:\n",
        "      if joint[(e,f)]!=0:\n",
        "        jentropy-=joint[(e,f)]*np.log2(joint[(e,f)])\n",
        "  \n",
        "  return (Xentropy+Yentropy-jentropy)\n",
        "\n",
        "def mutual_info_wrapper(features,target):\n",
        "\n",
        "  mi=np.array([])\n",
        "  for x in features:\n",
        "    discrete=discretize_feature(features[x])\n",
        "    mi=np.append(mi,mutual_info(discrete,target))\n",
        "  return np.array(mi)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2qREP_49tK_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "This cell is used for defining the method for calculating the t-scores\n",
        "\"\"\"\n",
        "\n",
        "def t_test(df,target):\n",
        "  \"\"\"\n",
        "  Input:\n",
        "  df= Dataframe of features (n_samples,n_features)\n",
        "  target= Pandas Series/1D Numpy Array containing the class labels (n_samples)\n",
        "  \n",
        "  Output:\n",
        "  scores= Descendingly Sorted array of features based on t-test \n",
        "  \"\"\"\n",
        "  import numpy as np\n",
        "  from scipy.stats import ttest_ind\n",
        "  scores=ttest_ind(df[:][target==0],df[:][target==1])[0] #Storing just the t-test scores and discarding the p-values from the result.\n",
        "  \n",
        "  # scores=np.argsort(scores,0)\n",
        "  return [scores] if type(scores) != np.ndarray else scores\n",
        "\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYCzFUqX9tjS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy.sparse import *\n",
        "def fisher_score(X, y):\n",
        "    import numpy as np\n",
        "    \n",
        "    from skfeature.utility.construct_W import construct_W\n",
        "    \"\"\"\n",
        "    This function implements the fisher score feature selection, steps are as follows:\n",
        "    1. Construct the affinity matrix W in fisher score way\n",
        "    2. For the r-th feature, we define fr = X(:,r), D = diag(W*ones), ones = [1,...,1]', L = D - W\n",
        "    3. Let fr_hat = fr - (fr'*D*ones)*ones/(ones'*D*ones)\n",
        "    4. Fisher score for the r-th feature is score = (fr_hat'*D*fr_hat)/(fr_hat'*L*fr_hat)-1\n",
        "\n",
        "    Input\n",
        "    -----\n",
        "    X: {numpy array}, shape (n_samples, n_features)\n",
        "        input data\n",
        "    y: {numpy array}, shape (n_samples,)\n",
        "        input class labels\n",
        "\n",
        "    Output\n",
        "    ------\n",
        "    score: {numpy array}, shape (n_features,)\n",
        "        fisher score for each feature\n",
        "\n",
        "    Reference\n",
        "    ---------\n",
        "    He, Xiaofei et al. \"Laplacian Score for Feature Selection.\" NIPS 2005.\n",
        "    Duda, Richard et al. \"Pattern classification.\" John Wiley & Sons, 2012.\n",
        "    \"\"\"\n",
        "\n",
        "    # Construct weight matrix W in a fisherScore way\n",
        "    kwargs = {\"neighbor_mode\": \"supervised\", \"fisher_score\": True, 'y': y}\n",
        "    W = construct_W(X, **kwargs)\n",
        "\n",
        "    # build the diagonal D matrix from affinity matrix W\n",
        "    D = np.array(W.sum(axis=1))\n",
        "    L = W\n",
        "    tmp = np.dot(np.transpose(D), X)\n",
        "    D = diags(np.transpose(D), [0])\n",
        "    Xt = np.transpose(X)\n",
        "    t1 = np.transpose(np.dot(Xt, D.todense()))\n",
        "    t2 = np.transpose(np.dot(Xt, L.todense()))\n",
        "    # compute the numerator of Lr\n",
        "    D_prime = np.sum(np.multiply(t1, X), 0) - np.multiply(tmp, tmp)/D.sum()\n",
        "    # compute the denominator of Lr\n",
        "    L_prime = np.sum(np.multiply(t2, X), 0) - np.multiply(tmp, tmp)/D.sum()\n",
        "    # avoid the denominator of Lr to be 0\n",
        "    D_prime[D_prime < 1e-12] = 10000\n",
        "    lap_score = 1 - np.array(np.multiply(L_prime, 1/D_prime))[0, :]\n",
        "\n",
        "    # compute fisher score from laplacian score, where fisher_score = 1/lap_score - 1\n",
        "    score = 1.0/lap_score - 1\n",
        "    return np.transpose(score)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tep2JSvp9s_9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#Pearson corelation\n",
        "def pearson_corr(feature,targetClass):\n",
        "  import numpy as np\n",
        "  coef=[np.abs(np.corrcoef(feature[i].values,targetClass)[0,1]) for i in feature.columns]\n",
        "  # range(feature.shape[1])\n",
        "  coef=[0 if np.isnan(i) else i for i in coef]\n",
        "  return coef\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6Jay5ItLozt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#gini_index "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6-JlRseRjYx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#signal to noise ratio\n",
        "#using weighted one-vs-all strategy for multi-class data\n",
        "def signaltonoise(feature, target, axis = 0, ddof = 0):\n",
        "  import numpy as np\n",
        "  classes = np.unique(target)\n",
        "  if len(feature.shape)<2:\n",
        "    feature = feature.reshape(-1,1)\n",
        "  row, _ = feature.shape\n",
        "  if len(classes) <= 2:\n",
        "    m = None\n",
        "    std = 0\n",
        "    for each in classes:\n",
        "      idx = np.where(target == each)[0]\n",
        "      #convinient way of doing m1-m2\n",
        "      if m is None:\n",
        "        m = feature.iloc[idx, :].mean(axis)\n",
        "      else:\n",
        "        m -= feature.iloc[idx, :].mean(axis)\n",
        "\n",
        "      #sd1+sd2\n",
        "      std += feature.iloc[idx, :].std(axis = axis, ddof = ddof)\n",
        "\n",
        "    return np.asanyarray(m/std)\n",
        "\n",
        "  else:\n",
        "    snr_scores = [] #for storing the weighted scores\n",
        "    #using the one vs all strategy for each class with\n",
        "    for each in classes:\n",
        "      idx = np.where(target == each)[0]\n",
        "      idxn = np.where(target != each)[0]\n",
        "      m = feature.iloc[idx, :].mean(axis) - feature.iloc[idxn, :].mean(axis)\n",
        "      std = feature.iloc[idx, :].std(axis = axis, ddof = ddof) + feature.iloc[idxn, :].std(axis = axis, ddof = ddof) \n",
        "      snr_scores.append((m/std) * len(idx)/row) #weighted snr\n",
        "\n",
        "    return np.asanyarray(snr_scores).sum(axis = axis)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3aJ2aexJCT3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#intentionally left blank!"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pOkMLeXaRCL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def feature_ranking(score):\n",
        "    \"\"\"\n",
        "    Rank features in descending order according to fisher score, the larger the fisher score, the more important the\n",
        "    feature is\n",
        "    \"\"\"\n",
        "    idx = np.argsort(score, 0)\n",
        "    return idx[::-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GB_5vrPKaRAh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "relief_score=reliefF(feature,target,NEIGHBOURS)\n",
        "\n",
        "mutual_inf=mutual_info_wrapper(feature,target)\n",
        "\n",
        "mms=MinMaxScaler()\n",
        "nfeature=mms.fit_transform(feature)\n",
        "chi_score,p_val=chi2(nfeature,target)\n",
        "\n",
        "p_corr = pearson_corr(feature, target)\n",
        "\n",
        "f_score = fisher_score(feature.values, target)\n",
        "\n",
        "tt_score = t_test(feature, target)\n",
        "\n",
        "snr_score = signaltonoise(feature, target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9cBmx7aCXUh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2QjsyTSaiYK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "aae20b60-495e-4982-bda7-22b93453fc03"
      },
      "source": [
        "#Can skip this cell\n",
        "print(\"Feature Scores (Unsorted)-\")\n",
        "print(\"ReliefF -\",relief_score[:5])\n",
        "print(\"Mutual Information -\", mutual_inf)\n",
        "print(\"Chi Square Test Score -\",chi_score)\n",
        "print(\"Pearson Corelation - \", p_corr)\n",
        "print(\"Fisher Score - \", f_score)\n",
        "print(\"T-Test Scores - \", tt_score)\n",
        "print(\"Signal to Noise Scores - \", snr_score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Feature Scores (Unsorted)-\n",
            "ReliefF - [0.050397709381417126, 0.015370894335704561, -0.022086670820492597, -0.022715501783129123, 0.003680098330294964]\n",
            "Mutual Information - [ 0.36215326  0.33373526  0.16595525 ...  0.02036548 -0.00082661\n",
            "  0.06555464]\n",
            "Chi Square Test Score - [4.23321274 8.00993606 2.82050613 ... 0.74141386 0.26034787 1.10973111]\n",
            "Pearson Corelation -  [0.026541896784921033, 0.5405803857131632, 0.23885562398046828, 0.12039690845168322, 0.08899644437478674, 0.0010208805091560104, 0.23948542930963157, 0.0664511656541523, 0.12246062071494108, 0.08573846303703508, 0.26198780104598535, 0.1531583159711869, 0.10020599113445554, 0.128676248051197, 0.07086681885124309, 0.07202866092115452, 0.028658546919926, 0.2758875278075834, 0.0638003958441658, 0.07295220400809659, 0.1378952755154495, 0.13086275183875515, 0.041418223322166145, 0.17040186504205568, 0.09533182260498088, 0.44776682681100355, 0.24037061777161972, 0.18689599652100916, 0.4851086140576573, 0.1362529644004312, 0.26740388818510896, 0.25332797764995274, 0.0943081405376732, 0.053650193421152126, 0.06697714400131928, 0.5371715059110296, 0.05453192681221789, 0.07518637203060434, 0.08019273079603825, 0.25378948102193805, 0.07250443406744342, 0.04260594588853249, 0.14646704662058732, 0.13120889311623396, 0.015816872044864438, 0.0170116412441467, 0.08081462732523381, 0.3324103747258781, 0.13993012230897878, 0.3295108507636897, 0.22852334451781928, 0.4699418979121612, 0.05854801829043008, 0.4026414622935943, 0.029114178491440827, 0.07646369674052961, 0.32248812148352846, 0.01780674695743916, 0.21110684548411118, 0.32367260210797205, 0.24883676514808184, 0.035245506476697004, 0.17139832527946497, 0.15373385039400958, 0.2820821915327891, 0.14721214186577364, 0.49919119810151924, 0.26518190724753943, 0.15042460353987924, 0.2481479649049814, 0.051543871510374206, 0.23606235558865524, 0.3160772603183599, 0.055893271479970766, 0.1995578072599339, 0.19751429501016646, 0.005484074896614123, 0.023431754786494254, 0.13541344949086787, 0.42393488155122594, 0.054679977382715954, 0.1785781969516107, 0.06272581082984933, 0.1941649658664414, 0.16838073327816566, 0.049624411515189, 0.05235659869971679, 0.06775685969842996, 0.3801652434165498, 0.29290794549766686, 0.09243167729546801, 0.13407431011151225, 0.32966504304965205, 0.08467178216006199, 0.16836392660804364, 0.023655583827157597, 0.34594353184089843, 0.007976725270060594, 0.037109659617253356, 0.1451463687954421, 0.040889271113205575, 0.07706070398508078, 0.04366266422577759, 0.1842249141414225, 0.06449258702493875, 0.2572746824807449, 0.18894511212402998, 0.051820430605059316, 0.364136624513, 0.1997645907326335, 0.18709487434832994, 0.136124539648217, 0.21120335029602558, 0.09010543845529556, 0.07659798882953357, 0.10530699805908474, 0.13048742496547316, 0.0937383821684118, 0.4310034184172005, 0.0780891756462726, 0.2862006010042818, 0.07928008821110899, 0.1715844388734998, 0.229088830867674, 0.0269628035021969, 0.11889328578926778, 0.05970870358329479, 0.018967744635988073, 0.5284571880283899, 0.2626182309332752, 0.3177524710885521, 0.2466214803386696, 0.06490412985507515, 0.2023524855283783, 0.0877007932055688, 0.060869395354572316, 0.26924140178627415, 0.22336057531401043, 0.3357352826508091, 0.03654883909697887, 0.42448581110218425, 0.2133489873441108, 0.061014160170744014, 0.1355681511578183, 0.25148388555383305, 0.2788824223045841, 0.0871826124052466, 0.2881356059441337, 0.11434824491106166, 0.056287601556385944, 0.4323853470888059, 0.26122303155688265, 0.4115375731253944, 0.037394588716051745, 0.1412638830671867, 0.3231748713332806, 0.00040074722725951445, 0.2722446043913895, 0.2577739201167606, 0.026439247067495335, 0.23824000268546666, 0.2528166993046293, 0.05055474241978647, 0.0678541568682869, 0.22633037152561003, 0.2238305191762477, 0.25177899020190647, 0.13693301689302745, 0.353776830831769, 0.0755733573608744, 0.09433650166220443, 0.08105937017610691, 0.06116541151639357, 0.5460968555317244, 0.009547705240099699, 0.0174936048997381, 0.07796347745031038, 0.1252285457089244, 0.008385922770302244, 0.21189562298947914, 0.01664254518631976, 0.3981320401421685, 0.07072553069890032, 0.1484148934737647, 0.0014288258113762614, 0.21765801518197478, 0.6524834917937152, 0.43687307672666525, 0.20191315917118385, 0.050319532765879714, 0.3958364082037534, 0.20949742307376384, 0.1603930804747128, 0.14001934689305748, 0.0032647080518434964, 0.13615031607479175, 0.059776636865777145, 0.156038021257593, 0.043899562864600845, 0.15646426069547809, 0.00544785213951007, 0.11536300337463558, 0.022678440114924075, 0.18173795874482362, 0.18309697558188912, 0.17928407001809743, 0.08285147720333814, 0.11118171378693374, 0.0300033702176935, 0.11467859647525584, 0.23021214881376328, 0.2421414102492527, 0.1680635682445526, 0.28188772706016113, 0.04777320053468368, 0.11111128839929998, 0.3193581224877322, 0.01742194843767995, 0.15946830356544733, 0.14283185719483982, 0.08724831062099961, 0.24782335139485687, 0.31230450172897406, 0.23169891859774847, 0.13068335894690855, 0.24918141201244906, 0.12453083681825615, 0.008401830071023462, 0.6329313204683783, 0.3608066894045812, 0.2167062313468003, 0.23841728172378554, 0.055678506409622755, 0.04124204081258521, 0.05347137960596737, 0.13664686240652318, 0.11543765762405774, 0.16445374686704686, 0.069961137153009, 0.26870569871482985, 0.2219694416512956, 0.3187532060908302, 0.13727380712508697, 0.39269141365024157, 0.1641185891088927, 0.6966091582161384, 0.04871352314177756, 0.14256365974488863, 0.06097616835589562, 0.14727391224051925, 0.5100058804542439, 0.2400211865160128, 0.30366556781079507, 0.18475986286704418, 0.2583576896398729, 0.25449653907600706, 0.3118945541522823, 0.4006021193563976, 0.015458639668027107, 0.10939553697417184, 0.07385052310923138, 0.017164471928202026, 0.1357535770552484, 0.3421363037391464, 0.2500958888538031, 0.0317960308633746, 0.04882346314681342, 0.39212340645503596, 0.06192439451414106, 0.15835281166511536, 0.053686332917347014, 0.07321647324373928, 0.04879940104064257, 0.030693045302197873, 0.23997636594060232, 0.19303751986987333, 0.13942471166914913, 0.05591740910515498, 0.1697298376794909, 0.21837726582032385, 0.1276332892647396, 0.07871551752878836, 0.10886403937451236, 0.03809076951313617, 0.1010147862629724, 0.10921334629838773, 0.325607518135964, 0.15581396981818837, 0.16634000941242844, 0.16555303265938956, 0.06906357859638929, 0.026735178433846568, 0.23110917262622332, 0.23914062864160526, 0.022448824683475938, 0.03333384361745504, 0.08232242718705449, 0.2077895980190888, 0.08638247077565335, 0.04825242808895711, 0.06487044395345246, 0.10092322186542477, 0.0068196099581588855, 0.0030646423381730814, 0.009552402439847812, 0.003951193786862143, 0.11882128027645593, 0.08283378637717001, 0.22674541270109128, 0.17369294085873896, 0.023619222985848436, 0.16989767187152396, 0.2729529970456898, 0.2923966749714447, 0.38676921641290246, 0.013689852974805128, 0.16784676297227408, 0.2537841697766575, 0.16020877647877116, 0.1457369533832088, 0.21622122854323061, 0.19563267418912456, 0.363719229291041, 0.06990503359752741, 0.10199757933908675, 0.08771499415920066, 0.027212179465717024, 0.1548101114357819, 0.04097557276715954, 0.06064789509740391, 0.24271574430356163, 0.17541095931094117, 0.15902257084794502, 0.04085268165634184, 0.2599361382870559, 0.5378810112947207, 0.12585338705635452, 0.42838078145126174, 0.25391126496484784, 0.36303697605527807, 0.1693706594136719, 0.14465401902412262, 0.16464571525311264, 0.061892240258119145, 0.1286292129787855, 0.009925537708936316, 0.058372188621886686, 0.5795305724704733, 0.12962914380544802, 0.07565056400699573, 0.04652458028643757, 0.14870012071975364, 0.25859668042651823, 0.4392935128629044, 0.15525227762683041, 0.014957611233972459, 0.009275777646238341, 0.16993235077655666, 0.14605383209327927, 0.26513043295206834, 0.38816157430785964, 0.2784344661671378, 0.014884503780423297, 0.07372350151574454, 0.30592695457246455, 0.11825999443442775, 0.10125055622454925, 0.500069002517102, 0.2872641733918714, 0.09693225501724834, 0.0014891017259791818, 0.45655369488798564, 0.5094022069350796, 0.14970822172275008, 0.2266792417543805, 0.2856977764277695, 0.02004849155476714, 0.3679099488839864, 0.011165603271645062, 0.26482229402261226, 0.35435523431405486, 0.029982939825979632, 0.2403929947679774, 0.3394875815328534, 0.11696871899889136, 0.003790333289977526, 0.18272170849822272, 0.39596151949215763, 0.1003000684869451, 0.2004064246336908, 0.20117362730471947, 0.011809253624687563, 0.174681375241338, 0.02139303012615878, 0.18083015246824258, 0.02025461329104748, 0.31889572308186775, 0.0076331497178440955, 0.26965481890601933, 0.19488333081759046, 0.2733341131696848, 0.10892426814105577, 0.25977405295381034, 0.3547166814499581, 0.009898494838972063, 0.19228839032159026, 0.2986151925114643, 0.29553065493773123, 0.4293526474177209, 0.2443227844670478, 0.05560132564225496, 0.08441938630265651, 0.1457608240657377, 0.32433159237701314, 0.4104951214938761, 0.1150547931430102, 0.10355469876480672, 0.0761916007197845, 0.45290961621663056, 0.31499255384201075, 0.2939726515780973, 0.15352182213951074, 0.28666169955687215, 0.09174202335620102, 0.11828980012160502, 0.21323915406578134, 0.004153916222354579, 0.012667738485719575, 0.20532589922317118, 0.4310524274558257, 0.09089641248218723, 0.1283373566184439, 0.510392701959725, 0.0021887201064795235, 0.10146199009741273, 0.3345073490051156, 0.37352045200805495, 0.026026767919830187, 0.07115242403843725, 0.283423622877086, 0.10469712338683024, 0.27800952204368623, 0.38693582838605983, 0.19233940879311534, 0.04502580960779279, 0.06576799762431063, 0.046947543496148304, 0.032294709462617324, 0.26381072812229456, 0.20450591277537716, 0.01475071026078253, 0.11025592550724049, 0.2786446617082052, 0.023475879213490612, 0.08503922189194306, 0.10414345965325304, 0.03886323945264636, 0.16884570691750256, 0.15553546602844429, 0.14199841610698663, 0.14450618882051794, 0.060322802894819234, 0.006096658690753923, 0.035338876176983676, 0.4201394254332185, 0.2307337822265535, 0.07646239150616577, 0.056926756590925685, 0.5816732505104856, 0.09722506568718461, 0.06666762143673258, 0.16519028135177094, 0.16588169893462987, 0.16855609776194333, 0.029425376720286688, 0.07814530750638629, 0.17267747162821204, 0.06846566360622915, 0.03549494712388789, 0.15133769639764375, 0.4335757563441905, 0.28360305588226137, 0.5010892496565914, 0.41187358143851044, 0.06583427451408354, 0.0540847727713385, 0.14609146717913318, 0.05688334267802069, 0.024906305741568976, 0.21340876013846935, 0.18983168387230367, 0.1573253060472524, 0.1454572480463854, 0.26396658488144975, 0.05960137356121649, 0.12768245553592672, 0.330567971342095, 0.0823022142370417, 0.0801804613376624, 0.3247760981300928, 0.36498880317106486, 0.005974015368216569, 0.3891324421776077, 0.35189046118587464, 0.025081875251873265, 0.02187339925990252, 0.1476491526255518, 0.055277240302055455, 0.6318956933276971, 0.28929258619267667, 0.16816624856046017, 0.14099506343274865, 0.08656466700351251, 0.1349005938191215, 0.1268747242535519, 0.04003159377991523, 0.13681875306026178, 0.34586602708303427, 0.17719767132071151, 0.05704405334483545, 0.1784368982583347, 0.20146267771348575, 0.369576126832027, 0.008349489326323862, 0.07103535815424979, 0.0980852536159811, 0.1244145218847838, 0.23996196661057298, 0.03902964636548582, 0.2355887299411938, 0.07444518936003702, 0.1619602246254424, 0.2619267027725959, 0.20775713706821944, 0.13241440114620434, 0.1413180964931061, 0.10860987035098423, 0.14230041920776032, 0.16756011278166424, 0.123226523864312, 0.07884291601997924, 0.2752602909052149, 0.25717059070269305, 0.09006388009933604, 0.6670115507088794, 0.2548755900886905, 0.23414204866638824, 0.04633104054966905, 0.20532166708937177, 0.02362641897828975, 0.16549814928800624, 0.12664356442919558, 0.25996505609960985, 0.4688823297888517, 0.011641828073038695, 0.09682234810440894, 0.13169638034700287, 0.5069856935825717, 0.034866211589716194, 0.16098595282027167, 0.0944611342314195, 0.06525793694864467, 0.06768037124901528, 0.10908333853742504, 0.13713152679744767, 0.5329468799238433, 0.03296750483273226, 0.24729961713503767, 0.1385751981652782, 0.2317718564135821, 0.07323960097811148, 0.20508629920599122, 0.31870413052438745, 0.20560709426998774, 0.2382130585844973, 0.104922689505205, 0.16213986837366007, 0.07728774479742152, 0.008114376162400315, 0.16940828808664865, 0.12042277909173302, 0.10183687287944268, 0.12743942194625107, 0.08818926557929602, 0.1391223650056491, 0.05931775959827269, 0.07482552475077317, 0.03986911715292424, 0.12214527221148432, 0.1965985406898046, 0.15838842460656047, 0.029669469392444935, 0.010205265680081486, 0.22989631302473332, 0.18716888861570666, 0.2637602639983994, 0.08287331341645093, 0.33767482068484184, 0.04751019626031677, 0.04112707927212061, 0.05958911780473367, 0.1325090565951286, 0.505796875367092, 0.4517748079905773, 0.09276383462241407, 0.017982774512027528, 0.35952299914106733, 0.3052807475194265, 0.12916345756153544, 0.06491646381700833, 0.13620485477389577, 0.36759316321312924, 0.11295458712050827, 0.3708782183120855, 0.37435518205007035, 0.1397347330581041, 0.023743738106765347, 0.13071983863356984, 0.0042913837933079724, 0.12751443311254593, 0.0589472243537838, 0.026555240322409662, 0.11718154929660506, 0.07288326100206141, 0.09806344685189351, 0.2481075516927417, 0.08294994060898368, 0.24057939763607908, 0.35508731744632854, 0.06876931875053238, 0.16197726102523077, 0.3208837131766608, 0.07614580187627323, 0.32934146280132615, 0.23883828410808466, 0.393199989091733, 0.303134401899429, 0.3998694061921658, 0.15212211555461205, 0.3121995365666285, 0.02059471011210827, 0.4087883015367933, 0.2264154925542995, 0.05965176022020602, 0.2653940978366822, 0.16596626696817451, 0.0362715183388, 0.03921546835873728, 0.07102254566009747, 0.3783154975022495, 0.07670948567107976, 0.19365448164478652, 0.04222372164134423, 0.0424810266072259, 0.513923945316747, 0.05112219322468357, 0.4496879523032312, 0.03522116384406156, 0.2216604186789617, 0.10254214774250102, 0.056779496542284605, 0.19705464452384452, 0.11810701439093708, 0.03515316590495319, 0.22722862676480393, 0.4176275940651346, 0.059916443055075284, 0.12370015283135868, 0.05682002880890276, 0.08372431959354003, 0.3012392285387542, 0.23346889911044683, 0.06571520737583082, 0.01434177165981186, 0.08910923605091532, 0.1434486942620575, 0.12063066374751956, 0.0862364697699321, 0.21082832108960664, 0.015165628865438914, 0.3547708458247311, 0.2483361507450076, 0.33219700310621403, 0.04182299737964766, 0.0031755359486842823, 0.019070904765460882, 0.038368890525135806, 0.36589070477495017, 0.3564784965297263, 0.023940412849830117, 0.18747285595410387, 0.18899325623326885, 0.08273369660920012, 0.34686510286596517, 0.045068995129197764, 0.4389481465113303, 0.35179519745043464, 0.15789369542624998, 0.06292401702700645, 0.15729667098124778, 0.15613973763081526, 0.4246839233340165, 0.02112654430138895, 0.042255776316812856, 0.011737726622422995, 0.32407591132232266, 0.17901358914812265, 0.21959798808253497, 0.18937076296385508, 0.11166017572727634, 0.02087685215967369, 0.03220014433621448, 0.32700000305200366, 0.3124034580908537, 0.4767941776757935, 0.027582721088614207, 0.15208566403501886, 0.09666134763431074, 0.09476875503473613, 0.049679107827252524, 0.15562115767066748, 0.008674859243709332, 0.07293568354716029, 0.24985551503190764, 0.14719715751406448, 0.09502384359215207, 0.08611766570589999, 0.25892751317519197, 0.30851364449839075, 0.16812868154855945, 0.22712604236654294, 0.0036305239088636645, 0.3548839347787414, 0.07825908739929034, 0.11578178207744673, 0.34652313898854087, 0.215684197568684, 0.05389034909595052, 0.07581622394774021, 0.1471534212818134, 0.27899430612855236, 0.20183927519115324, 0.15420230122229686, 0.5069930880207715, 0.005444446288157457, 0.4454437848759722, 0.45569138488628974, 0.14485520202758495, 0.37910071623309954, 0.12777949052771903, 0.24295223833014473, 0.19035679541752532, 0.34614366751275094, 0.17384891116456236, 0.11421823004159536, 0.3259060624418042, 0.17603714853127117, 0.22451090200490964, 0.06582477244349094, 0.36055770399332154, 0.4764376743270752, 0.3304059058346289, 0.04019335029005164, 0.056617696166108164, 0.2447970123882527, 0.30578028833642285, 0.00023764207206261934, 0.16253480052317196, 0.13325432872494414, 0.05839947052692085, 0.07687474611636663, 0.007294138758293121, 0.01048422836685412, 0.42110915751597744, 0.1870213662721166, 0.13557586265196372, 0.0632107064410728, 0.336115351550982, 0.47216953128938216, 0.12234801893355707, 0.16289513852234178, 0.03351440552797706, 0.1564898020803225, 0.1698713353803789, 0.01996674651709991, 0.16789440786510784, 0.015150267885727086, 0.2157208591664438, 0.3870917580915411, 0.08804334855836969, 0.09002071541605841, 0.20901785060585903, 0.07558755197801253, 0.2232019930526931, 0.3971199225742768, 0.12892293259113627, 0.18810680779856195, 0.12185697445764607, 0.173167408205341, 0.004593461033812225, 0.11994132947381986, 0.08884049421422588, 0.4567943835380796, 0.09269988514034094, 0.04886890419378255, 0.1962721522035629, 0.060111772756802705, 0.43876785397083184, 0.014740210150805138, 0.07265677766573667, 0.11689620555144734, 0.36725632725587465, 0.052091770570899566, 0.0791215703054207, 0.08460407212045143, 0.026792702141327653, 0.235553964620608, 0.06389011312214452, 0.18912886812273264, 0.4409369655333025, 0.14358398823620513, 0.15914285725007662, 0.33068401413838683, 0.25173830525648366, 0.30361579120928806, 0.09756799429919263, 0.06455591272785635, 0.5247835175643611, 0.059250166232508686, 0.024615082344683577, 0.0038850268396779103, 0.34394032048612877, 0.18329571725807853, 0.16034398983006573, 0.020531026837969788, 0.13856177163585542, 0.21568539684528867, 0.23809665524876325, 0.38263897430198107, 0.04232739276043099, 0.2491663138174481, 0.14459761764525803, 0.11275634614724385, 0.0401780016770446, 0.07663736052673625, 0.11909328480289881, 0.17734437155180335, 0.17883690374281533, 0.4006125420632043, 0.3727314599970852, 0.30799945773389387, 0.08096725954692466, 0.16001750315520213, 0.09217343473996625, 0.32871606600654546, 0.04945065117473868, 0.4462951218553696, 0.08983751200733399, 0.1792697473032148, 0.16029577341137166, 0.22590182878222462, 0.1767477629519116, 0.22159591506239765, 0.07812424867360296, 0.3340457499691643, 0.13773698931750664, 0.5610845163597998, 0.02346580102990678, 0.06819508920327211, 0.21329862612224218, 0.2009712683877072, 0.2341295874497148, 0.05612657536792363, 0.02583682931795732, 0.03297467219091302, 0.1899302732132345, 0.039707071726942975, 0.0011618889941569024, 0.0478476495668967, 0.23666048778375423, 0.03869775904712042, 0.2017258505225357, 0.3493176110276295, 0.2980447784787843, 0.10138272292707438, 0.06788255991099039, 0.19396673198377, 0.14079801202871467, 0.2408191662893204, 0.12888843157843757, 0.38475538148729616, 0.09585175562527568, 0.2316156920483573, 0.20748703268926486, 0.16163625597782086, 0.11182844504879925, 0.1508872487961881, 0.13402775235452666, 0.14086326459461218, 0.19087157895187504, 0.10218825869055993, 0.17610611961456624, 0.16405191285404025, 0.11471908995104681, 0.033708433257989175, 0.01868009572850192, 0.028343931196709544, 0.1378466075849287, 0.1561517226601247, 0.5868111796036962, 0.0655842515022205, 0.1293896697639292, 0.14062810377851218, 0.01775925674807898, 0.04958646076042062, 0.015076668155611178, 0.1259881914192504, 0.045662427171880376, 0.35429010382518134, 0.211202203107329, 0.03025109896705604, 0.01120768334166439, 0.017146638531333733, 0.2065298111818358, 0.021457978806253296, 0.13996569943857778, 0.08093335911595086, 0.09520620472504183, 0.14501937514333338, 0.00032433860274186713, 0.11076287461726785, 0.040581713074605806, 0.36400413056401526, 0.25754220139848366, 0.011309381658348631, 0.05824181586868556, 0.09181153497743226, 0.016233153403861486, 0.20478806564471613, 0.12419398913287331, 0.513020726000285, 0.1734811032353838, 0.16525746002859598, 0.09183517439013979, 0.1798165578709089, 0.13809605371812167, 0.31122932430590516, 0.2040956755131403, 0.07793360734540856, 0.1848789724800548, 0.4036644634284193, 0.10083635212723448, 0.21233507112127384, 0.0810009000401059, 0.061597327050145985, 0.06038414723008895, 0.08527859425917679, 0.03200744396422741, 0.028515723666813913, 0.07231950521233567, 0.17145973359740793, 0.20856358929102592, 0.07427584392623886, 0.38184324310598877, 0.2004504056304765, 0.027481671334300045, 0.13519062767979909, 0.22116106891916965, 0.28269223547870787, 0.3484151045667633, 0.5901373287724669, 0.16361223289369062, 0.3166851507086655, 0.28643655870192003, 0.09173242345486492, 0.3562915120332501, 0.09500705398847915, 0.14522339118757568, 0.5586921098955338, 0.26775237830531895, 0.01602849075401722, 0.2234203912915847, 0.31021532733853097, 0.048496912525938546, 0.2841052962020603, 0.10920970965977232, 0.04090776042366059, 0.02046564685963094, 0.12475237218862635, 0.19301241519082563, 0.24988380606940824, 0.17348508325428863, 0.15047154026834716, 0.06021067327165856, 0.0793470976941453, 0.20579493354549344, 0.026846270712416746, 0.07073830910146296, 0.2989676828268197, 0.2515506950685353, 0.14290634458915127, 0.21959481057200664, 0.6693985029904829, 0.11265150608169819, 0.230828270229407, 0.0951497819762068, 0.04929618271447574, 0.06859903161183917, 0.04547976325284768, 0.02634687746448689, 0.027196248887040756, 0.44811894141812864, 0.3423697301446506, 0.14921557420859574, 0.029696668967798392, 0.2320536158254298, 0.016519325294796345, 0.12668416365620036, 0.16067887341107961, 0.30709315286057487, 0.525303106216252, 0.40774375389248113, 0.4732701551176866, 0.06607884750980877, 0.16098767064944441, 0.061632623291614896, 0.12676631193690832, 0.30278216358768817, 0.031115897338430613, 0.47515142806162247, 0.16186203842807598, 0.20919925659618777, 0.2554355354182499, 0.2859041209977398, 0.1478332908438642, 0.12800562110791758, 0.27397629698769144, 0.3415177134801905, 0.4469109252133028, 0.0969104224016566, 0.1466128002791806, 0.12129664482734315, 0.016063092228284642, 0.030422623411554845, 0.018717550931836753, 0.30074636493004075, 0.12364912036948399, 0.026499988916934364, 0.4633540385982269, 0.13042857348009798, 0.16516594266940818, 0.1926205287729391, 0.028131189037440746, 0.15290719712806963, 0.49062464861090854, 0.11340326095849736, 0.0019177711925567609, 0.03361476753249687, 0.06999672872737077, 0.3072924720258598, 0.3003525711141062, 0.028206404337387834, 0.3982258258166806, 0.03836137303260136, 0.16724219567246779, 0.23128512215534935, 0.0007628573350238508, 0.20627600924875442, 0.34470137277605195, 0.44678582686419177, 0.20166576518877563, 0.03717947728107292, 0.1964636940998294, 0.6492076390341057, 0.08323659369546732, 0.22801899882839227, 0.06920431023283341, 0.3070658154251539, 0.12274341210748481, 0.010034104709169885, 0.02194113895201005, 0.058412026518734554, 0.2946100665316555, 0.20981191031044197, 0.07060570979884011, 0.11042613730394597, 0.21565383373622068, 0.23312256312572785, 0.47489755535364764, 0.3865314329014867, 0.0803749057594071, 0.15694101166487903, 0.6084072590636802, 0.37664682183041676, 0.3065226658572083, 0.007864305793084938, 0.052153638933983754, 0.22549746821710778, 0.07444044660603161, 0.31075777800720755, 0.1497410316648988, 0.05386161040420116, 0.0868999837123712, 0.2069439377756971, 0.48975339278445046, 0.26935437171475435, 0.2175018859905261, 0.08673468058572752, 0.1934581395272232, 0.6147479550613336, 0.1621460991207169, 0.4617785564120213, 0.21179930700902702, 0.0880761146030485, 0.039390503015784284, 0.023341406898474304, 0.12145676874880239, 0.17710324779089467, 0.0022495863040406117, 0.1940888928807621, 0.12246834084255534, 0.40745610247179453, 0.012329801559434054, 0.0497398696933731, 0.3464500077639774, 0.06263295195130474, 0.2729883361017998, 0.056207717538372774, 0.024242156494374167, 0.19042544359475708, 0.02308090473893241, 0.43979788377913887, 0.15753706621475697, 0.24463528285862718, 0.06404352166514748, 0.2556274926149193, 0.009243194397406123, 0.05169238786222216, 0.09159571972777701, 0.20013624001419472, 0.0006289443789293502, 0.041534238241313595, 0.3442845383637787, 0.00811361985538898, 0.032888061835561325, 0.09630243800327727, 0.21458697700698542, 0.0518019028732654, 0.3025980847955643, 0.1158858858120725, 0.36835309713423564, 0.10188616658419825, 0.3235292696673439, 0.17559868433248746, 0.3177860144756752, 0.18819073577225795, 0.2901484162844811, 0.1256822992532023, 0.32121698469212384, 0.3576678371337446, 0.006212292086596011, 0.3000783568342126, 0.12153833896092921, 0.2816631600281182, 0.12897532721544527, 0.04634694081024505, 0.07697131833999601, 0.12432782354569709, 0.1721502602684048, 0.08142365827707501, 0.2576933587983969, 0.08410802750641942, 0.10766357201514096, 0.017534783932736202, 0.2514988032705811, 0.044077401932618006, 0.15083917477439107, 0.04113577351973347, 0.16285470587440437, 0.0311516271782495, 0.11297809514634923, 0.1443640794291716, 0.09760932337110514, 0.05668647881440426, 0.12259425275718996, 0.06497800731470865, 0.30296793696181695, 0.0831539258510891, 0.237227954876429, 0.16419372717927333, 0.019945840865516484, 0.0792830217355101, 0.03544735814706187, 0.6824500301745791, 0.22068615200223954, 0.5232639446598211, 0.10636603457530576, 0.24562803534089805, 0.14210460786047435, 0.07844887228400825, 0.4184861346639597, 0.12131093266491678, 0.4659819752696612, 0.1567498221404646, 0.0783214311452315, 0.1018198345442937, 0.6478342017151887, 0.07117025158726592, 0.03354819422133201, 0.10477496439888154, 0.2554204819177615, 0.024145979368304846, 0.025898961934579627, 0.09762379658652204, 0.0465182464047864, 0.09913324804964858, 0.50674225956288, 0.11914413935409951, 0.1557142820334691, 0.40932938092935445, 0.3273447286529461, 0.2880320383940861, 0.04857641104807903, 0.04858021223105026, 0.2892602331879043, 0.33386699437192063, 0.3363874130881885, 0.39374302427557567, 0.0533035522867616, 0.0002569560916050183, 0.0819934751749101, 0.0961675169186683, 0.2622118982582139, 0.01681108475113963, 0.07360220761745044, 0.20079943656368174, 0.28243492556510763, 0.38376927362221047, 0.008236892682121313, 0.20512816025082298, 0.1961081832087842, 0.10995185957310345, 0.16873499210692278, 0.2350813911964866, 0.08944404086290943, 0.37828521112022606, 0.02358029246792645, 0.0011083649618803888, 0.1419689617816264, 0.15928483279377528, 0.18546926059672367, 0.36462615521861524, 0.1767495870755323, 0.3896359925198828, 0.29372985339637286, 0.1142235456524488, 0.04913543971325332, 0.35562419783979216, 0.018198133831910285, 0.23048955979432717, 0.11896386292380652, 0.3921197112550275, 0.2941073541620202, 0.2585407027839998, 0.03053431317364528, 0.15008710434363903, 0.1655834046730276, 0.1590845418046799, 0.01566574068808897, 0.07399857727909624, 0.1320659901683392, 0.026214516113419826, 0.11504065965089517, 0.24616827286144538, 0.3027280292795072, 0.08694702086682267, 0.08030876109090608, 0.007877195833996436, 0.07027937179314526, 0.10166855966671606, 0.002583881260588239, 0.05754031533637726, 0.3077525036842289, 0.17958343384475242, 0.2863047232954898, 0.45594482904924827, 0.43990637787356207, 0.0304734649571291, 0.017897793470341913, 0.17001930998622086, 0.15592133668884134, 0.4654800214676045, 0.14963387403572662, 0.2262457999341316, 0.04858538564978059, 0.30109293124930997, 0.345871443663808, 0.5110483191681139, 0.2053509914741753, 0.3332569396582418, 0.34313992497182755, 0.052007319292581185, 0.23062075010695762, 0.14245669167097036, 0.21866333931970094, 0.19530356333453347, 0.05102407793745341, 0.14311072549712867, 0.03657265806589575, 0.12328930358466102, 0.017666746172996683, 0.0029765229997923306, 0.0750478425816353, 0.06856096423676923, 0.1916491716818716, 0.1756121646698741, 0.37413292227404066, 0.12781098590182852, 0.6431088580885482, 0.283532602911875, 0.02563931700857683, 0.1260516141484418, 0.006682292608425722, 0.02235353010275303, 0.42538355530791744, 0.03875273999107982, 0.6083908406871469, 0.0882606952917167, 0.08108362511343557, 0.5654218069330117, 0.32923441127121383, 0.05782665768451954, 0.19995091420739614, 0.13852421283091015, 0.003366304765984854, 0.0640630331709752, 0.12724942805941905, 0.09144488224135225, 0.19744173008321844, 0.08455715687661461, 0.026975801561823838, 0.07676108495327505, 0.005816831439202137, 0.16010754659735582, 0.320178875383512, 0.08682155216580104, 0.2728569633614172, 0.02260448975388374, 0.2689201937270659, 0.0927623098743271, 0.10116238617685137, 0.16531038363772566, 0.4194099838044382, 0.16742230808162928, 0.13728816714693948, 0.03103556085360693, 0.3397185805347549, 0.052502324854981, 0.28288353141339323, 0.04244765530238305, 0.08350330055419257, 0.09472441177316075, 0.10054517241993464, 0.011757446508503265, 0.08780451528046745, 0.04071063523982551, 0.1292178100126714, 0.2590830353621441, 0.04208192105478246, 0.03444670215401112, 0.15347717726041393, 0.580115534100936, 0.14506587107126337, 0.07930725481094347, 0.025846699884073586, 0.24408549860780476, 0.08020044075298632, 0.38635490085603824, 0.2689336405866132, 0.04821981487897662, 0.2532688671301228, 0.21727761296356413, 0.10965862105437482, 0.1735161645726227, 0.014694186545978082, 0.06447958127093331, 0.13788196141765519, 0.0072658802624843335, 0.7383256815553316, 0.3906955568618413, 0.2745293026958981, 0.1317687670982004, 0.27454787140312437, 0.07255868941369555, 0.18772420806452741, 0.10843184861843125, 0.0422464466377895, 0.18636223828633067, 0.021901417034620396, 0.2579500960400927, 0.04189607603790621, 0.20142280016729294, 0.30684717288113267, 0.18185103282686316, 0.4322493672617185, 0.0031061245348438385, 0.026057133653795205, 0.056147739289244186, 0.16829420840488257, 0.04467119874065093, 0.11418552256394139, 0.0012357507492002495, 0.07625721906630083, 0.1043685145702638, 0.13356080942092236, 0.43797303110599406, 0.04816170683952448, 0.2720667195043837, 0.1465834600994144, 0.11130725360887883, 0.3607363908573276, 0.1380367481008165, 0.14555327479559665, 0.1705208189345089, 0.04800307500323372, 0.049395558140986964, 0.02730032304144189, 0.017646009413343954, 0.014386220569386505, 0.23335892437858033, 0.24330643248251563, 0.32272356963314774, 0.1606920535535036, 0.03590957488791642, 0.20404334958093417, 0.019692402746682956, 0.10352273426609983, 0.1208640474954994, 0.21602437218248177, 0.36707359355171393, 0.027303900126921715, 0.0403532368469222, 0.032335603865312125, 0.02220180339799454, 0.17373785490069113, 0.11395995972167741, 0.17633802875788257, 0.22083189298519482, 0.10412475321671186, 0.18378472143417932, 0.0055554865170951715, 0.23055676848644346, 0.1430730215410336, 0.2708346398539437, 0.03800461545235786, 0.07139056102005294, 0.04413733860132324, 0.09751708786107008, 0.17952286998594733, 0.0396939399230152, 0.2005074826597113, 0.07792060897722787, 0.07304838985317416, 0.288632324348662, 0.19554382067033874, 0.050333392723024326, 0.095732882494071, 0.2950023085392068, 0.20661281370394896, 0.10157757176079349, 0.1693864504445409, 0.17188693057588822, 0.24441068534773738, 0.2803215983800772, 0.06999656991780742, 0.010801700516150684, 0.06123248762292208, 0.030709753386041337, 0.27082856053303783, 0.10573049931101551, 0.32025986998660266, 0.08248055826744023, 0.18707533356219466, 0.1701598917692163, 0.18919562150390312, 0.26923557904131007, 0.30470531860551897, 0.2108067711379424, 0.36161383724137436, 0.35049906612693216, 0.08506494325816281, 0.02958648827745608, 0.44498003323518914, 0.33866407562323175, 0.018062465955052637, 0.4904991491378063, 0.34219128754510497, 0.36595378483258, 0.23615666963417573, 0.14687049085308318, 0.06673519500961542, 0.26154353035137756, 0.10358064654909611, 0.0434531608958966, 0.11300709848974762, 0.15869486865725613, 0.15737225297287238, 0.20315635724404218, 0.1290156247345513, 0.12395274207737599, 0.012016278946287382, 0.06307969177207703, 0.06761141389711915, 0.14322843736167484, 0.013309114577262658, 0.19373966076294474, 0.42697895981192574, 0.31650320908187196, 0.33795145772396673, 0.1491736047996599, 0.18566728832567694, 0.24026068048635574, 0.17608927192776572, 0.29078971534180875, 0.32416862711997196, 0.3103491710989987, 0.2806287574134183, 0.20970123849161987, 0.12538285336716687, 0.14858209436949382, 0.1397978275339723, 0.24795290965300457, 0.22477549998568983, 0.1753278145262738, 0.07160790653982133, 0.30515417217076696, 0.10116363815750833, 0.15111151891789826, 0.23981758981851298, 0.1501361792796957, 0.26481863666575123, 0.17347777573572015, 0.16084838632651427, 0.05058172344907258, 0.13871207638604516, 0.05478134322465542, 0.06266996693166922, 0.12931900416925876, 0.15950617921865692, 0.3193149122583805, 0.2367039395946806, 0.019963011448552097, 0.058174082041651656, 0.1912373984280072, 0.045860288312831995, 0.18537517848297808, 0.2733249469897398, 0.10225455791757813, 0.1283797509938058, 0.09738854285727909, 0.10431491957967715, 0.08162375104562974, 0.010552679318822372, 0.15965368422635254, 0.2013025880183417, 0.26444966112434487, 0.03724205137646926, 0.24590424888955142, 0.1822611745772091, 0.2111226572341393, 0.13320527326188733, 0.26530963677801855, 0.0356271976029594, 0.27833350843753457, 0.36906646219647343, 0.021246055815735587, 0.190617112116199, 0.10982172233088955, 0.07667183905200299, 0.02358917033631359, 0.04393634755685631, 0.16495849245204686, 0.06483430355852494, 0.07882291293476945, 0.27779623521839275, 0.12130102545594135, 0.10938838744830173, 0.26952334371149467, 0.15638364884271494, 0.00301221153350087, 0.08727111283206926, 0.22089889588548633, 0.25535116633926724, 0.3125292477851392, 0.35526302853647135, 0.3353691287692656, 0.44658783585576567, 0.007930651034242992, 0.19037354988455765, 0.11217005657859162, 0.23657899168812951, 0.01635930400011444, 0.29181094752248277, 0.0016977104069728435, 0.25747905223735174, 0.3097868737861616, 0.23301085032184723, 0.1816096634558096, 0.22793616957823307, 0.4551460030265183, 0.19242686428100783, 0.03231583370747714, 0.4251558550144988, 0.13796872272069205, 0.04587114322165191, 0.07688753914719944, 0.03676587936984684, 0.05700462218218462, 0.18729819044335402, 0.0010380329508752357, 0.19958296831702962, 0.1750563288348628, 0.18489721112583846, 0.11223081393980082, 0.06747974936337084, 0.390167737487107, 0.11183511093010319, 0.03804262974950082, 0.18185963986181947, 0.07286367313258654, 0.012514528302500098, 0.02998949511415154, 0.08529992581639771, 0.5419715938073852, 0.1242150466846769, 0.07365063007640452, 0.09641369500552412, 0.062332761205048215, 0.24249612430591505, 0.2713418030250965, 0.16373299254043955, 0.03786990995920358, 0.3475491072811921, 0.41097059888764526, 0.5988745645787646, 0.32120653822780004, 0.23092873318389878, 0.027865214069132338, 0.1335778887353921, 0.32843834437915914, 0.13348070702189369, 0.20819027996421777, 0.036520783557667254, 0.267057854102236, 0.37687654802388904, 0.004157181620281931, 0.018950620670074046, 0.0009896443765456122, 0.1101983190722651, 0.17711009848714318, 0.07987960336632681, 0.3509086080168139, 0.05390299875351244, 0.07482416148515558, 0.03053337634252069, 0.08475669797140063, 0.17984436608321452, 0.07098256812546416, 0.20852594363129304, 0.46687734503570616, 0.5183182185030939, 0.2793449597714303, 0.2804183324505002, 0.2269563944966277, 0.06137079182460029, 0.1997603550956914, 0.370165776834529, 0.11574412436165131, 0.06585627635393206, 0.11940146422261302, 0.0037870474954910856, 0.06499921478965187, 0.19509616283399484, 0.01667407868700292, 0.021597973982083594, 0.05781712891235706, 0.08755290264592397, 0.19153853975202104, 0.16156541482082512, 0.308509553424313, 0.2906692427472026, 0.0758215588453415, 0.005767109034598493, 0.03407548168673214, 0.15271719900189737, 0.19687695967473073, 0.381741956087827, 0.09087646157724119, 0.271035838221888, 0.03031833215889953, 0.26699112484390153, 0.14895343916963763, 0.07994973132612121, 0.14133848861269382, 0.18740445027921568, 0.6107819297276552, 0.19720711435208718, 0.5241278388843196, 0.35397406569698087, 0.17968727986028318, 0.04087158848882153, 0.1682239297612154, 0.14170465611450286, 0.4363010389403722, 0.1177567165932638, 0.3351565199099208, 0.03869956847606509, 0.03787263546165289, 0.01933830909562059, 0.13003378181600064, 0.02129213308918182, 0.1928624712130432, 0.5766071081229822, 0.055223468041798104, 0.04418098301088238, 0.30799417338455637, 0.3297016512465337, 0.2560276386867683, 0.3033279726748571, 0.016725828998911882, 0.041046251114226, 0.22219750007523245, 0.2749973308974643, 0.4329943224759205, 0.08446749149973162, 0.06065677348473889, 0.004275620675346478, 0.47484395279497, 0.2142528233574159, 0.2988875622084449, 0.1348885606121432, 0.10258796529785309, 0.03887406380013644, 0.10123421370842439, 0.06317340988430598, 0.21435926118294976, 0.14845209881901997, 0.2518954945354886, 0.11048616849738918, 0.21089561225156186, 0.36805210274925854, 0.06922044449818582, 0.16785671789852696, 0.16292135684367015, 0.064895735357823, 0.24084427741994552, 0.11434867455329906, 0.07730095767870461, 0.05693281049222504, 0.2775360827093642, 0.2894122444912073, 0.2165005353779311, 0.03813492375383065, 0.13587767448462687, 0.22779773775047713, 0.1326416041246612, 0.04856071139010192, 0.308015012250688, 0.05572622090348348, 0.16459308273367831, 0.31591376358062073, 0.509942163137071, 0.4206270951877671, 0.04068320445623958, 0.287869493055391, 0.18176595771916793, 0.0759381686905648, 0.1281494263706762, 0.23958191460237363, 0.33808387483274527, 0.12628443943488185, 0.2522101801020136, 0.2308243747518414, 0.08480462715768713, 0.19992469523836315, 0.10325430685816238, 0.057025904105465874, 0.01935684402649466, 0.002781656443872604, 0.04566321606811475, 0.0773480389611498, 0.05391935376708854, 0.006849482936354941, 0.001565717368498195, 0.15971971242947408, 0.25944238130508773, 0.09807830897184797, 0.14823601152896698, 0.6146528106943188, 0.2059927119748487, 0.20304315608482904, 0.12358951633227121, 0.23223795891620808, 0.05101624764454568, 0.12371616015701974, 0.34898801746132446, 0.21933281119644402, 0.03296392961858356, 0.032435168912878336, 0.1610247711210803, 0.004109678782308596, 0.13167667352333925, 0.11794104762954333, 0.143092645053384, 0.07250075668959971, 0.014400119796453207, 0.12399183416389684, 0.04893036235943589, 0.08462527475547742, 0.09347123848366355, 0.35616238239278636, 0.36841744788984887, 0.036258797525064064, 0.13551108808144297, 0.240861896363193, 0.18772565641597044, 0.197838936703384, 0.31827842738576806, 0.11220029808890537, 0.021904230015478542, 0.3026913714591077, 0.0027719721056751576, 0.09823895973084293, 0.22475274005507942, 0.002319337497387347, 0.05536444342021043, 0.3752575966384382, 0.1464233641652859, 0.006864899355500333, 0.07300047768795828, 0.2158059439983151, 0.14884542644810642, 0.3238024012581679, 0.10137949883341427, 0.07975712335806484, 0.2783664410661511, 0.2415409026126393, 0.19046404650251117, 0.22228506184818964, 0.4420132594416762, 0.11743455873525496, 0.23848934104961989, 0.301319864243137, 0.41169279713786394, 0.3039152370511429, 0.12919032446898354, 0.4947457388539047, 0.21688004827107504, 0.18615005988485597, 0.3416174423391023, 0.10181643913443389, 0.00047543391939610866, 0.05732579706301, 0.28270333335441117, 0.00033411843735989765, 0.023149124555145107, 0.45903734086659553, 0.05645429568575984, 0.13197830805497376, 0.26979591129737013, 0.050599050131405275, 0.033208859377248955, 0.25991605501428505, 0.2362719022715978, 0.11706193281171251, 0.4002589969186715, 0.022539188314220377, 0.3131485145072822, 0.31617845205063255, 0.2793799800697589, 0.09959105202053102, 0.3857013318007237, 0.03302713031457755, 0.1422660952185774, 0.030773658186252006, 0.13532082544152876, 0.1490874191655226, 0.6355093308274106, 0.04596768460238594, 0.14936599721118102, 0.2541535513177946, 0.0702370965829148, 0.12078853371632749, 0.11840098105618065, 0.10725949520291893, 0.5634930342366976, 0.012642256787337764, 0.021438712486894808, 0.21749216765894852, 0.16153039857400514, 0.37017203656748887, 0.17466560603089437, 0.08780675649030686, 0.16029917216331788, 0.036046428064850755, 0.291583350456533, 0.04379717235653886, 0.2839750777235983, 0.15396516302220145, 0.291191156922136, 0.6069328481363955, 0.08579658223430721, 0.25418671892937517, 0.43932559827578593, 0.18121065954689905, 0.11524173138491013, 0.5422211494239356, 0.04330117660301997, 0.004904677454031941, 0.3788844183076443, 0.13056662005530428, 0.015394691698154364, 0.19773527026305113, 0.4277128904799972, 0.21564725783166122, 0.13440637077754222, 0.006113071240617133, 0.16010982395466763, 0.378725068658658, 0.21112156106569074, 0.0643820528771448, 0.09886904334007121, 0.11793591139999815, 0.17564223948067365, 0.16517729021390862, 0.05574463244795751, 0.4314963098184262, 0.23993709476085914, 0.0864463273935668, 0.17211391085901148, 0.06703864051211106, 0.35891864560699444, 0.1252131192887097, 0.21745641647836736, 0.3635529295282338, 0.05364679749488858, 0.3472369421181315, 0.05887574384871867, 0.011412492403262147, 0.008600933836949822, 0.25375038215834944, 0.12080764730770283, 0.2031144679023566, 0.7130149931564993, 0.6900604619924574, 0.2718969485880623, 0.30690437240480717, 0.1153546922168358, 0.17138131945032709, 0.172406602643562, 0.1520149269133582, 0.297853576358333, 0.06284390315931784, 0.27812193198055063, 0.0999227974161145, 0.10540199022310752, 0.31789743467572257, 0.270589323307538, 0.12018665816939057, 0.021495596781620704, 0.2123545315837145, 0.1347575013630445, 0.21997288995300962, 0.12505530506868923, 0.10047959160072623, 0.2369214979737429, 0.03102093236476516, 0.046712493401691514, 0.45950014107368303, 0.5464331480782706, 0.06477537239878715, 0.0014939877736226542, 0.32496516674334225, 0.1579265516608412, 0.16802320899858295, 0.03840186866980608, 0.06381985423353766, 0.03551544107362429, 0.15439644483491796, 0.224042104639536, 0.43523230708308674, 0.013669378367942363, 0.08683677592355733, 0.4888392334270823, 0.36074762399259436, 0.019574409447334063, 0.21429883702859487, 0.30887247517248567, 0.06987864114520274, 0.27993111301478985, 0.19902343627787136, 0.22690806208012235, 0.0924543327027244, 0.1949577481421694, 0.28105294504662937, 0.17681050019724198, 0.16115373280992393, 0.31454535816977985, 0.4190003840097349, 0.09723177504339196, 0.08547553782670396, 0.25297450808756056, 0.19156542493628045, 0.06087442381657472, 0.26001988902011325, 0.29985693417336867, 0.2525812745322704, 0.05400854694020919, 0.2866193389607679, 0.3583126921883546, 0.3767254844118059, 0.15258410021059515, 0.12268081717978731, 0.08373756126545984, 0.1946605543825835, 0.020092700166876636, 0.186267282306003, 0.06963073481039422, 0.07385311620247713, 0.07430891478060618, 0.08337718966243854, 0.1799588544906501, 0.20969603432428985, 0.2132148159543114, 0.05715721116965454, 0.1481179966613435, 0.41982267298229275, 0.15230031810294242, 0.26054731269620796, 0.08934641604337519, 0.19133781818212323, 0.1095035216074018, 0.08087502477118429, 0.07976658705495566, 0.09101891240896051, 0.618679324136188, 0.47269757019268305, 0.18334698275161135, 0.4402197172351645, 0.6395848501082869, 0.005945890789127648, 0.00744861413505442, 0.04178901041257319, 0.00882247646528485, 0.25203867955881154, 0.03398647826031784, 0.03987124772228797, 0.1800299669858607, 0.00033260128141672567, 0.2779148175591309, 0.3081683970092736, 0.13769201031960737, 0.21440230371861327, 0.17375926213022824, 0.14752882224970232, 0.010557545039254733, 0.08294090171697414, 0.26135485112363754, 0.19802280489686516, 0.37432287273822334, 0.12903662622276324, 0.12649290286872233, 0.3143723640669222, 0.05283906013940808, 0.2728623773030527, 0.005149470939236006, 0.1462750149076149, 0.036540921713608024, 0.06621414489715692, 0.11949690732193037, 0.308137001345493, 0.12674012096194437, 0.4414157187171379, 0.10368116993240901, 0.05265775553042088, 0.36937674927657704, 0.2012810669687156, 0.3978855500614189, 0.1611858460112559, 0.01600565866694325, 0.21311982976206292, 0.24115151929230036, 0.4218681698028534, 0.2627002525824149, 0.002027695525663562, 0.26837732513048057, 0.007492510298975883, 0.11947270117533773, 0.4048978582929121, 0.3486578250595152, 0.12628937965480272, 0.33617416227994146, 0.07527531432369236, 0.15875743853916946, 0.30724436368722985, 0.3819897989697042, 0.10566188039381591, 0.1968752956562442, 0.027289647446421497, 0.047604617129596107, 0.1867449416691431, 0.14371867552622028, 0.1796780636163861, 0.35310816432024567, 0.22883233782817944, 0.014862449651493803, 0.5680416693714144, 0.07758270254207929, 0.12563731739699568, 0.30603642052898966, 0.06981229256250733, 0.12721266859079128, 0.2607977423416783, 0.14595978842868168, 0.19434557251928103, 0.15876582540635123, 0.05166937462497395, 0.11939957036307564, 0.012048475430995634, 0.03751431950865408, 0.04864206456766063, 0.17441061157566834, 0.04996387006219988, 0.12115100916389217, 0.15465768246072553, 0.08754743570500838, 0.044680750162060794, 0.14454942845899307, 0.21339124738358928, 0.14707800095383278, 0.24760229618063886, 0.154569739268472, 0.3397989645735829, 0.3147941456406367, 0.24887740359493093, 0.5040323363602399, 0.04776106902109358, 0.2515502242681404, 0.2742609664631385, 0.05246846551664591, 0.3737364361534671, 0.010904837549449455, 0.23661671103398907, 0.1955508692013307, 0.3139196696093956, 0.10152159063932313, 0.07796053527555322, 0.2550047713729923, 0.47007530291007943, 0.2647952463130732, 0.0006223196848474025, 0.0017904554786509815, 0.10834887205661842, 0.20000388430660757, 0.0915874254314228, 0.013374060043791587, 0.25172084671983364, 0.3111305821025839, 0.033330747174543866, 0.2800852677774966, 0.11873588107243528, 0.44229036445818076, 0.06997201952511235, 0.06501763647394332, 0.1934159246424042, 0.21173198763559983, 0.20416551047160214, 0.07263771597721333, 0.017105747329231757, 0.07468669080206879, 0.22492742743240338, 0.04600977982824221, 0.2859171091798599, 0.13192262868280752, 0.019427098883230843, 0.10037401994815796, 0.10767385758299776, 0.20415065621339862, 0.05022871032685032, 0.23617066859234978, 0.17770505327721903, 0.09923282004010843, 0.19725372806864447, 0.11539409647447244, 0.18615532828015324, 0.05113314099619836, 0.1317129354306216, 0.14140975850539242, 0.04253911249095674, 0.2505981478544138, 0.10215907044704517, 0.1480472408468552, 0.2402251533180292, 0.07603431586605375, 0.06671851587771217, 0.14574768988953388, 0.2067931816783096, 0.04921985642635468, 0.35381972562269187, 0.062090007226244213, 0.03439082471661071, 0.1471674626156424, 0.16764334432088823, 0.0055426758136403855, 0.19365292053211533, 0.14443543045611865, 0.10359913352182429, 0.024602487156093762, 0.009584753277557236, 0.11270604124377455, 0.29691546273115266, 0.14343707569890188, 0.2815248583824228, 0.06111706375503774, 0.10172968462803876, 0.00426145544876137, 0.44553387469367745, 0.15175668839280118, 0.11495719162019602, 0.4122344821790416, 0.050833518218676994, 0.04431059290660608, 0.20950799299457445, 0.24663500916773318, 0.38386691584995003, 0.2586811521801099, 0.11394824758501233, 0.15984432904086993, 0.025839270763508924, 0.19677491380975387, 0.02885139409495284, 0.08751286627212024, 0.053499678486985384, 0.0058836853349715605, 0.052507783874791734, 0.12735967880896149, 0.5054976170562283, 0.21166369946326416, 0.010115635581299137, 0.13252566561662074, 0.05514855594041399, 0.08303657072917899, 0.45932197207556674, 0.03620588646070618, 0.1402187587863439, 0.08851320811612365, 0.024172824132502727, 0.19085873634230288, 0.1680908036207805, 0.044803854885562606, 0.27617505027042916, 0.3033867014068747, 0.13947632176239, 0.0903869831562617, 0.11265439064390781, 0.05968618264632407, 0.01632148522220234, 0.03222202387878238, 0.14520080909146943, 0.2312751327184085, 0.05140241597674188, 0.15186645078968117, 0.2810280374910218, 0.03463684182430113, 0.4558683770746753, 0.12155977424539527, 0.1310097641151645, 0.3729546173965969, 0.15503091163129254, 0.009751559456487632, 0.06350235878084033, 0.21080319559372482, 0.027339792408346403, 0.013008368364485531, 0.3086652976089938, 0.08409028970245178, 0.026531920422484805, 0.12422781437856174, 0.2781394837762476, 0.24612636676452046, 0.14292421101157518, 0.07861092255237469, 0.20546088842413074, 0.3428118326228037, 0.43743252294926915, 0.04283349643233301, 0.060233901787420815, 0.19289880456384764, 0.06424213475695201, 0.4211407448155303, 0.2028961962878594, 0.30319317747181707, 0.3175932264291065, 0.05623405649113247, 0.3378837143550426, 0.21428023208949548, 0.047062228790851424, 0.26274080675379324]\n",
            "Fisher Score -  [0.76509222 0.76345616 0.36776747 ... 0.10885736 0.03800741 0.15417942]\n",
            "T-Test Scores -  [ 5.34943282  2.39501128 -0.42965956 ...  1.27240697 -0.73247244\n",
            "  1.3102961 ]\n",
            "Signal to Noise Scores -  [-0.0576154  -0.03067477 -0.07381643 ... -0.01466343 -0.00834573\n",
            "  0.00602035]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDxNwckauNsD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#The Features are sorted as per their scores\n",
        "sorted_relief = feature_ranking(relief_score)[:p]\n",
        "sorted_mi = feature_ranking(mutual_inf)[:p]\n",
        "sorted_chi = feature_ranking(chi_score)[:p]\n",
        "sorted_pc = feature_ranking(p_corr)[:p]\n",
        "sorted_fs = feature_ranking(f_score)[:p]\n",
        "sorted_tt = feature_ranking(tt_score)[:p]\n",
        "sorted_snr = feature_ranking(snr_score)[:p]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UqKYU7wEQ8c6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3027e441-8d4d-45b7-842d-7175fadafbd8"
      },
      "source": [
        "#Can Skip this Cell\n",
        "\n",
        "print(\"Features after sorting -\")\n",
        "print(\"\\nSorted MI -\",sorted_mi)\n",
        "print(\"\\nSorted Relief -\",sorted_relief)\n",
        "print(\"\\nSorted Chi -\",sorted_chi)\n",
        "print(\"\\nSorted Pearson Corr -\",sorted_pc)\n",
        "print(\"\\nSorted Fisher Score -\",sorted_fs)\n",
        "print(\"\\nSorted T-test -\",sorted_tt)\n",
        "print(\"\\nSorted SNR - \", sorted_snr)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Features after sorting -\n",
            "\n",
            "Sorted MI - [1388  544 1002  152 1954 2143 1193 1644  186  245  845  334 1206  508\n",
            " 2045 1953 2049 1661  741 1318 1707 1931 2161  950 1326  975  228 1065\n",
            "  173  187 2158  835  254 1895 1979  106  335  866 2252 1612 1352  757\n",
            " 1893 1705 1887  107 2198 1798 1157  367  878  909 1329 1910 1083 1054\n",
            "  337  480  379  436 1883 1722 2202 1374 1488 1967 2126  936  602 1654\n",
            " 1829  978  822  416  429 1999  606  243 1029  760  165 2247 1092 1605\n",
            "  421 1923  255 1197 1600 1771  482 1485 1433 1872 1104  250  235 1913\n",
            "  181  718 1769  589  798   66 2229 1861 1262  574 1729 1386  122  229\n",
            " 1066 1633 1914 2145 2031  565  656 1158 2185    0 1195 1111  752 1820\n",
            " 2257 1875 2302 1020 1109  799 1492 1294 1737 2275 1478 1578 2095   73\n",
            " 2156  551 1073 1141  818 1819  234 1672  206  476 1948  168 1523  399\n",
            "  596 1941 1699  432  850  468  377    1  714 1881 1755 1371  150 2116\n",
            " 1089 1300 1884  364 1385  347  155 1993  308  819  997  874  782   88\n",
            " 1480 1749 2021 1607  246  164 1886 1347 2239  257 1186 1759  778 1496\n",
            "  605 1370 1413 1625  811 1234 2216  841  276 1961 1081 1856 1767 1803\n",
            "  443 1090  521 1278 1908 2046  597  216   84  372 1115 1794 2278  706\n",
            " 1626  247 1726  844 1077  325 1716 1282 2048 1035  280  500  531  414\n",
            " 2197  503  730 1656 1576  748 1544 1021  654  423  940  498 1314 2082\n",
            " 1830 1915  649 1061  611 1016 2157 2227 1087  353  441  969 1764 2015\n",
            "   35  666  736  204   75  557  572 1006   83  848 1178  932  670 1990\n",
            "  836 1376  324  145 1734 1976  631 2226 1031 1858  864 1220 1155 1660\n",
            " 1209  584  638  955  448 1750 1859   94   32 1421 1210  800   28 1075\n",
            "  905 1620 1369 1495 1810 1775 1991 1670   24  688 1783 1393  570  853\n",
            "  807 1521 1400  671 1012  802 1048  890 1007 1866  840  694  644 2234\n",
            " 2199 1281  191 2150 2129 1757 1623 2007 1392  136 1802 1236  293  588\n",
            "   53  779 2080  123 1701 1698 1290 1212 2131 1828  278  743  499 1973\n",
            " 2115 1517   26 1552 1098 1346 1005  118 1280 1452 1267 1593  970 1297\n",
            "  520  687 1119 1245   89 1291 2297 1391 1010 2113 1916  830  128 1022\n",
            " 1732  911  542 1113 1032 1150 1253 1774  665  880 1251 1956 2300 2079\n",
            " 2246 1807 1001   36  509   16  144  129   80 1216 1535  314 1889  417\n",
            "  987 1350 1855 1534 1334  263 1760 2274 1202  839  493  838 1323  241\n",
            " 2209  532 1938 2017  553  543 1166  517  755  371 1781 1833  275 1394\n",
            " 1516   51  449 1748 2272 1372 1733 1928 1821  745 1527  794 2018  849\n",
            " 1637 1575  704  646  256 1697 1237 1004 1125 1730  981 2165 2262  761\n",
            " 1207  773  383 1745 1338  375 1417 1315 2240 2014  453 1458 2039 1015\n",
            "  795 2212 1763  601   76 2208  628 1922  982 1966  593  387  418  921\n",
            "  422  265 1706 1332 1664  489   31 2167   49 1520  412 1838  115  852\n",
            "  141  158  473  637 1663  287  837 1214 1809  876  797  948 1977 1219\n",
            "  140 1249 1963  454 2104 1275 1911  900  309 2166 1223 2041 1818 1703\n",
            " 1271 1426  138 2169 1863 1483 1885 2006 1185 1442 1142 1685 1677 1880\n",
            "  994  290  357 1715  964 1345  974  259 1121 1627  813  526 1647  787\n",
            "   14    8  668 1268  660  971  568  788 1069 1761 2074 2171 1580   93\n",
            " 1265 1822 1867 1658 2091 1072  693 1753  681  566 2092  664 1404 1696\n",
            " 2038 2087 2284 2098  750 1506 1709 1071  744 1796 1436 1457 1740 1648\n",
            " 1285 1741 1203 1827  912  351  267 2100 1852 1368 2294 1415 2288  727\n",
            "  883 2096 1084  545 1272 1019 1173  444  796 1395  642 1813 1422  902\n",
            " 1955 2135 2249   70 1646  460 1175 2225 1746 1692 1464 1384  956 1841\n",
            "  313  871 2151 1508  724  829 1024 1700 1564 1547 1601  212 1950  522\n",
            "   33 1509  126 1874  732 1609 1132 1832 1200 1459  363 1412 1530  352\n",
            " 1360 1790 1044  870  824  184  492  707    2 1154 1159  846 1432  170\n",
            "  258  120 1156 1930 1847 2149 1708  735 2024  858 1978 1772  516 1018\n",
            " 1606 1131 1669 2206 1124 1586 1112 1909 1959 2052 1383  285  435 1182\n",
            " 1244 1493  405   38 2174 1713 1301 1311  311  151 1273 1257  193 1088\n",
            "  674  251  885 1127  189  471  408 1997  930  703   23 2148 1467  765\n",
            " 1008  360 2182 1260 1229  159  425 1784 1396 1039 1573  233  134 1882\n",
            "  963 1163 1056  477  634 1900  478 1435  856 1461  872  400 1632 1402\n",
            "  733  804 1541 2093 1980 1972 1067  510 2301 1906 1330   79 1943  354\n",
            " 1693 1747]\n",
            "\n",
            "Sorted Relief - [  63   32 2161 2252 1388  444  736 1953    0  503  106  703  263  819\n",
            " 1127  107  120  509 1523   88 2021  847  795 1771 2040  635 1979  367\n",
            "  929 1612 2289  417 1426 1245  424 1990 1122 1048  865 1318  670  118\n",
            " 1745 1520 1261  181 1081 2165 1273 1485 2137  531 1875 1701  265  565\n",
            " 2041 1280  134  718 1544 1209 1488 1710  276 1276 2264  377  836  544\n",
            "  429 2098 2280  309 1635  811 1521  483  778 2129   49 2110 1607 2298\n",
            " 1175 2202 2283 1552  368 1769 1400  126 1750  229  249 2218   28 1667\n",
            "  511 2219 2220 2004  837 2082 1827   96  660 1262 1142  256 1439 1644\n",
            " 2013  245 1372  532 1326 1472 1119  373 1950 1707  750  671 2297   51\n",
            "  912  802 2303  280  234  841 1937 1501 1008  431  818 1716 2231  144\n",
            "  521  357 1460 1939 2302 1291 1037 1941  606  951 2134  166 1602 1436\n",
            " 1079  476 1836 2029  468 1846 2091   22   13  267 1845 1641  305 1494\n",
            " 1692 1354 1010 2194  524 2199  628 1403 1464 1496  808  957 1093 1353\n",
            " 1297 1996 2017  246 1659  943  828 1833 1029 2088 1841 1794  566  389\n",
            " 1538  950  401 1772  460  266  706 1463  967 1112   94  910 2007  325\n",
            " 2060  593 1269  402  765  984 1555  860 2158 1615 1884  545 2251 1085\n",
            " 1731  405  851 1860  434 1153 2037  702  230 1733   26  430  255 2222\n",
            "  243  347 2197  400  961 2270  580 1188 1516 2031 1342 1183 2306  799\n",
            "  218  787  953  199 1936  364 1389  899 1243 1830 1735 1808  850  664\n",
            "  852  151 1138  855 1259 2030  124  414  110  258  410 1583 1874 1348\n",
            " 1362 1377  933 1072 2020 2006 1121 1671 2019  145   31 2095  361 1879\n",
            " 1730 2301 1084 1625  409  771  846 1985   77  115  985 1912  113 1196\n",
            "  959   83  730  726 1746 2056 1328 1366  892  156 2266  695   67 1894\n",
            "  520 1566 1646 1207  831  170  752 1367  202  296 2299 1492 1840 1073\n",
            " 1810 1738 1642  684  568 1316 1376  875 2216 2179 1082 2221  335  464\n",
            "  978  655 1788 1331 1916  674   66 1158 1823 1802  839 2173 2262 1670\n",
            "  510 2227 2150 1493 1598  135  935  137 1525 1666 1536 1418 1785 1699\n",
            "  407  866 1984  433   65  973 1420 2268 2093 1432 1727   52 1352  411\n",
            " 1744 1662 1774 2136 1358 1691  281   40  138  890   62 1809  403  886\n",
            " 2045  396   91 2241 1359 1232 1722  548 1617 1473 1929 1999  547 1872\n",
            " 1784  292  415 2182  755 1240  525 2189  585 1467 1221 2225 2064 1185\n",
            " 1045 1700  784 1978  916 2027 1285 1134  830 1795  928 1234  767 1972\n",
            "  247  178  658  980 1155  494 2304   20  387  907 1187  146 1742  743\n",
            " 1314  748  833 2290 1857 1947  455 1695 1569  944  372  259 1324 1002\n",
            " 1960 2213  849 2208 1852  318 2296  673 2071 2125  173 1390 1351 1201\n",
            " 2244  589   37 2059 1147  514  395 1200 1268  448 2284   15  109 1747\n",
            " 1069  381  408 1576 1088 1858  432 1732 1030 1885  257 1504 1649  233\n",
            " 1603  339 1123 1871  686  925 1247    1 2010  946 1340 2046 1244 1773\n",
            "  762  863 2099 1441  672 2195 1018  976  121 2147 1395  191 1419 1848\n",
            " 1042 1706 1235  358  248 1907 1021  286 1068 1676  602  543  720 1633\n",
            "  705  991 1974 2250  813 1422  343  627 1868  608 1619  215 1469 1036\n",
            " 1968  614   47  972 1812 1721 1791 1582 2285  603  482 1737  932 1126\n",
            " 1397 2094  675 1565  783  827 1604   74 1690 1780  918 2279 2070 1507\n",
            " 1519  519  731  825 2243  150 2008 1618  220 1295  314 1345  806 1092\n",
            " 2123  337 2109  180  656 1104  919  205  904   99   14  906  349   85\n",
            "  611 1562  704 1708  607  838  212 1152 2131 1867 2171   29  515 1768\n",
            " 1920  862 1755  893 2018  236 1910  471 2065 1500 1219  920 1896  486\n",
            " 1298  930 1640 1805 1807  728 1781 1921  561 1236  954  184  356 1977\n",
            " 1172  211  291   21  530 1626 1672 1319 1821 1302 2167  536  739 1975\n",
            "  268  622  634 1656  351 1517  131  333  965  624 1248 1638  239 1086\n",
            "  262  253  826 1005 2107  273 2005   30  465  370  425 1144  681 2081\n",
            " 2069 1312 2235  539  392  155  283  637   98 1767  549 1760  729  689\n",
            "  185 1705 2011 1587  128  365 2085 1286  641 2258 2210 1687 1592 2048\n",
            "  817 1099 1399  600 1337 1220 1616  774 1150 1470 1855 1726  159  328\n",
            "   89 2307 1897  734  103 1575 1813 1343 2039 1720 2053  474  981 1258\n",
            "  996 1499 1796   79  979  665 1054  988 1211 1032 1572 1218  162 2058\n",
            "  653 2148 1114 1480 2237  260 2044  496 1078   48  590 1814 2154  553\n",
            "  725  989]\n",
            "\n",
            "Sorted Chi - [1388 1954  782  245  835 1915 2045  845 1318 1953  122  741 1600  544\n",
            " 1883 1002  254 1914   84   73  186 1386  565 1157  334 1895 2198 1763\n",
            " 1294  173  128 1707 1910  757  909 1644  152 1734 1352  553 1605    1\n",
            "  508 1722  235  975  367 2049 1803  866  588 1054 1923 1206 1065 1979\n",
            "  416 2158  164 1385  822 2143 1931 1374 2252 1775 1705  602 1073 1262\n",
            " 1887  432 1193  347 1066 1092  969 1612 1083  574 1973  275 1326 1798\n",
            " 1098  118  187 1661 1115  936  778 2082  421  250 1104 1195 2161 1771\n",
            " 1893 2229  106  399 1633  878  584 1048  798 1442 2126 1278 1433  606\n",
            " 1021 1297 1737 1109  718  654  335  441 1990  429  848 2046  168  752\n",
            "  337  165  997  819  436  950 1197 1200  229  181  468  324 1346  779\n",
            " 1654 1861  570 1296 1089 1578 2098 1035 2257 2048   49 1838  760 1029\n",
            " 2116  443  665  818 1535 1329  230  666 1913  874   28 1750  150  811\n",
            "   53 2021   66 1413  557  978    0 2145 2300 2226  189  379 1745 1999\n",
            " 1205  554 1282  288  216  694  671 2302 2202  503 1523 1729 2156  364\n",
            "   32  551 1012 2275 1908 1226  795 1272 1245  932 1166  509 1516 1219\n",
            " 1452 1141  687 1415 1991 1300  372 1593  228 1485  787 1323 1625 2174\n",
            "  841 1833    3 1774  243 1976 2185 1158 1203  974  572 1943 1607  531\n",
            " 2246  377 1830 2278 1726  728  476 1371  807  736  596 1006 1459  371\n",
            "  656 1959  706 1672 1330 1317 1186  971 2274  480 1426  482  498 1260\n",
            " 2115  256 1948 1794  325 1916 1941 1082  713 2103   75 1069 1802 1757\n",
            " 1730  902 1087 1620 1586 1493 1416   35  730  255  136 2197  714 1755\n",
            "  545 1739  649 1005  353 1291  744 1334 1866  383 1769  155  107   88\n",
            " 1715  838  871 1081  380   51  448  257 2234 2288 1488 1150 1007 2113\n",
            "  603 1478  802  611  905  267 2015  638  141  911 1311 1372 1670 1496\n",
            " 1492 1216 1623 1764 1828 2265 1111  263  522  414 2155  755 1131 1212\n",
            "  849 2092 1805 1594  631 1347 1020 2135  601  793  670 1885  449  444\n",
            "  138 1886  234 1576 2240 1642 2239  543  311 1209    2 1220 1856  641\n",
            " 1022  276  500  129  280 1950 1820 1727 1875  846 1534 2131    8 1872\n",
            " 1581 1068 1772 1253  535  879 2074  850  290  140  589  605 1827  123\n",
            " 1783  607  637 1125 2199  900  750 1072  322 2041 1350 1402 1273  837\n",
            " 1767 1822 1547  940  145 1271 1224  970 1980  532  628 2208 2139  748\n",
            "   89 1648  193   26 1281 2289  285 1723  644 1041 2294 1400 1669 1738\n",
            " 2117  581  521  320  247 2169 1685 1966 1759 1697 1075 1067   63 1202\n",
            " 1142  732  661 1696 1517  191  271  743 1004 1468  435 1530  872 1733\n",
            "  483 1308 2162  765 2191 1703  313 1881 1963  423  746  864 1677  735\n",
            " 1404   31 2247 1609  293 1391  278 1436 2052 1016 1159  832 1658  238\n",
            " 1956 1663  827 2095  492  759 1090  265 1740 1285  287 1229  703 1716\n",
            " 1422  836 1261 1369  972   25  373 1015 1001 2122 1148 1225  314  496\n",
            " 1251  681  134  208 2160 2087  237 1544 1008 1457 1537 1234 2167  585\n",
            "   67 1521 1676 1480  199 1900   57 1852  693 2227  664  126  289  206\n",
            " 1093 1236 2222 1708 1071 2200 1628 1095  166 2230 1860 2206  188  144\n",
            " 2165 1119 2014  634 2204  363  695 1170  824 1275  502 1709 1267  396\n",
            " 2212 1840  942 1423 2182 1495  131  613 1088  361 1344 1338 1701  797\n",
            " 2298  839 1097  880 1681 1094 1301 1121  517  788 1307  979 1376  542\n",
            " 1124  456 2031 1266  955 2151  170  987 2242  890 1019  151  204 1506\n",
            "  464 1967  261 1955 2215 1435 2096 1235   96 1777   83 2018 1904  963\n",
            "  642 1010   55  696 1303 1978 1290 2216 2193  635 1699 1905 1700 1564\n",
            "  452 1789 1884  776 1524 1501  816  368  369 2069 1368 1819 1749  418\n",
            " 2137 1105 1962  799  982  533  761 1859 1993  660  541 1927  520  489\n",
            " 2036  221 1735 2272  499 1760 2166  552   80 1265 2233 1821 1099 1060\n",
            " 1257  947 2134 2301 1643  593   92 1314 1031  921  408 1392  400 1836\n",
            " 1660  840 1598 1463  403 1249  218 1196 2039  442 1439 1208  754  351\n",
            " 1024 1813 1393 2088  804  484 1655 1929 1176 1268  252  705   91 2293\n",
            " 1156  745 1342 1552  796 1377   98 2040 1741  790 1928 2297 1724  794\n",
            "  823 2277 1472 2100 1299  277 2171  262  929 1163 1583 1555 1906  417\n",
            " 1557 1656 1298  241   74 2130 1483  740  918 1038  973  420  120   16\n",
            " 1650  479 1575   33 1846 1182 1011 1062 1549 1389  425 1880 1808 1556\n",
            "   24  510]\n",
            "\n",
            "Sorted Pearson Corr - [1388 1953  245 1954 1193 1002  544  186 1073 1206 1318 2049 1887  228\n",
            "  508 2045 1109 1798 1705 1092 1326 1910 1644  970  909  468 1371  347\n",
            " 1722 2116 1329 1895  866  978 1979  173 1916 1633    1  335   35  565\n",
            "  128 1020  827 1707 1195 1670  654  940 1297  432  250 1771  372  743\n",
            "  557 1216  602 2246 2145  482  367   66 1856 1054 1495 1104 1993   28\n",
            "  714  760 1029 1088 1737 1022 2046  778 2158   51  553 1669 1202 1291\n",
            " 1048 1111 1978 2252 1866  802  371 1285 2274  746 1609  418  603  656\n",
            " 1011   25 1038 1069 1596  856 2226  745 1492 2171 1849 2082  819 2048\n",
            " 1286 1131 1913  353  695  807 1415 2294  187 1713 1990  480 1733  150\n",
            " 1404 1936  429  118  408  337 1923 1516 1324 1612  701  140   79 2092\n",
            " 2299  773 1772  464 2036 1352 2008 1200  665 2229  483 1853  152 1643\n",
            "  414 1219  641 1021 1121 2098  950   53  848  257 1875  637 1062  181\n",
            " 2087  794  387  190 1227  635  243  267 1261 1389 1625 1253  502  360\n",
            "  788  442  314 1089 1377 1881  890 2234 1237  838 2105  963 1696   88\n",
            "  748 1919 1928  649 1245 1654 2020 1093 1836  614 2069 1316 2150  436\n",
            " 2277  849  613 1900 1676  522 2085 1574 1821 1150 1750  377  611  811\n",
            " 1439 1497  687  500 1251  108  932  322 1944  339 1488  229 1994 1420\n",
            "  759  606 1941 2019 1159  688  975 1820 1257 1594  628  732  680  403\n",
            "  380  918 1708 2208  168 2113  503  696 1661 1489  882 1805 2099  969\n",
            " 1642 1946  693  735 1124  752   96 1296  517 1068 1142  831 1300 2293\n",
            " 1012 1496  263 1859 1037 2142 1356  383 1493 1779 1518 2304  597 1226\n",
            " 2101  777  138 1595 1715  435  864 1225 1299   47  682  822  496  761\n",
            " 1726   92   49  633 1330  854 1649 1220  712  755  286 1982  499  413\n",
            " 1524  705 1842   59 1152  155 1431   56 1158 1645  631 1480 1344  216\n",
            " 1549  396  241  572 1827 1966 1154  130 2302  972 1517 1878   72 1770\n",
            "  419 2143 2007 2072 2154 1877 1593  713  222  639  256  946 2167 1099\n",
            " 1525  982 1605 1997 2284  728 1689 2060 2080 1767  850 1725 1282 1059\n",
            " 2104 1019 1077 1956 1402 1094 2119  364  765  607 1535 1486 1854  252\n",
            "  824 2261 1728 2301  636 1186 1027 1274 1830 1148 1852  670 1295 1045\n",
            " 1060 1161 2015  998 1739  406  883 1961 2220  407 1467 1082 1262  420\n",
            " 1254   89  313 1602 1905 1909 1523 1690 1156 1760  509 1224 1463  147\n",
            " 1221 1774  368  422 2018  973 1284  120 2182 1033  375  984 1907  481\n",
            " 1319  439 1358 1863  968 1236   64  213 1163 2222 2004 2272 1526 1672\n",
            " 1473 2169 1999 1879 1671  740  145  452  361 1845 1573 2288 1963  441\n",
            " 2059 1584 1759 2260   17  541 1732 1392 1390 2148 1036  400 1556 1126\n",
            "  312 2074 1346  157 1417 1955 1639 1698 1453 1478 1967 1869  398 1587\n",
            " 1105  136 1485 1378 1348  239 2095  979   30 1653 1700  644 1571   67\n",
            "  359  379 1540 2159 1565  493  448  595 2307 2093  129 1232   10  532\n",
            " 1501 2067  151 2122 2038 2014  552  334 1872  402 1795 1367  727 2235\n",
            "  352 1263  254 1399  158 1170  933 1604  105  542 1727 1135 1032 1210\n",
            " 1592 2157  545  255 1912 1890  338   39  317 1950   31 1380 2011  161\n",
            " 2016 1781 2054 1747  166  823 2166  999 2147 1174  144 2199  264  990\n",
            "  723  225  840 2144   60  681   69  625 1531  221 2140  567 2233  131\n",
            " 1273 2289 1567 1197  764 1133 1472  409 1375 1430  750  330 1638  211\n",
            " 1846 2091 1824 1755  888  627  382   26 1521 2202  251  274  527 1937\n",
            " 1538 1778    6  293    2  634 1851  231  160  574  837 1188 1975 1550\n",
            "  879 2152 1600 1873 2189 1498   71  529  816 1243  546  871  671 1429\n",
            " 1087 1606 1802 1015  569  223  892 1065 2269  292 1646 1004 1782  465\n",
            " 1302 1451 1259  210  593  123 2114   50 1075 1608 1764  664  730 1673\n",
            " 2001  308  374  642  164 1293  860 1097 2180 1532 1833  757 1989  165\n",
            "  981  137  793 1848 1731  240  658  862  967 1591 1447 1194 1972  707\n",
            " 1001 1806 1304  279  185 1106 1898 1943 1381 1857  230 1761  320 1438\n",
            " 1840  787  836  736 1086 1924 1146 2062 1745 1996 2305 1738  489 2138\n",
            "  141  869  425 2033 2090 1970  952  179 1112 2175 2247  112  919 1569\n",
            " 1929   58 1749  678 1487 2281 1083 1527 2032 2232  191 1031  791  961\n",
            " 1668 1651  297  533  893 1103 2206 1468  923 1067 1799  995  573 2292\n",
            " 1298  428  548 1239  571  938  449 2176 2187  947 1434 1507 1952 1800\n",
            " 2300  133]\n",
            "\n",
            "Sorted Fisher Score - [ 122 1388  741  845 1157 1605 1954  334  757  544  245  835  782 1883\n",
            " 1385  152  254 1953  878 1600 1002  164  822  975 1294  584   73  588\n",
            " 1386 1065 1979 1661 2143 1326 1206  187 2045 2158 1973 1318 1035  421\n",
            " 1115 1895 1374 1915 1098  173 1887 1193 1066  950  909  186  936 1914\n",
            " 1931  997 1092 2156 1073   84 1861  508 1535 1803 2252 2049 1910 1838\n",
            " 1278  574  235 1893 1452 1913  165 2257 1089  416 1083 1771 2229  848\n",
            "  602 1644  798  228 2185 1578 1197 1722 1763 1433 1999 2198 2126 1923\n",
            "  570 1775  399  275  718 1633 1729  819  866 1734  441  551  554  779\n",
            " 1496 1352 1346 1029    0    1 1282 1442 1087  335  480  974 2115 2275\n",
            " 2161  106  436  189 2116 1705  367   28  606 1941 1654  128 1195 1798\n",
            " 1205 1109  482  432  337  324 1586  978 1006 1828  811 2082 2278  565\n",
            " 1707  347  874  181 1007 2046 1990  596  940  971  468 1625 1948 1054\n",
            " 1141 1612  955  760 1150  429  371  841 1623  666 1769  970 2145 2300\n",
            " 1737  443  654   35 1943 1297   75 1886  969 1323  531  229 1875  905\n",
            "  377   51 1908  150 1794 1413 2048  250 1262  900 1371 1166 1317 2302\n",
            " 1041  243  778 1976  714  372 1347 1329  553  509 1672 1963  649 1048\n",
            " 1104  818 1685  557  755 2155  802 1158 1260 2239 1272 2202  545 1488\n",
            "  364 1021  379  247  267 1822 2174  631 1783 1459  288 1216 2191  902\n",
            "  752 1866   53  665   66  694 1576  795 1202 2021 1991  503  827  476\n",
            " 1005 1670 1067  601 1391  656 1186 1291 1916 1426  637 1483  581   49\n",
            " 1648  730 1955 1219  423 1334 1020 1088   88 2240 1311 1620 1607  732\n",
            " 1492  118  932  136 1485 1534 1774  706 1745 1927 1200  141 2135  787\n",
            " 2103 1856 1663  807 2226 1764 1393 1980 1697  744   83 2113 1081 2246\n",
            " 1757 1229  911 1872 1015  452  256 1212  864 1308 1521 1090  383 1300\n",
            " 2288  890 1530  498 1966 1516 2274  638 1249  840 1001  448 1368 2015\n",
            " 1750  492  263 2197 1767 1495  314  290 1111 1978 1022 1307  837 2098\n",
            " 1885 1517   24 1523  687 1772 1125 1961  981 1220 1203 2265  168  800\n",
            " 1962 1733  255  743 1993 1245 1285 1019  748  872 1072    2 1271  605\n",
            " 1730   31  257  418 1281 1967 1416  123 1715 2117 1669    8 1480 1609\n",
            " 1696 1350  287  496 1713 2052  449 1956 1740  572 1959 1461  880  325\n",
            " 2074  849  585 2234 2206 1598 2087 1012 1755 1813  278  216  320 1936\n",
            " 1071 2130  745   25  170 1131 1758 1575 1225  414 1699 1423 1537  746\n",
            "  483   26 1701 1655  603  276  644 1170 1369  736 1004 1468  793  728\n",
            " 1314 1148  213   16 1435 1950 2092 1209  824  788 1457  628 1031 1301\n",
            " 1275  816 1761  962 2160  444 2162  543  871 1402  204 1415 1884  208\n",
            "  396  797  856 1547  461  158 1478  151   89 2096  138  238  839  735\n",
            " 1709 1506 1267  500 1008 1904 1069 1444 1596 1827 1095 2039 1119 1121\n",
            "  703 1703 1760  535  799   33 1257  794 1805  850  611  661 1060  947\n",
            " 2298 1606  750 1400 1928 2031 1208  616  759 1677 1016 1493  838 1290\n",
            "  271 1156 1726  261 1155 1524  190 1038 1859 2165  642 2208 1094   80\n",
            "  129 1594 2095  634  542 1404  963 1544 1660 1422  206 1124 1436  313\n",
            " 1342 1142  408 1642   32  522 1790  425 1376 1154 1011 1253  435  671\n",
            " 1251 1564 2171  293 1693 2014  982 1579 2167  693 1759 2284 1900  668\n",
            " 2041  832  280  339  311  858 1906 1196  942 1858   93  120  241  442\n",
            " 1265 1849 1799  660 1439 1580 1716 1593 1879  251 2166 1789  363 1394\n",
            "  497 1819 1739  921 1377 1658 1010  353  717 2247 1911 2227  193   79\n",
            "  790 1227 2170 2301  846  593  107  987  380 2216 1223   54 1261  462\n",
            " 1273  670   55  641  140 1905  695 1874  701  796 1929 1487 1836 2199\n",
            "   63 1244 1324 2299  499  387  237 2294  392  977 1643  979 1821 1188\n",
            "  259 1330  646 2242 1463 2212 1097  831  852 1880 1749 1226 2200 1316\n",
            " 2036 1286  589 1830 1075 1296  464 2088 1421 2233  221 1268  357 1237\n",
            " 1645 2182  277  733  773  124 2293  360  705  145  520  633   94  489\n",
            "  635 1706  625 1650  607 1338  458  805  400  571  915  230  454 1796\n",
            "  285 1093 1501  373 1581   74 2230   98 1383 1003  804 2080 2152  754\n",
            "   45 1802 1266  777 2100  306 2151  767  860 2204 2139  891  613 1159\n",
            " 2144  867 1412 2150 2019 1303 1710  265 1528 1777 1486 2040 2105  552\n",
            "  502  614  776 1372  973 1236 1574  403   96 2122  491  765  134  533\n",
            " 1024 1890]\n",
            "\n",
            "Sorted T-test - [1388 1979  544  950  181 1699 1326   76 1496  245 1607    0 2302 1941\n",
            "  819  606  247 1426  276 1576 1004 1654 1977  718 2252 1953 1771  543\n",
            " 1625 2197 2161  730  799 2165  787  170 1885 1794 2202  852 1478 2080\n",
            " 1158 1521 2021 1065 1749  545 1517 1072 1318  416 1073 2167 1422 1436\n",
            "  509 1485  890  444   83  430  531  476 1875  434  503  106  811  755\n",
            " 1488  373  714  649  392  259  335 1196 1194 1884  656 1872 1155 1672\n",
            "  866  155  377  238 1644 1008 1376  752 1209 1010 1990  265 1392  878\n",
            " 1081  448  585  243 1433 2031  637 1661  429 1291 1088 1750 2040 1225\n",
            "  748 1077  152 1480 2158   88 2285 1523  864 1769  367  574 1236  837\n",
            " 1612 1544 1520  364 1119 1234   98  425  840  703 2258 1813  795  325\n",
            "  151  736 2039 1874 2298  617 1858  836 1753 1999  798  384 2116  876\n",
            " 1524 2095  846  256 1760 1710  849 2301 1748  357  520  929 1463 1733\n",
            " 1314  267 2199  706 1707   63 1731 1830 1911 2234  717   31 1755 1493\n",
            "   51 2081  372  633  818 1048 1656  565  625 1268 1553 1395  124  250\n",
            "  471  483 1827  255 1244  424 1803  396 2287  510  120 1692   77   16\n",
            "  906   87   32  659 1721   35  750 1986 1667  589  850   28  279  788\n",
            "  760  491 1950 1745 1245   94 1121 1193 1767  982 2005  912 2272  229\n",
            "  126 1634 1855  806  379  566  481 2076 1772  263 2143  118 1285  944\n",
            "  253 2091  382 1516 1249 2098 1713 2198 1716 2262 2195 1315  721  802\n",
            "  478  314  496  624  389  611  670  557  704  402 2264 1084 1226 1879\n",
            "  981 1280  784 2133  337 1730 1122  827 2094  687 2204 1206  414  258\n",
            " 2235 1815 2218  115  660 1701 2226  138   29  858 1759  831  741  805\n",
            " 1085 2189 1841  932    1 1674  681 2303  511 1297 1232  626 1124  280\n",
            " 1153  358 1598  368 1273  411  234 1846  693  417 2017  400 2216 1111\n",
            " 1812 1499 1600 2280   97  804 2137 2104 1418 2019 1569   49   20 1978\n",
            "  200  199 1555  671 1635  309 1868 1045  940  296  450 2006  532 1354\n",
            " 2194  965  522  686  146   52 1880 1996  967 1359  494  904 1670 1464\n",
            " 1810  860 2169 1296  930 1564   74  735 1937  971 1068 1770 1538  202\n",
            "  235 1345 1188 1852 1583 1083 2088 1377 2071 1737 1646  946 1319  216\n",
            " 1352  215 1439 2087  134 1889  553  107 1836 2292 1888  657 1754   44\n",
            " 1972 1400  998 1335  560  336  634 2145  159  988 1020 2045 2136  441\n",
            "  347 1187  959 1348  232 1437 1854  184 1501 1642 1663  525 1262 1414\n",
            "  973 1316 1645  951  145 1747  212  778  405  286  672 1705 1871 2284\n",
            " 1594 1624  709  401 1706  968 1626 1899 1404 1017  130 1895  810  705\n",
            " 1300  246  614  203  453 1808 1592   79 1514 1662 1114  176 1372 2060\n",
            " 2056 1974 1814 1878 2077   15 1965 1261 1059  875  552 1022 2048 2213\n",
            " 1467  326 1788  833 1500 1036  635  462 1857 2018 1641 1312 1727  408\n",
            " 1159 2028 2219 2225  559 1235  339 1845 1774 1472 1366  268  381 2293\n",
            " 1823   91 1537  928 1099 1127  957 1216 1530 1420   89  958  270 1762\n",
            "   13  847 2297 1248 2182  650  655  820 2232 1219   85 2093  740 2283\n",
            " 1075 1021 2030  786 1807  547  116  665  249 1877 1562 1489 1901 1207\n",
            "  620  499 1144  731 1175 1407 1700 2105  839  403 2271  223 1441 2290\n",
            "  907 1069 1328  826 1460 1112 1329 1742 1989  916 1726 1243 1142 1148\n",
            "  177   26 1338 1840 1012  979 1593  191 1492 1343  349 1163 1952 1944\n",
            "   67  283 1689 1763 1070  493 2125 1093   53  230  351  166 2010  948\n",
            "  521  475 1859 2100 1708 2289 1220 1240  622 1087  632 1781 1397 1536\n",
            " 1821 2110 1618 1809 1985 2066  855  603  153 1191 1484 1200  361  356\n",
            "  524 1239 1728  888  197 2162 1353 1805 1202 1419  418 2208 1756  168\n",
            "  985 2129  990 1201  433 1943 2244  764 1269 2001 1867  233 1054 1787\n",
            " 1224  841 2251  394  432 1104  830 1033  743  593 1336  828 1723 1543\n",
            " 2296 1896 2281  953  623  865  817 1331 1833  103  893  972  410 2131\n",
            " 2222  653 1082   69 2250 1582  767 2099 1037 2299  564 1032 1005  281\n",
            "  157 1690 1497 1722  257 1936  834 1735 1548 2119 2307 2156  156  922\n",
            " 2266  132   78  920 1339  144 2046 1584 1960 1028 1738  529 2259  333\n",
            " 2305 1123 1720  508  881   99 1744  415  375  569 1324  813 2118 1983\n",
            "  295 1958 1362 1802 1765  664 2004 1791  785 2270 2020 1518 2037 1566\n",
            "  796 1942  901 2214 1860 1358 1784 1900 2249 2047  135  427 1204 1102\n",
            " 1609  318]\n",
            "\n",
            "Sorted SNR -  [1388  245  544 1953 1326 1954 1318 1073 2116 1088   51 1291  819  267\n",
            "  120 1771  831 1121   35  802  335  864 1348 2105 1517   79  483 1859\n",
            " 1733  181  371 1878 1746 1112 1377  727  489 1316  157  405 1324  875\n",
            "  462 1772 1045  635  382 2283 1002  286 1584   28 2076 1670  606  450\n",
            "  387  368  377 2262  603 1239 1624 1319  820 1854  968  212  892  339\n",
            "  811 1521 1399 1531 1213 1979  103  122  826  132 2235  402 2019  414\n",
            "  672  512  890   58  827  604 1362 1375 1059 1122  837  295 2271 1990\n",
            " 1225  314 1148 1899  946  613  647 2284 1536  631 1427 1538  884   81\n",
            "  511  429 1728  803 1048  454   20  507 2298  705 1888  565 2099  909\n",
            " 1937 1751 1564  268  338 1877  608 1420 1036  689 1869  587  494 1972\n",
            " 1975  567 1836  907  177 1191 2066    4 1481  865 1463 1445  578 1950\n",
            " 2290 1512  104  720 1770  944 1144  639  376  707  633  693 1328  365\n",
            "  281  121 1285 2082 1072  741  655 1827 2243  347  201 1302 1437  735\n",
            " 1958  747 1232  612 1631  108  920  632 2264 1695  750  137 1464 1569\n",
            "  627 1875 2299  343  788 1539  329 1917 1565 2119 1689 1276 2252  625\n",
            "  791 2083  851 1353  731 2220 1408  423 1813  596  498 1847 1641  703\n",
            " 2060 2307  659  781 2301  530 1074 1707  119  318 2098  737   82  151\n",
            " 2177 1713 1687 1985  986 1941  426 1674  336  323 1698  985  981 1206\n",
            "  783  673   14 1498  796 1559 1029 1160 1030  503   52 1407  413  477\n",
            " 1627 2136 1310 1619  927  960 1183  901 1995  770 1907   63 1543 1580\n",
            "   76 1204  549 1489  403  515 1714 1137 1093  808  148  401 2256  813\n",
            " 1895 1450  888 1760   22 1554 1357 2040  965 1070 1228 1123  437 1845\n",
            " 1516  162  682  562  367  362 2020  428  491 1230 1897  698 1261 1056\n",
            "  679 2237  504 2279 2107  575  941 1114 1610 2244 1616 1611   46  569\n",
            "  220 1248 1297 1965  900 1814 2159  722  675  935  710 2178 1293 1391\n",
            " 1414 1636  558  660 1702 2218 2270  767  923 1439  464 2075  833 1879\n",
            " 1354  363  291  304  922  579  400  381  677 1502   88 1898 1033  786\n",
            "  836 2184 1482 2010  559  929 1419  626 2219 1614  519  881  523 2253\n",
            "  919 1169  948  139  395  860 1120 1389 2044 2058  478 2238  392 1397\n",
            " 1752 1286 1524 2249 1028  333  294 2029  629  716  356  481  407 2034\n",
            "  586  113 1252 1666 1829  926 2188 1358  975  911  242 1126  172 1188\n",
            "  205 1795 1446  302  202  488 1762 1863 1440  784 2181 1608 1460 1776\n",
            " 1057 2122 1038  609  273 1396 1329 2293 2094 1245 2056 1815 1680 1947\n",
            " 2125  486 1929  785   13   96  580   99  447  925  855  124 1005  556\n",
            "  470  142 1804 2282  427 2236  328   48 1177 2089 1246 1047 1505 1196\n",
            "  614  305 2071  217 2224 2057 2168  914 2102  717  996 2280  283  366\n",
            "  605  862 1065  439  499  839 1496 1778 2292 2038  961  548  296  117\n",
            " 1577  771 1944 2023  683  812 1342 1384 2109 1479  495  225 1133 1405\n",
            "  794 2251  628  810 1258 1945 1428  316  509  431 2077  249 1871 1339\n",
            "  487 1788  814 1884   70  111 1520 1317 1315 1283 2245 2110 2137 1264\n",
            "  561  373 1683  774 1403   77 2250 1037 1107 1519 1526 2149   31 2043\n",
            "  591 1367  154 1321 1475 1831  102 1467 1497   65 1338 2070 1766  215\n",
            " 1052 1808  459 1434  916 1009 2146  352 2172  692   62 1136 1172  326\n",
            "  829  528 1998 2027 1662  758 2008 1848  415  806  110 1365 1652 1546\n",
            " 1572  384 1968  198  582 2045  992  125 1116  409  274  539  958 1145\n",
            "  389  934 1398 1635 1218 1078  463 1545  180 1894 1000 1691 1151 1719\n",
            " 1732 2120  600   18 1130  643 1585  412 1501 1868 1499 1816  650 2030\n",
            "  589 1765 1835  618 1277  292  910  243 1725   39 1818 1591  505 1542\n",
            "  615 1768 1449 1417 1518 1981 1102 1563  408 2287 1147 1091 1385 1180\n",
            "  736 2022 1588   30 1613 1222 1390  397  878 1667 1821  332 1032 2007\n",
            " 1003 1469 1743 1312  467  636  843 1465  834  451  594 1969 2129  702\n",
            "  317 2151 1269 1706 1658  398  669  350  951  190   56 1488  206  676\n",
            " 1644   12  258 1247 1199 1826 1140  178   61 1240 1872 1805  726 1629\n",
            " 1615 1379  846  545 1454 2025  440  592  821  715 1949   38 1876 1404\n",
            "  424 1472  236 2156 1142  906  756 1092 2158 1896 2059 1940  617 1671\n",
            " 1356  224  991  303   86 2241  607  959 2194  690  937  346 2173 1305\n",
            " 1162 1870  980 2111 1960   92  648 2004 1364  537  863   85 1337 2078\n",
            "  310  709]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIsgDC9Jv2dR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def score(a,p,target):  \n",
        "  if p==1:\n",
        "    return mutual_info_wrapper(pd.DataFrame(a.reshape(-1,1)),target)\n",
        "    \n",
        "  if p==2:    \n",
        "    ndf=pd.DataFrame()\n",
        "    ndf[0]=a\n",
        "    reliefa=reliefF(ndf,target,NEIGHBOURS,2)\n",
        "    return reliefa\n",
        "  \n",
        "  if p==3:    \n",
        "    from sklearn.preprocessing import MinMaxScaler\n",
        "    mms=MinMaxScaler() \n",
        "    a=mms.fit_transform(a.reshape(-1,1))\n",
        "    chia=chi2(a,target)[0]\n",
        "    return chia\n",
        "  \n",
        "  if p==4:\n",
        "    return pearson_corr(pd.DataFrame(a.reshape(-1, 1)), target)\n",
        "  \n",
        "  if p==5:\n",
        "    return fisher_score(a.reshape(-1,1), target)\n",
        "  \n",
        "  if p==6:\n",
        "    return t_test(a, target)\n",
        "  \n",
        "  if p==7:\n",
        "    return signaltonoise(pd.DataFrame(a.reshape(-1,1)), target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6PLDQyOFwTvz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_clusters(genes,features,p,target):\n",
        "  \"\"\"\n",
        "  genes - list of subset gene. These are the genes of picked by the score function. Please note that these are just the gene names. Their actual values are passed in the features dataframe\n",
        "  features - the dataframe which contains the values of the genes\n",
        "  p - this denotes the  type of score function. 1- mutual information, 2- reliefF, 3- chi square test.\n",
        "  target - target is a pandas series of target clases for each observation\n",
        "  \"\"\"\n",
        "  clusters={}\n",
        "  cluster_gene={}\n",
        "  x,y=0,0\n",
        "  genes_copy_1=np.copy(genes)\n",
        "  while(len(genes_copy_1)>0):\n",
        "    # print(\"Starting New Iteration with\", len(genes_copy_1),\"number of genes!\")\n",
        "    genes_copy_2=np.copy(genes_copy_1)\n",
        "    r_gene=genes_copy_2[0]\n",
        "    r_gene_values=features[r_gene].values\n",
        "\n",
        "    clusters[str(r_gene)]=[]\n",
        "    \n",
        "    genes_copy_2=np.delete(genes_copy_2,0)\n",
        "    genes_copy_1=np.delete(genes_copy_1,0)\n",
        "    \n",
        "    \n",
        "    \n",
        "    r_score=score(r_gene_values,p,target)[0]\n",
        "    \n",
        "    # print(\"\\nCluster number=\",len(clusters))\n",
        "    # print(\"First feature =========================j1=\",r_gene,\"\\n\")\n",
        "    x+=1\n",
        "    # print(\"Intial Relevance Score\",r_score)\n",
        "\n",
        "    while(len(genes_copy_2)>0):\n",
        "      \n",
        "      gs=genes_copy_2[0]\n",
        "      gene=features[gs].values\n",
        "\n",
        "      y+=1      \n",
        "      \n",
        "      a_plus=np.add(r_gene_values,gene,dtype='float64') #creating A+\n",
        "      a_minus=np.subtract(r_gene_values,gene,dtype='float64') #Creating A-\n",
        "\n",
        "      a_plus_score=score(a_plus,p,target)[0]\n",
        "      a_minus_score=score(a_minus,p,target)[0]\n",
        "      \n",
        "      new_score=a_plus_score if a_plus_score>a_minus_score else a_minus_score\n",
        "      # print(\"Gene\",gs,\"+ Score\",a_plus_score,\"- Score\",a_minus_score)\n",
        "\n",
        "      if new_score>r_score:\n",
        "\n",
        "        if a_plus_score==new_score:\n",
        "\n",
        "          # print(\"Gene Under Consideration\",gs)\n",
        "          # print(\"Initial Relevance\",r_score,\"Final Relevance\",a_plus_score,r_score<a_plus_score)\n",
        "\n",
        "          clusters[str(r_gene)].append(str(gs)+\"+\")\n",
        "          r_gene_values=a_plus[:]\n",
        "          r_score=a_plus_score\n",
        "\n",
        "          # print(\"cluster member = +\",gs,\"\\tRelevance Changed to\",r_score)\n",
        "\n",
        "        elif a_minus_score==new_score:\n",
        "\n",
        "          # print(\"Gene Under Consideration\",gs)\n",
        "          # print(\"Initial Relevance\",r_score,\"Final Relevance\",a_minus_score,r_score<a_minus_score)\n",
        "          \n",
        "          clusters[str(r_gene)].append(str(gs)+\"-\")\n",
        "          r_gene_values=a_minus[:]\n",
        "          r_score=a_minus_score\n",
        "\n",
        "        #   print(\"cluster member = -\",gs,\"\\tRelevance Changed to\",r_score)\n",
        "        # print(\"Gene\",gs,\"selected!\",np.where(genes_copy_1 == gs))\n",
        "        genes_copy_1 = np.delete(genes_copy_1, np.where(genes_copy_1 == gs))      \n",
        "      genes_copy_2=np.delete(genes_copy_2,0)\n",
        "    \n",
        "    # for each in clusters[str(r_gene)]:\n",
        "    #     genes_copy_1=np.delete(genes_copy_1,np.where(genes_copy_1==each))\n",
        "    cluster_gene[r_gene]=r_gene_values\n",
        "\n",
        "  #   print(\"\\nFinal Relevance Score\",r_score)\n",
        "  print(\"Clusters formed! Returning Clusters and Gene Representatives\")\n",
        "  return clusters,cluster_gene"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "doROa5GC9OF7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "6132dbc8-7a54-4bd6-c2a2-be9bd6435b22"
      },
      "source": [
        "#Please skip this cell in favour of the next if you are using a local runtime instead of colab.\n",
        "\"\"\"\n",
        "Computes the clusters via parallel processing\n",
        "\n",
        "\"\"\"\n",
        "\"\"\"\n",
        "import time\n",
        "start=time.time()\n",
        "import multiprocessing as mp\n",
        "pool = mp.Pool(mp.cpu_count())\n",
        "(mi_cluster,gene_repre_1),(relief_cluster,gene_repre_2),(chi_cluster,gene_repre_3)=[pool.apply(getClusters, args=x) for x in [(sorted_mi,feature,1,target),(sorted_relief,feature,2,target),(sorted_chi,feature,3,target)]]\n",
        "pool.close()\n",
        "end=time.time()\n",
        "print(end-start)\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nimport time\\nstart=time.time()\\nimport multiprocessing as mp\\npool = mp.Pool(mp.cpu_count())\\n(mi_cluster,gene_repre_1),(relief_cluster,gene_repre_2),(chi_cluster,gene_repre_3)=[pool.apply(getClusters, args=x) for x in [(sorted_mi,feature,1,target),(sorted_relief,feature,2,target),(sorted_chi,feature,3,target)]]\\npool.close()\\nend=time.time()\\nprint(end-start)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h03bwBlJ_YGx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "2ea81d42-ad63-4afa-b110-eed22a5e5364"
      },
      "source": [
        "mi_cluster, gene_repre_1 = get_clusters(sorted_mi, feature, 1, target)\n",
        "relief_cluster ,gene_repre_2 = get_clusters(sorted_relief, feature, 2, target)\n",
        "chi_cluster, gene_repre_3 = get_clusters(sorted_chi, feature, 3, target)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clusters formed! Returning Clusters and Gene Representatives\n",
            "Clusters formed! Returning Clusters and Gene Representatives\n",
            "Clusters formed! Returning Clusters and Gene Representatives\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4OGZQTkzIfP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "7811e3d8-98f6-48ce-ab20-01714c33fdc3"
      },
      "source": [
        "\n",
        "pc_cluster, gene_repre_4 = get_clusters(sorted_pc, feature, 4, target)\n",
        "fs_cluster, gene_repre_5 = get_clusters(sorted_fs, feature, 5, target)\n",
        "tt_cluster, gene_repre_6 = get_clusters(sorted_tt, feature, 6, target)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clusters formed! Returning Clusters and Gene Representatives\n",
            "Clusters formed! Returning Clusters and Gene Representatives\n",
            "Clusters formed! Returning Clusters and Gene Representatives\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnWhuHknYN0j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "11d9b269-8e12-4f54-db2c-2b172199fa2c"
      },
      "source": [
        "snr_cluster, gene_repre_7 = get_clusters(sorted_snr, feature, 7, target)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clusters formed! Returning Clusters and Gene Representatives\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unmgoPcqGrdZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "51fad001-4939-4db5-83e2-12c229d1c8b6"
      },
      "source": [
        "print(\"Number of MI Clusters formed -\",len(mi_cluster))\n",
        "print(\"Number of ReliefF Clusters formed -\",len(relief_cluster))\n",
        "print(\"Number of ChiSq. Clusters formed -\",len(chi_cluster))\n",
        "print(\"Number of Pearson Clusters formed -\",len(pc_cluster))\n",
        "print(\"Number of Fisher Score Clusters formed -\",len(fs_cluster))\n",
        "print(\"Number of T-Test Clusters formed -\",len(tt_cluster))\n",
        "print(\"Number of SNR Clusters formed -\", len(snr_cluster))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of MI Clusters formed - 54\n",
            "Number of ReliefF Clusters formed - 12\n",
            "Number of ChiSq. Clusters formed - 39\n",
            "Number of Pearson Clusters formed - 7\n",
            "Number of Fisher Score Clusters formed - 9\n",
            "Number of T-Test Clusters formed - 12\n",
            "Number of SNR Clusters formed - 14\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MbSnAEwWBvl6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gene_repre_1 = pd.DataFrame(gene_repre_1)\n",
        "gene_repre_2 = pd.DataFrame(gene_repre_2)\n",
        "gene_repre_3 = pd.DataFrame(gene_repre_3)\n",
        "gene_repre_4 = pd.DataFrame(gene_repre_4)\n",
        "gene_repre_5 = pd.DataFrame(gene_repre_5)\n",
        "gene_repre_6 = pd.DataFrame(gene_repre_6)\n",
        "gene_repre_7 = pd.DataFrame(gene_repre_7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYNyXkNZ2EEo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 901
        },
        "outputId": "c7bd48c0-718e-4441-a67c-92485a1668b0"
      },
      "source": [
        "print(\"MI -\",gene_repre_1.head())\n",
        "print(\"ReliefF -\",gene_repre_2.head())\n",
        "print(\"Chi -\",gene_repre_3.head())\n",
        "print(\"Pearson -\",gene_repre_4.head())\n",
        "print(\"Fisher Score -\",gene_repre_5.head())\n",
        "print(\"T-Test -\",gene_repre_6.head())\n",
        "print(\"SNR -\",gene_repre_7.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MI -       1388     1193    334      1318  ...    23      1573    477     354 \n",
            "0  10.1886 -10.3985 -2.8721  12.5458  ...  7.5323  3.7401  1.3653  3.0216\n",
            "1   9.4296  -7.8566 -2.6802  13.4258  ...  8.5748  2.3794  2.0892  2.9033\n",
            "2   6.8954  -8.2212 -1.4287  10.4759  ...  9.8648  3.0841  1.6290  2.8229\n",
            "3  10.3398  -4.7042 -1.8044   9.4123  ...  6.7251  4.5457  1.8211  6.5289\n",
            "4   9.7931  -8.8772 -0.6759  10.0126  ...  7.1531  1.7820  1.0683  2.7075\n",
            "\n",
            "[5 rows x 54 columns]\n",
            "ReliefF -      63       1953     2289     565   ...     1467     286      1780    1726\n",
            "0  7.3056  10.3002   8.9733   1.5153  ...  -9.7188   5.6944   3.7661  0.3419\n",
            "1  6.5486  11.6163  12.3314   0.7962  ...  -6.9983   5.9472   5.4671  0.2437\n",
            "2  6.9280   8.6558  16.8619   7.6460  ...  -9.7865   5.8401   4.2402  0.3628\n",
            "3  4.3371  20.7725  19.2294   2.0250  ... -11.0355   5.4688  12.3256  0.9463\n",
            "4  6.3834  16.6092  12.6048  12.1985  ...  -3.5591  15.0916  14.1811  2.0023\n",
            "\n",
            "[5 rows x 12 columns]\n",
            "Chi -       1388    1954    782     845   ...    613     83      2134    1906\n",
            "0  15.6997  0.6362 -0.1270  3.5697  ...  3.3478 -2.2004  0.9215  2.1117\n",
            "1  18.2297  0.8703 -0.0739  3.9297  ...  2.5582 -1.9606  3.5672  1.6635\n",
            "2  16.5814  1.2004 -0.5820  2.2279  ...  2.2700  0.2424  4.8988  1.2047\n",
            "3  20.5141  1.0810 -0.0012  4.5191  ...  0.7325 -2.5295  0.1810  1.7362\n",
            "4  20.9987  1.0549 -0.0952  2.2488  ...  1.3900  2.0665  3.8012  0.7027\n",
            "\n",
            "[5 rows x 39 columns]\n",
            "Pearson -       1388     544      1707     429      47       1573    1833\n",
            "0  28.4262  25.7957  15.2204  11.7678  -7.6985  25.4996  1.6751\n",
            "1  28.1209  26.5660  18.4480  15.2371  -6.9149  17.5551  1.6474\n",
            "2  29.9331  24.9150  18.4940  18.5935  -7.2867  22.9836  4.6208\n",
            "3  29.0543  24.4332  14.5881  12.7054 -11.4723  30.0036  9.7504\n",
            "4  29.0209  24.9082  13.2140  22.6358  -4.7334  23.3636  1.0653\n",
            "Fisher Score -      122      1954     975     909      508      900      637     500     535 \n",
            "0 -6.3248 -24.8233  14.7648 -4.3010 -27.1948  12.1102  -7.3377 -3.8272  7.6962\n",
            "1 -6.2642 -24.6371  15.6480 -4.1006 -28.5489  10.2902  -4.4265 -4.3703  3.5012\n",
            "2 -7.5608 -25.7597  16.0077 -3.8280 -29.7133   7.4653 -13.7878 -6.7224  3.8070\n",
            "3 -7.0659 -24.3495  14.9024 -3.3516 -26.9572  10.6853 -15.4027 -2.9301  3.1359\n",
            "4 -7.0129 -24.6170  15.4340 -2.2634 -28.6246  11.9589  -9.1935 -5.2446  1.5370\n",
            "T-Test -       1388     245      83       1644  ...     2219     1840     830      1833\n",
            "0  44.9975  34.0159  37.2666  34.4919  ...  24.1912   8.8041   8.2255   1.8091\n",
            "1  44.8559  34.3939  37.6501  34.4642  ...  26.8148  12.6256   7.1942   2.1905\n",
            "2  44.4779  34.3311  36.4786  34.1910  ...  24.6697  13.3366   8.8351   5.5761\n",
            "3  44.8547  34.2566  37.0808  34.5888  ...  26.1236  15.7858  15.5108  10.6881\n",
            "4  44.3162  34.3168  37.7037  34.1233  ...  24.8006  14.8864  13.9716   7.0737\n",
            "\n",
            "[5 rows x 12 columns]\n",
            "SNR -       1388    1954     1073     831   ...    519      48      1546     12  \n",
            "0  30.5545 -2.6593  18.7581  39.5848  ... -3.5851  -6.6704 -1.5388  -3.9304\n",
            "1  30.6827 -0.9143  19.6680  39.7834  ...  3.0416 -10.8026  1.0058  -8.4560\n",
            "2  30.9158 -0.4166  19.4456  40.2370  ...  0.9508  -6.2222 -3.4967  -5.9353\n",
            "3  30.7167 -2.1572  18.6679  39.0027  ... -0.2260 -12.4711 -2.7648 -10.5658\n",
            "4  30.2602 -2.6427  20.3809  40.0509  ...  0.3290  -3.9557 -3.5043  -4.7793\n",
            "\n",
            "[5 rows x 14 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6MZ-3JyQwEl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gene_repre_1.to_csv(\"%s_p%sRepresentative_Genes_1.csv\"%(DATASET, p),index=False)\n",
        "gene_repre_2.to_csv(\"%s_p%sRepresentative_Genes_2.csv\"%(DATASET, p),index=False)\n",
        "gene_repre_3.to_csv(\"%s_p%sRepresentative_Genes_3.csv\"%(DATASET, p),index=False)\n",
        "gene_repre_4.to_csv(\"%s_p%sRepresentative_Genes_4.csv\"%(DATASET, p),index=False)\n",
        "gene_repre_5.to_csv(\"%s_p%sRepresentative_Genes_5.csv\"%(DATASET, p),index=False)\n",
        "gene_repre_6.to_csv(\"%s_p%sRepresentative_Genes_6.csv\"%(DATASET, p),index=False)\n",
        "gene_repre_7.to_csv(\"%s_p%sRepresentative_Genes_7.csv\"%(DATASET, p),index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ni7FqzO4MDnJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Saving the clusters to JSON files, this preserves the gene selection sequence\n",
        "\"\"\"\n",
        "with open('%s_p%smi_cluster.json'%(DATASET, p), 'w') as fp:\n",
        "    json.dump(mi_cluster, fp)\n",
        "\n",
        "with open('%s_p%srelief_cluster.json'%(DATASET, p), 'w') as fp:\n",
        "    json.dump(relief_cluster, fp)\n",
        "\n",
        "\n",
        "with open('%s_p%schi_cluster.json'%(DATASET, p), 'w') as fp:\n",
        "    json.dump(chi_cluster, fp)\n",
        "\n",
        "with open('%s_p%spc_cluster.json'%(DATASET, p), 'w') as fp:\n",
        "    json.dump(pc_cluster, fp)\n",
        "\n",
        "with open('%s_p%sfs_cluster.json'%(DATASET, p), 'w') as fp:\n",
        "    json.dump(fs_cluster, fp)\n",
        "\n",
        "with open('%s_p%stt_cluster.json'%(DATASET, p), 'w') as fp:\n",
        "    json.dump(tt_cluster, fp)\n",
        "\n",
        "with open('%s_p%ssnr_cluster.json'%(DATASET, p), 'w') as fp:\n",
        "    json.dump(snr_cluster, fp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLC-totaX3q8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sort_keys(scores,gene_repre,target,flag=True):\n",
        "  score_dict={}\n",
        "  x=0\n",
        "  for i in gene_repre.columns:\n",
        "    score_dict[i]=scores[x]\n",
        "    x+=1\n",
        "  return [k for k, v in sorted(score_dict.items(), key=lambda item: item[1], reverse = True)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YoGkKYQbSZWA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "feature_ranking cannot be used here because it sorts and returns the indices from 0-1\n",
        "They need to be sorted using a different function\n",
        "\"\"\"\n",
        "sorted_mi_keys=sort_keys(mutual_info_wrapper(gene_repre_1,target),gene_repre_1,target,True)\n",
        "\n",
        "sorted_relief_keys=sort_keys(reliefF(gene_repre_2,target,k=NEIGHBOURS,repetitions=5),gene_repre_2,target,True)\n",
        "\n",
        "mms=MinMaxScaler()\n",
        "nfeature=mms.fit_transform(gene_repre_3)\n",
        "chi_score,p_val=chi2(nfeature,target)\n",
        "sorted_chi_keys=sort_keys(chi_score,gene_repre_3,target,False)\n",
        "\n",
        "sorted_pc_keys=sort_keys(pearson_corr(gene_repre_4,target),gene_repre_4,target,True)\n",
        "\n",
        "sorted_fs_keys=sort_keys(fisher_score(gene_repre_5.values,target),gene_repre_5,target,True)\n",
        "\n",
        "sorted_tt_keys=sort_keys(t_test(gene_repre_6,target),gene_repre_6,target,True)\n",
        "\n",
        "sorted_snr_keys = sort_keys(signaltonoise(gene_repre_7, target), gene_repre_7, target, True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FlViCrKzCuax",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "41a1c6f6-07bd-4ccb-dde0-dc3e979e65e3"
      },
      "source": [
        "print(\"MI cluster after sorting - \",sorted_mi_keys)\n",
        "print(\"Relief cluster after sorting - \",sorted_relief_keys)\n",
        "print(\"Chi cluster after sorting - \",sorted_chi_keys)\n",
        "print(\"Pearson cluster after sorting - \",sorted_pc_keys)\n",
        "print(\"Fisher cluster after sorting - \",sorted_fs_keys)\n",
        "print(\"T-Test cluster after sorting - \",sorted_tt_keys)\n",
        "print(\"SNR cluster after sorting - \",sorted_snr_keys)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MI cluster after sorting -  [1318, 1352, 1388, 1193, 1699, 2202, 1371, 950, 1798, 997, 760, 2229, 1083, 1065, 1620, 1750, 1820, 1859, 334, 1856, 878, 644, 1370, 572, 26, 1281, 1020, 611, 936, 1833, 1656, 799, 981, 921, 2165, 797, 1001, 668, 1685, 129, 1285, 1749, 1272, 1159, 1832, 1647, 70, 23, 184, 956, 1112, 477, 1573, 354]\n",
            "Relief cluster after sorting -  [2289, 63, 1953, 1985, 347, 1707, 565, 1833, 286, 1467, 1780, 1726]\n",
            "Chi cluster after sorting -  [782, 845, 254, 1388, 1914, 741, 1954, 1066, 1895, 152, 544, 1707, 565, 936, 2049, 1065, 1979, 1002, 2021, 1021, 950, 335, 347, 570, 150, 969, 671, 871, 535, 1820, 155, 1685, 850, 265, 293, 83, 613, 2134, 1906]\n",
            "Pearson cluster after sorting -  [1388, 544, 1707, 429, 47, 1573, 1833]\n",
            "Fisher cluster after sorting -  [1954, 122, 909, 975, 508, 900, 637, 500, 535]\n",
            "T-Test cluster after sorting -  [1388, 245, 83, 1644, 565, 2137, 1352, 145, 2219, 1840, 830, 1833]\n",
            "SNR cluster after sorting -  [1388, 831, 1954, 1073, 450, 720, 1539, 1619, 76, 519, 291, 48, 12, 1546]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqtp-7IbCWNk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LOOCV=LeaveOneOut()\n",
        "data_KNN=KNeighborsClassifier(n_neighbors= int(feature.shape[0] ** 0.5))\n",
        "data_SVM=SVC(kernel='rbf',gamma='scale')\n",
        "data_NB=GaussianNB()\n",
        "data_Tree= DecisionTreeClassifier()\n",
        "rows=feature.shape[0]\n",
        "classifiers=[\"NB\",\"KNN\",\"Tree\",\"SVM\"]\n",
        "\n",
        "keys_list=[sorted_mi_keys, sorted_relief_keys, sorted_chi_keys, sorted_pc_keys, \n",
        "           sorted_fs_keys, sorted_tt_keys, sorted_snr_keys]\n",
        "cluster_list=[gene_repre_1, gene_repre_2, gene_repre_3, gene_repre_4, \n",
        "              gene_repre_5, gene_repre_6, gene_repre_7]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ft9rtB-BNKc2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "3398b72d-79f9-49a4-be1d-c2b089383702"
      },
      "source": [
        "acc_matrix = pd.DataFrame()\n",
        "for i in range(1,6):\n",
        "  \"\"\"\n",
        "  Make a dataframe out of i keys from each gene_representatives from their \n",
        "  respective sorted keys. \n",
        "  Than use LOOCV to measure accuracy on Train Dataset.\n",
        "  \"\"\"\n",
        "  cluster_df=pd.DataFrame()\n",
        "  s=0\n",
        "  for x in range(len(cluster_list)):\n",
        "    tem_df = cluster_list[x][keys_list[x][:i]]\n",
        "    for x in range(i):\n",
        "      cluster_df[s] = tem_df.iloc[:,x]\n",
        "      s+=1\n",
        "  print(cluster_df.shape)\n",
        "  acc=0\n",
        "  individual_acc = np.zeros(4)\n",
        "  \n",
        "  for train_index,test_index in LOOCV.split(cluster_df):\n",
        "    \"\"\"\n",
        "    Data is divided into train-test splits and then polling method is used \n",
        "    to find the classification results (ensemble of KNN,SVM,NB,Decision Tree)\n",
        "    \"\"\"\n",
        "    train_data,train_labels=cluster_df.iloc[train_index,:],target[train_index]\n",
        "    test_data,test_labels=cluster_df.iloc[test_index,:],target[test_index].values.tolist()[0]\n",
        "    data_KNN.fit(train_data,train_labels)\n",
        "    data_SVM.fit(train_data,train_labels)\n",
        "    data_NB.fit(train_data,train_labels)\n",
        "    data_Tree.fit(train_data,train_labels)\n",
        "\n",
        "    class_list = [data_NB, data_KNN, data_Tree, data_SVM]\n",
        "    results=[]\n",
        "    for x in range(4):\n",
        "      tem_result = class_list[x].predict(test_data)[0]\n",
        "      if tem_result == test_labels:\n",
        "        individual_acc[x]+=1\n",
        "      results.append(tem_result)\n",
        "    polling_result=0\n",
        "    max_freq=0\n",
        "    for x in results:\n",
        "      freq=results.count(x)\n",
        "      if freq>max_freq:\n",
        "        max_freq=freq\n",
        "        polling_result=x\n",
        "    if polling_result == test_labels:\n",
        "      acc+=1\n",
        "  individual_acc = np.round(individual_acc/cluster_df.shape[0],4)\n",
        "  individual_acc = np.append(individual_acc, np.round(acc/cluster_df.shape[0],4))\n",
        "  print(individual_acc)\n",
        "  acc_matrix[i] = individual_acc\n",
        "acc_matrix = acc_matrix.T\n",
        "acc_matrix.columns = classifiers[:]+['Ensemble']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(63, 7)\n",
            "[1. 1. 1. 1. 1.]\n",
            "(63, 14)\n",
            "[1.     1.     0.9841 1.     1.    ]\n",
            "(63, 21)\n",
            "[1.     1.     0.9683 1.     1.    ]\n",
            "(63, 28)\n",
            "[1. 1. 1. 1. 1.]\n",
            "(63, 35)\n",
            "[1.     1.     0.9841 1.     1.    ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_mRSWxQQPqD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "8d041672-bdd9-44a7-bee3-d9a4bd587614"
      },
      "source": [
        "print(acc_matrix)\n",
        "acc_matrix.to_csv(\"%s_p%sAccuracy_Matrix.csv\"%(DATASET, p))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    NB  KNN    Tree  SVM  Ensemble\n",
            "1  1.0  1.0  1.0000  1.0       1.0\n",
            "2  1.0  1.0  0.9841  1.0       1.0\n",
            "3  1.0  1.0  0.9683  1.0       1.0\n",
            "4  1.0  1.0  1.0000  1.0       1.0\n",
            "5  1.0  1.0  0.9841  1.0       1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2XKtNshS_iS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Downloads all the Files generated for this dataset. Please note: The dataset name must be specified in the DATASET \n",
        "variable before proceeding with the steps below.\n",
        "\n",
        "Incase of 'failed to fetch' error, please rerun thiis cell.\n",
        "\"\"\"\n",
        "for x in range(1,4):\n",
        "  files.download(\"%s_p%sRepresentative_Genes_%d.csv\"%(DATASET, p, x))\n",
        "\n",
        "for x in ['mi','chi','relief']:\n",
        "  files.download(\"%s_p%s%s_cluster.json\"%(DATASET, p, x))\n",
        "\n",
        "files.download(\"%s_p%sAccuracy_Matrix.csv\"%(DATASET, p))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-j7hyxWTo6o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#*****************-----Notebook Training Code Ends Here. Below are cells for loading pre-calculated values for Representative Genes and Cluster Sequences.-------*****************************"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzDPRjeJWJ-0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Cell Left Empty Intentionally."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76pXgWiqP7Uo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Loading the JSON files from memory\n",
        "\"\"\"\n",
        "with open(\"%s_mi_cluster.json\"%(DATASET),\"r\") as fp:\n",
        "  mi_cluster=json.load(fp)\n",
        "with open(\"%s_chi_cluster.json\"%(DATASET),\"r\") as fp:\n",
        "  chi_cluster=json.load(fp)\n",
        "with open(\"%s_relief_cluster.json\"%(DATASET),\"r\") as fp:\n",
        "  relief_cluster=json.load(fp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfmCMag6fhUM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Loading Representative Genes from Memory\n",
        "\"\"\"\n",
        "gene_repre_1 = pd.read_csv(\"%s_Representative_Genes_1.csv\"%(DATASET),index_col = None)\n",
        "gene_repre_2 = pd.read_csv(\"%s_Representative_Genes_2.csv\"%(DATASET),index_col = None)\n",
        "gene_repre_3 = pd.read_csv(\"%s_Representative_Genes_3.csv\"%(DATASET),index_col = None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TueHai9eBmLb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_Tree.get_params()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qd9hWyXQbXV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}