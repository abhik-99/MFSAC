{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Univariate Supervised Gene Clustering.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP1rueduIPeWzdf1uZr7KHJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abhik-99/MFSGC/blob/master/Univariate_Supervised_Gene_Clustering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lW6QtcqxDye",
        "colab_type": "text"
      },
      "source": [
        "#Univariate Supervised Gene Clustering\n",
        "**UFSGC** is a method where by a specific filter algorithm is used to score and filter out high ranking genes from Gene Expression Dataset and then the filtered Genes are put through SGC for Gene Augmentation. The resulting Augmentation not only increases the class separability of the genes but also their expressions.\\\n",
        "This Augmented gene expression set is now used for classification of cancer from healthy patients.\\\n",
        "The Filter Methods chosen for evaluation are:- \n",
        "1. Mutual Information.\n",
        "2. ReliefF.\n",
        "3. Chi Sq.\n",
        "4. Fisher Score.\n",
        "5. Signal To Noise Ratio (adapted for multi-class datasets).\n",
        "6. T-Test.\n",
        "7. Pearson Corelation Coefficient.\n",
        "\n",
        "This method is used for evaluation of **MFSGC**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgq-QT-l3LS6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "b895f432-e725-4b1e-cac1-c76d7dcdcb69"
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "!pip install skfeature-chappers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting skfeature-chappers\n",
            "  Downloading https://files.pythonhosted.org/packages/e6/45/19bb801eb3b4a892534ab86468ad0669a68ff63578610f90051190e3622f/skfeature-chappers-1.0.3.tar.gz\n",
            "Building wheels for collected packages: skfeature-chappers\n",
            "  Building wheel for skfeature-chappers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for skfeature-chappers: filename=skfeature_chappers-1.0.3-py2.py3-none-any.whl size=59512 sha256=f6a0228ff6f5ff50dc985361ea3ddc0457665ed85c1a39236f7b77f3743fea87\n",
            "  Stored in directory: /root/.cache/pip/wheels/ac/61/bf/1b3a8c232a0072409508c2ec4c12f316e95681ae72ba7315d2\n",
            "Successfully built skfeature-chappers\n",
            "Installing collected packages: skfeature-chappers\n",
            "Successfully installed skfeature-chappers-1.0.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3I4n8fdw70p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_selection import chi2\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWEU4ygS3PiV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "from google.colab import files\n",
        "\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "#2. Get the file\n",
        "downloaded = drive.CreateFile({'id':'1oaOATE0D_f8MGPIMJOMXYVt0hBUWNCKV'}) # replace the id with id of file you want to access\n",
        "# For Leukemia- 1xcL-LT-E_gUqWLlqqeVJP1DVHHpiAGe_\n",
        "# For Colon - 1AUOto0GhTHW9fX52XSsf9kzYJS5ggv0G\n",
        "# for Prostate - 13Hf7uGbyJ1sWYo8KDRDL8scm-2Fs9_gd\n",
        "# For Lung- 1xuLzTWDGUbr4x3Pq1dnJj08MZqBB5I3U\n",
        "# for Rahc - 1oaOATE0D_f8MGPIMJOMXYVt0hBUWNCKV\n",
        "# for Raoa - 1d2vhPcT3I7ZFcAGOQYVLGB3Jx_vEMata\n",
        "# for Rbreast - 1Vf-h8zfVP_twMXivcJJtbWtjThShUHvn\n",
        "# for SRBCT - 1rO5EEvsoRJl2VVUB3ywKUd3kNiQ24oy3\n",
        "# for MLL - 1rS7x4x_DhrUzaBhrgKMQH3uIaLJdPgW3\n",
        "# for Breast - 1enhhyA4u2ByvOjnF81WoHflVNpXtfKpu\n",
        "downloaded.GetContentFile('data.txt')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NtuVbjd3QZv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "fa3728b7-a3b5-4661-e891-46d781977e83"
      },
      "source": [
        "#DATASET is the name of the dataset being used.\n",
        "DATASET=\"RAHC\"\n",
        "\n",
        "#NEIGHBOURS determines neighbours arg for ReliefF\n",
        "#for any dataset which contains any class sample \n",
        "# <10, make it less than 10. Eg of such dataset - SRBCT\n",
        "NEIGHBOURS = 3 \n",
        "\n",
        "#p is the number of top genes taken after sorting the filter scores\n",
        "p=800\n",
        "\n",
        "#uncomment the line below if using the dataset splitter else leave it commented \n",
        "#data_df = pd.read_csv(\"%s_train.csv\"%(DATASET),index_col=0)\n",
        "\n",
        "#uncomment the lines below if using the original dataset\n",
        "dataset = pd.read_table(\"data.txt\",header=None)\n",
        "data_df = dataset\n",
        "\n",
        "\n",
        "\n",
        "target = data_df.iloc[:,-1]\n",
        "feature = pd.DataFrame(data_df.iloc[:,:-1].values,dtype='float')\n",
        "m,n = feature.shape\n",
        "print(m,n)\n",
        "print(feature.head())\n",
        "print(\"Number of classes - \")\n",
        "classes = np.unique(target)\n",
        "for x in classes:\n",
        "  print(\"Class -\",x,\"Number of Sampples -\", len(np.where(target == x)[0]))\n",
        "\n",
        "feature_norm=pd.DataFrame(MinMaxScaler().fit_transform(feature))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "49 41056\n",
            "     0      1      2       3      4      ...  41051  41052  41053  41054  41055\n",
            "0  0.84300  0.925  0.602  0.1466 -0.827  ...  1.342  0.196 -0.763 -2.223 -0.349\n",
            "1  0.72900  0.569  0.481 -0.2620 -0.666  ...  2.723  0.213  0.132 -2.008 -0.278\n",
            "2  1.93300  0.005  0.636  0.9800 -0.950  ...  2.193 -0.715 -0.258 -2.376 -0.322\n",
            "3  1.52500  1.819  0.899  0.5750 -0.025  ...  1.100  0.094 -0.346 -1.472 -0.288\n",
            "4  0.36836  1.552  1.237  1.7100 -0.215  ...  2.944 -0.014  0.048 -1.213  0.646\n",
            "\n",
            "[5 rows x 41056 columns]\n",
            "Number of classes - \n",
            "Class - 0 Number of Sampples - 34\n",
            "Class - 1 Number of Sampples - 15\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvHtoWSI3jFH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#utility function\n",
        "def plot_feature(feature, target, c = ['r', 'b', 'g', 'y']):\n",
        "  import matplotlib.pyplot as plt\n",
        "  from matplotlib import style\n",
        "  import numpy as np\n",
        "  style.use('ggplot')\n",
        "  for idx, each in enumerate(np.unique(target)):\n",
        "    y = feature[np.where(target == each)[0]]\n",
        "    x = len(y)\n",
        "    plt.scatter(range(1, x+1), y, color = c[idx])\n",
        "    plt.plot(range(1, x+1), y, color = c[idx])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqPoVNzW3oVn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#construction of ReliefF function\n",
        "\n",
        "\"\"\"\n",
        "Given a dataset, number of random instances to pick form the dataset and\n",
        "number of features to consider in each iteration (k), the function returns the weigths of the attributes\n",
        "of the dataset.\n",
        "These weigths can then be used as the final results out of the ReliefF algorithm\n",
        "\n",
        "Paper-\n",
        "\n",
        "Marko Robnik-ˇSikonja and Igor Kononenko. Theoretical and empirical analysis of relieff\n",
        "and rrelieff. Machine learning, 53(1-2):23–69, 2003.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "def hit_miss_calculator(target,instance,k = 10, hit = True, c = None, ):\n",
        "    m=len(target)\n",
        "    upper,lower=instance-1,instance+1\n",
        "    hits=[]\n",
        "    hit_flag=False\n",
        "    #finds k nearest hits\n",
        "    while(not hit_flag):\n",
        "      #print(upper,lower)\n",
        "      if(len(hits)>=k):\n",
        "        hit_flag = True\n",
        "        break\n",
        "      if upper < 0 and lower > m:\n",
        "        hit_flag = True\n",
        "        break\n",
        "      if(upper>=0):\n",
        "        if((target[upper]==target[instance]) and hit):\n",
        "          hits.append(upper)\n",
        "        elif((target[upper]!=target[instance]) and (not hit) and target[upper]==c):\n",
        "          hits.append(upper)\n",
        "        upper-=1          \n",
        "      if(lower<m):\n",
        "        if((target[lower]==target[instance]) and hit):\n",
        "          hits.append(lower)\n",
        "        elif((target[lower]!=target[instance]) and (not hit) and target[lower]==c):\n",
        "          hits.append(lower)\n",
        "        lower+=1\n",
        "    hits.sort()\n",
        "    return hits\n",
        "\n",
        "\n",
        "def reliefF(feature,target,k=10,repetitions=10, seed = 0):\n",
        "  np.random.seed(seed)\n",
        "  if len(feature.shape)>1:\n",
        "    m,n=feature.shape\n",
        "  else:\n",
        "    m=len(feature)\n",
        "    n=1\n",
        "  #print(m,n)\n",
        "  observations=list(range(m))\n",
        "  classes=np.unique(target)\n",
        "  weights=np.zeros(n)\n",
        "  d=(np.max(feature,axis=0)-np.min(feature,axis=0))*m*k\n",
        "\n",
        "  for i in range(repetitions):\n",
        "    instance=np.random.choice(observations,1)[0]\n",
        "    #print(\"Iteration\",i)\n",
        "    #print(instance)\n",
        "    hits=hit_miss_calculator(target,instance,k)\n",
        "    hit_class_prob=len(np.where(target==target[instance])[0])/m\n",
        "    #print(\"\\nHit Probability -\",hit_class_prob)\n",
        "    #print(\"Repetition\",i,\"Class\",target[instance],\"Hits -\",hits)\n",
        "\n",
        "    miss={}\n",
        "    miss_class_prob={}\n",
        "\n",
        "    for each_class in classes:\n",
        "      if(each_class != target[instance]):\n",
        "        miss[each_class]=hit_miss_calculator(target,instance,k,False,each_class)\n",
        "        class_prob=len(np.where(target==each_class)[0])/m\n",
        "        #print(each_class,class_prob)\n",
        "        miss_class_prob[each_class]=hit_class_prob/(1 - (class_prob))\n",
        "\n",
        "    #print(\"Repetition\",i,\"Miss-\",miss,\"Miss Class Probability -\",miss_class_prob)\n",
        "    \n",
        "    for hit in hits:\n",
        "      if len(feature.shape)>1:\n",
        "        weights-=np.subtract(feature.iloc[instance,:],feature.iloc[hit,:])/d\n",
        "      else:\n",
        "        weights-=np.subtract(feature.iloc[instance],feature.iloc[hit])/d\n",
        "    for each_class in miss:\n",
        "      for each_miss in miss[each_class]:\n",
        "        if len(feature.shape)>1:\n",
        "          weights+=(np.subtract(feature.iloc[instance,:],feature.iloc[each_miss,:])/d)*miss_class_prob[each_class]\n",
        "        else:\n",
        "          weights+=(np.subtract(feature.iloc[instance],feature.iloc[each_miss])/d)*miss_class_prob[each_class]\n",
        "    \n",
        "    \n",
        "  return weights.tolist()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qM_OrCSa3ro0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#This function discretizes the given features into 3 categories\n",
        "def discretize_feature(feature):\n",
        "  \n",
        "  mean=np.mean(feature)\n",
        "  std=np.std(feature)\n",
        "  discretized=np.copy(feature)\n",
        "  \n",
        "  discretized[np.where(feature<(mean+std/2)) ,]=2#within 1/2 std div\n",
        "  discretized[np.where(feature>(mean-std/2)),]=2#within 1/2 std div\n",
        "  \n",
        "  discretized[np.where(feature>(mean+std/2)),]=0#greater than half\n",
        "  discretized[np.where(feature<(mean-std/2)),]=1#less than half\n",
        "  \n",
        "  return discretized\n",
        "\n",
        "def Xfreq(x):\n",
        "  xL={}\n",
        "  for e in x:\n",
        "    if e not in xL:\n",
        "      xL[e]=0\n",
        "    else:\n",
        "      xL[e]+=1\n",
        "  for e in xL:\n",
        "    xL[e]/=len(x)\n",
        "  return xL\n",
        "\n",
        "def XYfreq(x,y):\n",
        "  freq={}\n",
        "  \n",
        "  rX=np.unique(x)\n",
        "  rY=np.unique(y)\n",
        "      \n",
        "  for e in rX:\n",
        "    for f in rY:\n",
        "      freq[(e,f)]=round(len(np.where(y[np.where(x==e)[0]]==f)[0])/len(x),4)\n",
        "       \n",
        "  return freq\n",
        "\n",
        "def mutual_info(x,y):\n",
        "\n",
        "  xFreq=Xfreq(x)\n",
        "  yFreq=Xfreq(y)\n",
        "  joint=XYfreq(x,y)\n",
        "  \n",
        "  Xentropy=0\n",
        "  for e in xFreq:\n",
        "    if xFreq[e]!=0:\n",
        "      Xentropy-=xFreq[e]*np.log2(xFreq[e])\n",
        "      \n",
        "  Yentropy=0\n",
        "  for e in yFreq:\n",
        "    if yFreq[e]!=0:\n",
        "      Yentropy-=yFreq[e]*np.log2(yFreq[e])\n",
        "      \n",
        "  jentropy=0\n",
        "  for e in xFreq:\n",
        "    for f in yFreq:\n",
        "      if joint[(e,f)]!=0:\n",
        "        jentropy-=joint[(e,f)]*np.log2(joint[(e,f)])\n",
        "  \n",
        "  return (Xentropy+Yentropy-jentropy)\n",
        "\n",
        "def mutual_info_wrapper(features,target):\n",
        "\n",
        "  mi=np.array([])\n",
        "  for x in features:\n",
        "    discrete=discretize_feature(features[x])\n",
        "    mi=np.append(mi,mutual_info(discrete,target))\n",
        "  return np.array(mi)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1E5U3Fe3uQv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "This cell is used for defining the method for calculating the t-scores\n",
        "\"\"\"\n",
        "\n",
        "def t_test(df,target):\n",
        "  \"\"\"\n",
        "  Input:\n",
        "  df= Dataframe of features (n_samples,n_features)\n",
        "  target= Pandas Series/1D Numpy Array containing the class labels (n_samples)\n",
        "  \n",
        "  Output:\n",
        "  scores= Descendingly Sorted array of features based on t-test \n",
        "  \"\"\"\n",
        "  import numpy as np\n",
        "  from scipy.stats import ttest_ind\n",
        "  scores=ttest_ind(df[:][target==0],df[:][target==1])[0] #Storing just the t-test scores and discarding the p-values from the result.\n",
        "  \n",
        "  # scores=np.argsort(scores,0)\n",
        "  return [scores] if type(scores) != np.ndarray else scores\n",
        "\n",
        "  "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RktVmEeu3w_w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy.sparse import *\n",
        "def fisher_score(X, y):\n",
        "    import numpy as np\n",
        "    \n",
        "    from skfeature.utility.construct_W import construct_W\n",
        "    \"\"\"\n",
        "    This function implements the fisher score feature selection, steps are as follows:\n",
        "    1. Construct the affinity matrix W in fisher score way\n",
        "    2. For the r-th feature, we define fr = X(:,r), D = diag(W*ones), ones = [1,...,1]', L = D - W\n",
        "    3. Let fr_hat = fr - (fr'*D*ones)*ones/(ones'*D*ones)\n",
        "    4. Fisher score for the r-th feature is score = (fr_hat'*D*fr_hat)/(fr_hat'*L*fr_hat)-1\n",
        "\n",
        "    Input\n",
        "    -----\n",
        "    X: {numpy array}, shape (n_samples, n_features)\n",
        "        input data\n",
        "    y: {numpy array}, shape (n_samples,)\n",
        "        input class labels\n",
        "\n",
        "    Output\n",
        "    ------\n",
        "    score: {numpy array}, shape (n_features,)\n",
        "        fisher score for each feature\n",
        "\n",
        "    Reference\n",
        "    ---------\n",
        "    He, Xiaofei et al. \"Laplacian Score for Feature Selection.\" NIPS 2005.\n",
        "    Duda, Richard et al. \"Pattern classification.\" John Wiley & Sons, 2012.\n",
        "    \"\"\"\n",
        "\n",
        "    # Construct weight matrix W in a fisherScore way\n",
        "    kwargs = {\"neighbor_mode\": \"supervised\", \"fisher_score\": True, 'y': y}\n",
        "    W = construct_W(X, **kwargs)\n",
        "\n",
        "    # build the diagonal D matrix from affinity matrix W\n",
        "    D = np.array(W.sum(axis=1))\n",
        "    L = W\n",
        "    tmp = np.dot(np.transpose(D), X)\n",
        "    D = diags(np.transpose(D), [0])\n",
        "    Xt = np.transpose(X)\n",
        "    t1 = np.transpose(np.dot(Xt, D.todense()))\n",
        "    t2 = np.transpose(np.dot(Xt, L.todense()))\n",
        "    # compute the numerator of Lr\n",
        "    D_prime = np.sum(np.multiply(t1, X), 0) - np.multiply(tmp, tmp)/D.sum()\n",
        "    # compute the denominator of Lr\n",
        "    L_prime = np.sum(np.multiply(t2, X), 0) - np.multiply(tmp, tmp)/D.sum()\n",
        "    # avoid the denominator of Lr to be 0\n",
        "    D_prime[D_prime < 1e-12] = 10000\n",
        "    lap_score = 1 - np.array(np.multiply(L_prime, 1/D_prime))[0, :]\n",
        "\n",
        "    # compute fisher score from laplacian score, where fisher_score = 1/lap_score - 1\n",
        "    score = 1.0/lap_score - 1\n",
        "    return np.transpose(score)\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acdy9Tp_3zzJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#Pearson corelation\n",
        "def pearson_corr(feature,targetClass):\n",
        "  import numpy as np\n",
        "  coef=[np.abs(np.corrcoef(feature[i].values,targetClass)[0,1]) for i in feature.columns]\n",
        "  # range(feature.shape[1])\n",
        "  coef=[0 if np.isnan(i) else i for i in coef]\n",
        "  return coef\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61xH6L8j32If",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#signal to noise ratio\n",
        "#using weighted one-vs-all strategy for multi-class data\n",
        "def signaltonoise(feature, target, axis = 0, ddof = 0):\n",
        "  import numpy as np\n",
        "  classes = np.unique(target)\n",
        "  if len(feature.shape)<2:\n",
        "    feature = feature.reshape(-1,1)\n",
        "  row, _ = feature.shape\n",
        "  if len(classes) <= 2:\n",
        "    m = None\n",
        "    std = 0\n",
        "    for each in classes:\n",
        "      idx = np.where(target == each)[0]\n",
        "      #convinient way of doing m1-m2\n",
        "      if m is None:\n",
        "        m = feature.iloc[idx, :].mean(axis)\n",
        "      else:\n",
        "        m -= feature.iloc[idx, :].mean(axis)\n",
        "\n",
        "      #sd1+sd2\n",
        "      std += feature.iloc[idx, :].std(axis = axis, ddof = ddof)\n",
        "\n",
        "    return np.asanyarray(m/std)\n",
        "\n",
        "  else:\n",
        "    snr_scores = [] #for storing the weighted scores\n",
        "    #using the one vs all strategy for each class with\n",
        "    for each in classes:\n",
        "      idx = np.where(target == each)[0]\n",
        "      idxn = np.where(target != each)[0]\n",
        "      m = feature.iloc[idx, :].mean(axis) - feature.iloc[idxn, :].mean(axis)\n",
        "      std = feature.iloc[idx, :].std(axis = axis, ddof = ddof) + feature.iloc[idxn, :].std(axis = axis, ddof = ddof) \n",
        "      snr_scores.append((m/std) * len(idx)/row) #weighted snr\n",
        "\n",
        "    return np.asanyarray(snr_scores).sum(axis = axis)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7K7udgd35rE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def feature_ranking(score):\n",
        "    \"\"\"\n",
        "    Rank features in descending order according to fisher score, the larger the fisher score, the more important the\n",
        "    feature is\n",
        "    \"\"\"\n",
        "    idx = np.argsort(score, 0)\n",
        "    return idx[::-1]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FTz7uo23782",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "relief_score=reliefF(feature,target,NEIGHBOURS)\n",
        "\n",
        "mutual_inf=mutual_info_wrapper(feature,target)\n",
        "\n",
        "mms=MinMaxScaler()\n",
        "nfeature=mms.fit_transform(feature)\n",
        "chi_score,p_val=chi2(nfeature,target)\n",
        "\n",
        "p_corr = pearson_corr(feature, target)\n",
        "\n",
        "f_score = fisher_score(feature.values, target)\n",
        "\n",
        "tt_score = t_test(feature, target)\n",
        "\n",
        "snr_score = signaltonoise(feature, target)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ekDpdoJ4CZG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#The Features are sorted as per their scores\n",
        "sorted_relief = feature_ranking(relief_score)[:p]\n",
        "sorted_mi = feature_ranking(mutual_inf)[:p]\n",
        "sorted_chi = feature_ranking(chi_score)[:p]\n",
        "sorted_pc = feature_ranking(p_corr)[:p]\n",
        "sorted_fs = feature_ranking(f_score)[:p]\n",
        "sorted_tt = feature_ranking(tt_score)[:p]\n",
        "sorted_snr = feature_ranking(snr_score)[:p]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kk1j5t3i4FG_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "848885b9-782a-4888-a0cb-30c638220fc8"
      },
      "source": [
        "#Can Skip this Cell\n",
        "\n",
        "print(\"Features after sorting -\")\n",
        "print(\"\\nSorted MI -\",sorted_mi)\n",
        "print(\"\\nSorted Relief -\",sorted_relief)\n",
        "print(\"\\nSorted Chi -\",sorted_chi)\n",
        "print(\"\\nSorted Pearson Corr -\",sorted_pc)\n",
        "print(\"\\nSorted Fisher Score -\",sorted_fs)\n",
        "print(\"\\nSorted T-test -\",sorted_tt)\n",
        "print(\"\\nSorted SNR - \", sorted_snr)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Features after sorting -\n",
            "\n",
            "Sorted MI - [30281  4363 29141  9389 37463 32392 13914 30726 26339 38514  2415 37915\n",
            " 24926 24779 30853  1857 31676  4286 18189 39599 16488 12514 12563 31856\n",
            " 24211 11946  1342 21019 40435  6587 34674 34661 19234 31059  5203 28818\n",
            " 25710 39774 39754 30769 21834 19262  1584 36138 15186 28673 20211 32340\n",
            "  4084 21088 23949 27166 21280 11557 15969 25415   794 27637 37862 28495\n",
            "  4309  1856 16079 35279  9417 30705 32861 21009 39725 39651  7712  6302\n",
            " 10481 16564 10741 33908 15648 30753 37716 16335 19076 10376 26958  3527\n",
            "  4357 15907 15152  4287 17304 22706 12214 14659 18279 13311 31976  2690\n",
            " 21243 29885  5966  9114 34199 16261 18263 25227 27947 18145  2323 33043\n",
            " 12255 26319 21066 35309 38181 19705  1068 36968  7232 29086  7747 27540\n",
            " 15839  5562 13504 38671  5323 12153 40012 40458 39692 40413 40420 39370\n",
            " 37354 14683 39172 29829   386  1210 28326 27952 18450 36597 35640 38756\n",
            " 26787 32470 27650 31606  7862 27470 24519  7106 17509 20678   981  3155\n",
            " 26778 35987  4342 16616 18561 36286  1113 26477 18566 26626  4305  2759\n",
            " 18775     4 21773 29913   936 12796  5184 37917 26886 35386 17649 23509\n",
            " 12330 26243  2127 34157 36777 22107 19109 39127 17275  3648 39879 40246\n",
            " 39723 11011  3362 22240 31377  1801 15957 39133 33307  8601 23736 38829\n",
            "   741 29110  5166 40409 40675 17564  6497 16154 32817  8197 25321 32852\n",
            " 27161 15730 26469 34104 19361 31738 28877 26944 32900  4507  8748 23464\n",
            " 10133 15225 33544 21308 19977 17898 34590 23064  8846 39146 11811 25875\n",
            " 38151 27545 18120 20334 10614 21288 14266  7136 12612  9884 22957 21757\n",
            " 28675 32820 20151 38117 31251 34903 13045 19236 32534 34226  8359 34491\n",
            "   967  6363 30254 20499  4657 38106 32734   754 37536 34602 25170  4725\n",
            "  2918 12363 17610  4986  6035 31749 29559 26881  1632 40703 40714 39775\n",
            " 39917  1376 33457 36992 28699 37890 16641 33635 10328  2995 25624 18010\n",
            " 26010  1815 21237 21366 30944 26707 22732 17083  4861 15528 23346 18991\n",
            " 33334 18072 39277  6190  9997 15136 38763   893 17730 28447  3452 11223\n",
            " 17030 37089  6912 11344 17641 36341 37307 25492 26890  1433 10067  9458\n",
            " 24682 12354 17217   705  8500 34492  8360 18372 15191  7893  8021 27541\n",
            " 24045 30520 33237  3638 38519  8094   632 29920 13858 24055 38874 20758\n",
            "  4606 24399 29456 35800 18216 29856 35461  6561 18051 25711 19975 32605\n",
            " 27771 30150 32108 26473 19874 21753 32482 31637  6184 23817 17976  2911\n",
            " 19658 33148 10697 22867 24254  5583 30675  4626  1516 38716 20827 12626\n",
            "  5997 22249 31544 39052  3717 32932 34971 13043 12907 26302 19355 18592\n",
            " 32079 21688 32877 25962 36480 31163 14380  9374 17732  2502 24395  3658\n",
            " 34234 36816  5492 22057  1131 25815  6109 25138 28120   979 33190 25092\n",
            " 37882 22175  7531 16898 31831 15193  2426 39731 27417 17074 36930 40716\n",
            " 17755  7993 34018  9228 35827 21932 39770  3890 31535 26456 17740 10595\n",
            " 33217 27847  1009  7159 25686 34803 13381  3024 29178 26763 23313 26706\n",
            " 13923  6718 18749 30691  5074 10783 40463 40421 39953 39714 14558 11104\n",
            " 16697 36070 21146 30172 26342  2562 20648 29119 30206 22320 24446 29025\n",
            " 27809  9601 11357  9756 13741 24155 37997 34528   157 20455 27372 30171\n",
            " 10522  5281 38988  9297 31640  3623 15326 27938 10353 26675 15695 28501\n",
            " 18846 24596 20363 33326 27281 38517 27628 29929 38835 27803 30793  3614\n",
            " 26899 22539 38603  8723 12645 27423 33841 25821 31790 30893 16513 26258\n",
            "  7732  7807 16226 16961 26478  1377 37010  6095 25795  5204  7634 40361\n",
            " 33056 14979 13416 33552  5061 13147  8319 16579  9669  9315   868  6911\n",
            " 12894  7167 27838 17200  3914 36247 11340 10364 18760 11339 25606 33990\n",
            " 25669 28052 27226 26461  9122 20958 30941 34279 24844 16426   867  5124\n",
            " 31348 31245 18491 32218 23738  1002  9028 17075   840 30613    60 16291\n",
            " 12067 12966 20454 37088 25784 14508 27182  5220  6005 31208  7830  2751\n",
            " 22066 36629 39232  9847  4692 26726  4519  5158  6084 34683 21113 17673\n",
            "  3252 24095  7703 11841 14079 37118 22314 22312 19286 32949 12101  1582\n",
            " 36484 25005 22951 35481  8328 35524 39867 40812 39726 11184  1611 33042\n",
            " 37603 23322   711  1204 16991 21842  5563 33083 25050 36041  8086 14419\n",
            " 13105 15166 35419 26705  5925 26715 17252   962 35233 31774   133 25082\n",
            " 13601  5087 24761 17283  7706 35799 28640 13557 37522  8724 39798 40111\n",
            " 39887 11343  3460 22887 23039 26727  5498 38203 15039 37075 12753 13400\n",
            " 11900  1018  3349 35379 24452 33251 15229  6338 24843  4325 18021  3953\n",
            " 26785 32506 26982 34131 16237 34413 23467  9372 24797 14212 37829 21765\n",
            "  7188 24507  1728  4813 29706 27925 12703 38435 15041  8464  7163 26937\n",
            " 38296 11018 11372 34930 17167 23492  5371 35577 31016  6962 26476  7116\n",
            " 33362 26771 35545  9022 33315 25878 32001 34539 27375 15622 22402 15869\n",
            " 33185 14213  6245 20967  6004  6589 30852 29956  2067 31115 37176 12030\n",
            "  8848 37830 18352 18374  4484 35723 38759 31737 15944 15185 19282 17567\n",
            " 33261  9812 21539  9125 32838 14891 31144 27030  6030 27396 31290 17149\n",
            "  7989 37327 26463  8697  2564  7415  2152 37526]\n",
            "\n",
            "Sorted Relief - [39638 24349 39562  2630  5335 18123 34270 27546  8186 37758 39648 39924\n",
            " 24270  2077  6401  7858  6492 37678 10705 39639 30314 36161  1854 40483\n",
            "  4824 40550  1063  5326 32599  7965  1895  2830 27636 20383 39884  2687\n",
            " 19304 33593 19365 40723  6021 18121 13403 40202 15879 27493 22063 40399\n",
            " 17445 17033  3748 33901 16532  4655 20015  1883 24413 22650 27376 13441\n",
            " 24295 27433 17735  4103 28895 27404 22662  5270 20173 38549  2998 23493\n",
            "  2832 31563 13390 10417 39596  7808  3945 28101 40297 12195 24622 30280\n",
            " 10874 14131 36181 26801 29347 32440 31868  5415 30955 38779 24355  2016\n",
            " 20152 28971  5028  2160  2861 20499 39793 39711 23656 10121 40692 29810\n",
            " 26644  3713  6961 31532 27365 10415  9565 18365  3683 24369 40424  2042\n",
            "  8783  2045 12734  4738 36233 20205 39422 15228 29958 39696 35028 33600\n",
            "  7335  3672 35723 28994  8436  6490 25808 36639  6344 11890 17782 25324\n",
            " 10038 12610 28169  2922 21706 40612   377  4708 40530 17562 19367 40435\n",
            " 40231  8702 25078  3586  6388 21810 21124 11053  6224 19104  2903 13584\n",
            " 14281 16911 14847  7225 14127 36275 39836 23497 20975 40538  2666 14333\n",
            "  1735  3836  5420  2900 24320 20298 15857 12451  3527 27213 17557 22568\n",
            " 13252 30851 17876  7085 16958 35936 37636 37829 11052  6282  9434 10522\n",
            " 40484 25839  3365 24582   347 38016 31546 15129 39704 17080 40490 33560\n",
            " 24559 29817  1237 19452 39876  1802 20224  8688 39885 20179  7057 18601\n",
            " 19497 31456 32853 15702 39750 21102 10299 40349 26789 12502  7549 38592\n",
            " 39700  1224 37118  1234 30281 39548  2038 29999 40221 27604 38530 13332\n",
            " 11708  5299  4749 26722  3540 34117 30131 17739 10675 20067 25779  6302\n",
            " 37577 28301 31032 28148 32939 15734 22617 35863 36944 22789  1981 28253\n",
            " 34392  1024  2765 40553 34399 14987 26882 25710 31078 29095 17850 13068\n",
            " 40267 40465 38652 36001 18555 40316 40470 22012 33316 12181 18563 19660\n",
            " 17761 35873 40354 25828   160 36768 29984  2056 22894 18241 31394  7867\n",
            " 37634 21992  6494 20137  5292 17713 13562 24609 29118  2705  5497 28814\n",
            " 31981  7209 14797 21077 39616 25315 24353 39680 38825 26364  3684 38052\n",
            " 38834 24447   287   167 25875 17714 26480 39667  5155 38514  5538 17002\n",
            "  6868  7704 21325  2317 38859 16858  2019 18596  7243 31719  5542 39756\n",
            " 34430 21120  3070 14374 15229 20151  6288 39581 37940 33518 24936 29606\n",
            " 39658 10523 23637  8985  2707  4797  4409 29854 21644 12566  1896 21107\n",
            " 40178 39778 22492 38460   333  2858 36710 16706 19125 28995 40655 22644\n",
            " 39770  6398  1201 24454  2164 36319 28958  8464 20323 23459  8364  4537\n",
            "  4649  7097 27810 36931 20221 16306  1678 31081 40227 15884    18 22503\n",
            " 31889 27309 27461 24351 40416 38014 15743 13022 16994  1221 39201 36796\n",
            "  4605 17679 39538 33182   416  2918 36508 39693 18695 17070  7955 23370\n",
            " 27579 15853  4653 21058 34999 26791  2760  3543 20460  2075 29091  2043\n",
            " 39637 40278  8678 20874 33775  1180 37996 40421 21164 25712 27278 27450\n",
            "  3703 22935 30245 39327 25751 32528   236 38311  2079 24501  6256 34266\n",
            "  5555 20212 17709 20363 21766 24405 21021 40548 14791 21705 27596 20737\n",
            " 28891 20926    19  6866  7887 15092 16661 20831 13306 27854 12054 22001\n",
            " 18426 37776 27468  6274 20522 29136 29035  2706  4513 34343  1763 12623\n",
            "  3920  6893 18844 29092  3504 21979   219 11891 36954 37306 40498 18477\n",
            " 29094  4482  5276 22182 28980 20320 31806  7169 25093 18291 18521 32779\n",
            " 22725 15297  6325 15999  3695 22552 13492 21047 40423 17834 40618 10842\n",
            " 32527 24921 13495 18708  5221 14882 19235  2390 21080  2603 33830 26928\n",
            " 30306 33171 40499  2044 22144  9032 13400 14237  1021 21363 38579 38020\n",
            " 30670 26818 39781 21022 12359    51 17644  7872  9709 25673 38650 13998\n",
            "  7051 34515  4692 23021 33662 36277 38783  4869 20372 37878 16057 23440\n",
            " 20953 12492 14297 36677 25151 26680 22857  7096  4696 32401 24851 27540\n",
            " 40263 11899 20172 20149 13469 39474  7338 15040  8559 28386  2632 16938\n",
            " 28648 18160 14508 18803 39934 39767 20266 36164 28774 18925  9330 36818\n",
            "  9591 22692 14204 15828 29014 15791  9550 23496 24350 40690 33290 38952\n",
            " 23489  3906 35091  1090 40204 27311  3681 11866 32575 15045 14215  7538\n",
            "  4516 21099 17374  7703 22721 20384 18869   118 21081 40694 17781 24407\n",
            " 20254 28704  7920 40816  9811  1741 14217 17602 14238 18943  7160  8830\n",
            " 27214 11699 21686 25225 12393  1439 16067 32494 10337 13098  1743 26002\n",
            " 16142 21352 39789 23797 15037 13411 29416 12283 35507 11959 21037 37925\n",
            " 22759 15138 13151 13891 24418 25797 36929 18510  8825 10769  2926 12192\n",
            " 25046 36371 34901 23477 24052  5311 25709 31033 16937  1962 37070  7908\n",
            " 31936 18321 39514  2972 16818 25183  7310 13748 14639 10712 34294  1907\n",
            " 40531 20978 29701 15978 17929 40605 30017 25282 40228 19166 24867 35967\n",
            "   147 34963 27390 36112 13444 25762 29895  3667 19392  8868 23748 14029\n",
            "  7199  1845 27317  7406 38012 15629 40721 30669 21833  2719 12282 19689\n",
            "  7267  2914 33468 19866 40440 11686   128 40675  4566 39926 15764  8685\n",
            " 15249 11696  7488 21172 31155 40104 34350  5240]\n",
            "\n",
            "Sorted Chi - [40335 39950 40256 40171 39500 39602 39747 19262 40195 40356 40172  6184\n",
            " 39561 40303 18140  6940 39788 40364 40192 40326 40532 39534  8824 40198\n",
            " 40043 40634 40268 39743 19160 23482 22765 40395 40365 40560 39643  4287\n",
            " 39511 39729 33470 10543 17342 39604 39654 14855 40212 10353 25633 39571\n",
            " 16504  1377 24340 35518 40270 40428 40217 41044 13128 17366  6005 16644\n",
            " 17739 35133 17433 40507 39528 40929  2152 39860 40445 18588 13232 14727\n",
            " 40269  7111 39668  4363  9605 29699 19234 11369 26536 40187  9458 35987\n",
            " 15625 15755 23394  7821 30944 40598 40438 39618 39734 12035 34653  9417\n",
            " 40586 26477  5309  4476 40574 40464 39727 18292 26726 17466 26730 15839\n",
            "  7087 35069  6092  7284 39634 29975 39541 10621 35039 24125 26508 31738\n",
            "  3595 11512 39888 39785 40223 12154  6998 25617 20059 11557 15944 20903\n",
            " 24964 39613 40549 31606 15651  4497 40150 36739 12514 16226  4393 32001\n",
            " 22645 30735 39831 24443 39249 40298 27246 40940 39803 12152 39656 15869\n",
            " 18257 19843 15737  8672 27952 27233  8861 40317  6937 40779  4817  5596\n",
            " 41040 13362 18044 14056 19267  4874  5657 27300  8808 40869 24287  5167\n",
            "  9580 33326 39689 28176  7033 10347 31091  1113  6311 28447 12153 14760\n",
            " 23039 33298 41051  9678 11909  7415 25707  5886 15635 14149  5507  8789\n",
            " 34695 33294 40786 16697 33308 13979  3733 15640 40730 27256 25596 11414\n",
            "  2415 27900 18991 18907 24979 40253  5108 38013 20791 19641 19432 39636\n",
            "  3648  6960 10697 34674  4805 11302 31377  3636   170 18366 26660 27718\n",
            " 39497 40306 29784  9065 15730 23393 23346 40639 11385 33465  1798  6958\n",
            " 40799 18416 32817 17367 40038 25764 27399 18148 24926  6994 40243 39629\n",
            " 33247  6936  5892  8359 22126 16643 27281 16240 27395   426 18316 30746\n",
            " 18980  5112 32351 32495 32812 15663  5198 23464 16584  1206 19888 40149\n",
            "  6796 40606 26881 30693 24162  7672 30647 14893 33248 39941 24275 22484\n",
            " 24245 21734 20391 40173 13364 40059 30843  2215 24179  1888 16846 20742\n",
            " 25027 21642 15728 19664 27889 34482 34256  8810 17462 25781 20467 30212\n",
            "  2602 16377  6308 40426 39919 29860 30343 28199 23914  7073  5312 30766\n",
            " 12430 35127 26274 41027 29065 33478 21827 10287 19643  7969 40166 27500\n",
            " 15215 16679 40473 27545 20026 19153  8690 17801 27388 17610 25163 32533\n",
            "  5536  9190 35065  6154  1801 19433 16272 24116 29785  7146  6180 17691\n",
            " 40701 33576 17523 40715  5941  3032  4369 30692  6104  1037 14101 24446\n",
            " 36865 18592 14658 17429 20335 20226 32782 26116 19155  6381 27947  1112\n",
            "  1103 24157 13886 37916 34489 24924 21953   453 23391 14777  8747 14890\n",
            "  5272 37608  5034 35855 24253 20896 40691 39358 33518 13917 23187 35001\n",
            " 21524  5433 27394 37704 14954 26613 28326  5887  9746  5114 40409 24335\n",
            " 12354 14676 12431 40239  6100 29137 33232  3481  3469 40812  7114 39877\n",
            "  4325 30179  2690 23517 17439  4672  7062 15186  9197  8496 36047 12151\n",
            " 31708 34116  9021 15668 11328 21044  7387  8774 36484 13914 18517  1582\n",
            " 40435 11679 36968 11371 23885  8755 34196  1749 19691 13036  6127  3656\n",
            " 31676 31699 39403 37151 28306 26628 14033 40046 20628  6211 12249 24161\n",
            " 10805  9696 32797 29003  7070 26784 11129 22983 15632 10021 22978 12755\n",
            " 37842 36159  2179 13258 26944 31863  8709 36286   438 28110 19528 40174\n",
            "  5236 20813 18081  6849  1856 12346 37667 40665  1722 34175 34641  2390\n",
            " 15436 31629  8088 28850 11612 16645  7843 20010 11843 14826  7828  3707\n",
            " 35948 21184 39640 21809 10437 19226 19236  1827   335 34275 33464 35841\n",
            " 22670 11758 21753  4448 22583 23212 15735 11505 29090 31678  8912  8815\n",
            " 24802 39694   839 37908  2689 24573  8516 37088 17759 13858 27539 19198\n",
            "  7749 13887  3582  1857 23275 21777 29819 25021 40280 34135 19688 11007\n",
            " 20099  5919 10677 16950 23353  6884  8806 34619 37385  3507 32366  9258\n",
            " 22616 27295 38463 14778  4330 29054 22478 33513 25738  1881 14683 16407\n",
            " 29456  1790 11107 10714 40400 14877  2902 39362 37614  7064  2995 36251\n",
            " 12986 27084 13207 11361 23417 36946 31045 17711 26227 19950 27541 40184\n",
            " 11496 16007 28305 25201 26647 40488 40519  8373 34049  1433 37702  4610\n",
            " 17404  7863 34139 29787 14831 18011 24250 28645 37174  3037 24103 37632\n",
            " 20192 37631 24731  2865 27488 20113 38119  5197  1014 24043  5286 11570\n",
            " 13100 31089  4718 18468 11258 13086 12185 35366 21621 12297 38879  9228\n",
            " 32364 23122 28924 29005  5432  4606  3526  3953 35311  8477 38139  3503\n",
            " 14093   237 13045 10428  6333  9475 14213 36232 31057  1020 30926  4340\n",
            " 14821  4671 30841 30306 28137 39470 39318 21776  7765  4146 10633 10481\n",
            "  7256  7318 20739 20166 30995 21786  7741 13479  2943 10660 27252 16525\n",
            "  4309  6233 12363 12543 34274  5277 30757  2300 21622  6312  4391 18464\n",
            " 29907 16881 35047 26637 40716 16719  3483  4367 36123  7413  6465 18450\n",
            "  5301 10454 35067 39770 26742 29758 30788  5631 28495 19702 20634 21775\n",
            " 35176 14783  5478 10695 35138 29825 40480 27485 34174  8807 13044  1769\n",
            "   890 30846  1003 29002 33319 40489 40167  1170 17373  9600 32470 23954\n",
            " 19934 27746 14920 11364  1449  2286  5491 25843]\n",
            "\n",
            "Sorted Pearson Corr - [ 4363  2415 29141  1857 12514 40435 17976 10697 31676  6302 19262 40675\n",
            " 12354 13914 35309 39770 39774 39754 39651 22887 40413 14658 34674  1172\n",
            " 39599   741 27281  9458 27650 40278 23885 18189  6184 31606 14903 39867\n",
            "  1377 39528  7291 33148 37862  8197 13504 23187  9417 39597  4287 40409\n",
            " 18145 29456 21019 14683 15907 39249 40458  3648 34175 39887 32838 30206\n",
            " 40734   219 10695  5241 35987  4325  3966 24596 31377 15186 12074 40510\n",
            " 40708 12154 26778 39648 12153 18292 23346  4861 35069 33576 40385 30254\n",
            "  3733 33043 29950 40806 35279 20791 23512 33326 32817 39513 35518 35827\n",
            "  9228 27545 22489  6587  4309 17610 27295 39612 19234 40467 22645 40715\n",
            " 30769 39601 40702  8027 10522  1801 39726 40420 38378 31059 39860  2323\n",
            "  9389 12151 18450  1342 39775 40441 23464 39865 26339  6095 40231 19977\n",
            "  2903  1229 11562 39769 14855 22867 27267 33518 40393 40812 14826 40970\n",
            "  1769  1113 26944  7810  6005 35176 21263  1888 31107 31610 35841 12986\n",
            " 26477  7706 26726 25707 16697 27900 28293  9678  8500 26476 39559 36968\n",
            " 39533 40713  7856 40167 37925 39919  1376  1037 25699 15682 39723   546\n",
            " 38575 39500 32364  3921 39725  7380 40436 21753 10481 40111 39667 40102\n",
            " 27372 23212 39798 26647 39714 15944 27541 39876 37769 25094 16815 40318\n",
            " 39534 11505 20363 40565 37151 25617 40162 32533 39858 39941 28326 25074\n",
            " 19888  1722 12284 17283 27399 39560  5892  6994 10783 25533 13918 40537\n",
            " 31678 24926 27947 14831 35292 11355 16240 31863 31738 36041  2269 28305\n",
            " 35067 37865 32782   794  9190  1230 39917 32258 40743 40390 40703 18179\n",
            "  7749 39843 34761  4672 30623 22565  8021 15084  2894 16950 37088 39470\n",
            " 19658 24443 23638  7739 11557  5249  7312 13043 27229 15728 22320 38618\n",
            " 14979 34275 25428  9197 37216 40246 16504 36673 10347   386 36739 29975\n",
            " 37828 40822 33225  7064 39731  4103 15191 21775 39684  8861 34140 20872\n",
            "  5507 36410 40716 27636 17382  9756  4146 22670 32152  8491 20335 40539\n",
            "  6911  4342  2390 12546  1856 28495 32797 26138 18991 16919 25841  5061\n",
            " 30787  7367 29555 15648 10428 23064 24052 33470 18051 28306 30343  8359\n",
            " 19843 11107 36246  8672  4986 17801 13588 18142  5167 26958  2995 39979\n",
            " 38516  5301 12969 33316   157 35800 26573 11414 38835  3656 11011 21237\n",
            " 17496 14033  5631 23122  2100 39953 15623  7353 30150 39645 15674 27030\n",
            "  3801 40335  2770  2152 38514 18374 26784 16644 31551 17732 19125 17564\n",
            "  8824 12431 39682 22765 39854 40340 40905 40463 23156 37174 40421 30944\n",
            " 40119  7136  6224   335  8789 39639 12888 23954  6269 28649 17265 35278\n",
            " 25958 15869 39773 32470 31760 24915 38417 20904 20010 38519  9612 29886\n",
            " 17293 11681 27952 39906 19818 39685  1663 30788 37639   378  5596 14891\n",
            " 29319 36816 18757 17711 20455 12200 26626 16128  5166 30580 40361  2690\n",
            " 24562 40449 23482   893 25227 26274 13068 14920 39955 20903 19202 24303\n",
            " 33294  6311 12782 30813 40488 40704 35142  3555  9475 19236 13447  4220\n",
            " 25315  5657 15327  4497  3694 32605 38303 36835 40971 18169 40045 38517\n",
            " 13238 24155 38763 38129  9199 19641 37327 25711 27485 40041 17144 24537\n",
            " 20678 26394  5497  6940 17739 40160 15969  3215 26125   839 36809 18372\n",
            " 10714  5236 36484 20391 23014 15839  4610 29329 24834 17864 40365 36865\n",
            "  4626 31091 22583 34903  3226 17342  4369 34174  8964 39879 10353 37890\n",
            " 32534  1054 13343   453  4386 39856  1210 17433 27579  4164  6100 22227\n",
            " 29474 20099  6796 30117   237 19950 14266  4606 37051 26787 11340 35672\n",
            "  1991 39792  6210 20737 14890 29137 17759 38083 12693  4416 36608  5158\n",
            "  9605 22732  8714 26536  9580 12283 20121 40012 33465 38358 26650  9395\n",
            " 32812  2602 40693 19432  2934 24335 13044 40714 27041 16335 36726 26316\n",
            " 25863 29701 40015 28176 19801  5112 30029 34971 10461 40256  1090 35038\n",
            " 17444 15179 25345 33315 27557   488 26135  2562 14632 29108 17843 23396\n",
            "  6850 39358  4982 23288 18216 24178   987 20882 18588 25669 11570 18140\n",
            " 33524  2777 29168 32572 35327  7426 36251  6561  3595 40720  7767 34429\n",
            " 21538 40476 18980 13954 40960 15447 23039 40584 21827  1002  5886  5114\n",
            " 14769 11226 33708 11178 10712 40952 39634 27394 27495 15757 40243 27395\n",
            "  8299 30941 12297 33489 24779 21834 33455  8360 10290 11970 19160 10690\n",
            " 27717 23817 40623 30179 36028 20588  3924 15039 18697 30739 39950 25005\n",
            " 33308  4367 21288 40598 21878 36970 34934  5245 34864  5048 19045 19341\n",
            " 34913 26502 16564 16826 32336  1487  6122 29172 13128 40306 33295 40604\n",
            "  2286  5919 28447 37692 34482 40171 30693 24964 24043 27300   132 26457\n",
            " 17995 38125 40302  2186  3378 27375 12150  6936 17066 21072  3146 39603\n",
            "  7256 14101 19285  1011   446 15638 36946 21777  3526 34196 23353 13104\n",
            " 29784  6279 19689 37297  7012 17426  8849 36286 11678 16368  7033  9406\n",
            " 40538  7052 36969 13858 22440  6937  7142 20496 40730 20896 30281 25624\n",
            " 40999 26639 18226 34695  5475 34398 24275 15792 33635 24704 34842 31625\n",
            " 16426  1725 12242 27488 20628 36629 18681 40046 26881 18592 34396  2581\n",
            " 26742 32861 29920 40170  7827 11913 18517  4286]\n",
            "\n",
            "Sorted Fisher Score - [ 4363  2415 29141  1857 12514 40435 17976 10697 31676  6302 19262 40675\n",
            " 12354 13914 35309 39770 39774 39754 39651 22887 40413 14658 34674  1172\n",
            " 39599   741 27281  9458 27650 40278 23885 18189  6184 31606 14903 39867\n",
            "  1377 39528  7291 33148 37862  8197 13504 23187  9417 39597  4287 40409\n",
            " 18145 29456 21019 14683 15907 39249 40458  3648 34175 39887 32838 30206\n",
            " 40734   219 10695  5241 35987  4325  3966 24596 31377 15186 12074 40510\n",
            " 40708 12154 26778 39648 12153 18292 23346  4861 35069 33576 40385 30254\n",
            "  3733 33043 29950 40806 35279 20791 23512 33326 32817 39513 35518 35827\n",
            "  9228 27545 22489  6587  4309 17610 27295 39612 19234 40467 22645 40715\n",
            " 30769 39601 40702  8027 10522  1801 39726 40420 38378 31059 39860  2323\n",
            "  9389 12151 18450  1342 39775 40441 23464 39865 26339  6095 40231 19977\n",
            "  2903  1229 11562 39769 14855 22867 27267 33518 40393 40812 14826 40970\n",
            "  1769  1113 26944  7810  6005 35176 21263  1888 31107 31610 35841 12986\n",
            " 26477  7706 26726 25707 16697 27900 28293  9678  8500 26476 39559 36968\n",
            " 39533 40713  7856 40167 37925 39919  1376  1037 25699 15682 39723   546\n",
            " 38575 39500 32364  3921 39725  7380 40436 21753 10481 40111 39667 40102\n",
            " 27372 23212 39798 26647 39714 15944 27541 39876 37769 25094 16815 40318\n",
            " 39534 11505 20363 40565 37151 25617 40162 32533 39858 39941 28326 25074\n",
            " 19888  1722 12284 17283 27399 39560  5892  6994 10783 25533 13918 40537\n",
            " 31678 24926 27947 14831 35292 11355 16240 31863 31738 36041  2269 28305\n",
            " 35067 37865 32782   794  9190  1230 39917 32258 40743 40390 40703 18179\n",
            "  7749 39843 34761  4672 30623 22565  8021 15084  2894 16950 37088 39470\n",
            " 19658 24443 23638  7739 11557  5249  7312 13043 27229 15728 22320 38618\n",
            " 14979 34275 25428  9197 37216 40246 16504 36673 10347   386 36739 29975\n",
            " 37828 40822 33225  7064 39731  4103 15191 21775 39684  8861 34140 20872\n",
            "  5507 36410 40716 27636 17382  9756  4146 22670 32152  8491 20335 40539\n",
            "  6911  4342  2390 12546  1856 28495 32797 26138 18991 16919 25841  5061\n",
            " 30787  7367 29555 15648 10428 23064 24052 33470 18051 28306 30343  8359\n",
            " 19843 11107 36246  8672  4986 17801 13588 18142  5167 26958  2995 39979\n",
            " 38516  5301 12969 33316   157 35800 26573 11414 38835  3656 11011 21237\n",
            " 17496 14033  5631 23122  2100 39953 15623  7353 30150 39645 15674 27030\n",
            "  3801 40335  2770  2152 38514 18374 26784 16644 31551 17732 19125 17564\n",
            "  8824 12431 39682 22765 39854 40340 40905 40463 23156 37174 40421 30944\n",
            " 40119  7136  6224   335  8789 39639 12888 23954  6269 28649 17265 35278\n",
            " 25958 15869 39773 32470 31760 24915 38417 20904 20010 38519  9612 29886\n",
            " 17293 11681 27952 39906 19818 39685  1663 30788 37639   378  5596 14891\n",
            " 29319 36816 18757 17711 20455 12200 26626 16128  5166 30580 40361  2690\n",
            " 24562 40449 23482   893 25227 26274 13068 14920 39955 20903 19202 24303\n",
            " 33294  6311 12782 30813 40488 40704 35142  3555  9475 19236 13447  4220\n",
            " 25315  5657 15327  4497  3694 32605 38303 36835 40971 18169 40045 38517\n",
            " 13238 24155 38763 38129  9199 19641 37327 25711 27485 40041 17144 24537\n",
            " 20678 26394  5497  6940 17739 40160 15969  3215 26125   839 36809 18372\n",
            " 10714  5236 36484 20391 23014 15839  4610 29329 24834 17864 40365 36865\n",
            "  4626 31091 22583 34903  3226 17342  4369 34174  8964 39879 10353 37890\n",
            " 32534  1054 13343   453  4386 39856  1210 17433 27579  4164  6100 22227\n",
            " 29474 20099  6796 30117   237 19950 14266  4606 37051 26787 11340 35672\n",
            "  1991 39792  6210 20737 14890 29137 17759 38083 12693  4416 36608  5158\n",
            "  9605 22732  8714 26536  9580 12283 20121 40012 33465 38358 26650  9395\n",
            " 32812  2602 40693 19432  2934 24335 13044 40714 27041 16335 36726 26316\n",
            " 25863 29701 40015 28176 19801  5112 30029 34971 10461 40256  1090 35038\n",
            " 17444 15179 25345 33315 27557   488 26135  2562 14632 29108 17843 23396\n",
            "  6850 39358  4982 23288 18216 24178   987 20882 18588 25669 11570 18140\n",
            " 33524  2777 29168 32572 35327  7426 36251  6561  3595 40720  7767 34429\n",
            " 21538 40476 18980 13954 40960 15447 23039 40584 21827  1002  5886  5114\n",
            " 14769 11226 33708 11178 10712 40952 39634 27394 27495 15757 40243 27395\n",
            "  8299 30941 12297 33489 24779 21834 33455  8360 10290 11970 19160 10690\n",
            " 27717 23817 40623 30179 36028 20588  3924 15039 18697 30739 39950 25005\n",
            " 33308  4367 21288 40598 21878 36970 34934  5245 34864  5048 19045 19341\n",
            " 34913 26502 16564 16826 32336  1487  6122 29172 13128 40306 33295 40604\n",
            "  2286  5919 28447 37692 34482 40171 30693 24964 24043 27300   132 26457\n",
            " 17995 38125 40302  2186  3378 27375 12150  6936 17066 21072  3146 39603\n",
            "  7256 14101 19285  1011   446 15638 36946 21777  3526 34196 23353 13104\n",
            " 29784  6279 19689 37297  7012 17426  8849 36286 11678 16368  7033  9406\n",
            " 40538  7052 36969 13858 22440  6937  7142 20496 40730 20896 30281 25624\n",
            " 40999 26639 18226 34695  5475 34398 24275 15792 33635 24704 34842 31625\n",
            " 16426  1725 12242 27488 20628 36629 18681 40046 26881 18592 34396  2581\n",
            " 26742 32861 29920 40170  7827 11913 18517  4286]\n",
            "\n",
            "Sorted T-test - [ 2415 29141 12514 40435 17976 10697 31676  6302 40675 12354 35309 39770\n",
            " 39774 39651 22887 40413 14658 39599   741 27650 40278 23885 18189 31606\n",
            " 14903 39867 33148  8197 23187 39597 29456 21019 39249 40458 39887 30206\n",
            " 40734   219 10695  3966 24596 12074 40708 39648  4861 33576 40385 30254\n",
            " 35279 39513 35827 39612 40467 30769 39601 40702  8027 10522 39726 40420\n",
            " 38378 31059  2323 39775 40441 39865 40231 19977  2903 11562 39769 22867\n",
            " 27267 33518 40393 40970 26944 21263 31107 31610 35841 28293 26476 39559\n",
            " 36968 39533 40713  7856 37925 25699 15682 39723 38575 32364  3921 39725\n",
            "  7380 40436 40111 39667 40102 23212 39798 39714 15944 39876 37769 16815\n",
            " 20363 40565 40162 39858 25074 12284 17283 40537 35292 11355 31863  2269\n",
            "   794 32258 40743 40390 40703 18179 39843 34761 30623 22565  2894 23638\n",
            "  7739  7312 38618 14979 25428 36673   386 40822 33225 39731  4103 39684\n",
            " 36410 27636  4146 32152 40539  6911  2390 28495 32797 26138 18991 25841\n",
            "  7367 15648 24052 30343 13588  2995 39979  5301 12969 33316 35800 26573\n",
            " 21237  5631 23122 39953 39645 15674 27030  3801  2152 38514 19125 39854\n",
            " 40905 40463 23156 40421 40119  6224 39639 23954 35278 25958 39773 31760\n",
            " 17293 11681 39906 39685  1663 29319 36816 20455 30580 40449 25227 13068\n",
            " 39955 19202 24303 12782 40704 25315 15327 32605 38303 36835 40971 18169\n",
            " 40045 13238 37327 27485 40041 17144  5497 40160  3215 26125 36809 18372\n",
            "  5236 36484  4626 31091  3226  8964 39879 10353  1054 13343  4386 39856\n",
            " 27579 22227 29474 30117  4606 35672  1991 39792  6210 20737 17759  5158\n",
            " 22732  8714 12283 20121 40012 38358  9395 24335 27041 16335 29701 40015\n",
            " 30029 34971  1090 25345 33315 27557 26135 17843 23396  6850  4982 23288\n",
            " 18216 24178 11570 29168 32572  7426 40720  7767 34429 21538 40476 40960\n",
            " 40584 14769 11226 33708 10712 40952 27495 15757 30941 33489 24779 21834\n",
            " 33455 10290 11970 10690 23817 40623 36028 20588  3924 18697 30739 21288\n",
            " 36970 34934 19045 19341 34913 32336  1487  6122 29172  2286 37692 34482\n",
            " 17995 17066  3146 19285   446 36946 13104  6279 19689 37297  8849 36286\n",
            " 11678 16368  9406 40538 36969 22440 30281 40999  5475 34398 33635 34842\n",
            " 16426 12242 27488 20628 34396 26742 32861 36943 28614 18159 26001 31114\n",
            " 26946 39756 36698  6270 19219 21494 13520 18301 26250 33298  1435 11217\n",
            " 28850 26634 31033 16812 38559 15608 40600 12043 23477  3899  2317  7741\n",
            " 25321 32506 40494 37496 30912 18549 15562 40483 33379 30097 22414 35766\n",
            "  3769 26915 32646  3155 18520  4053 22244 22894 28519 40007 38952  4895\n",
            " 35710 31764 12490  3702  8812 38466 23509 35884  7355  4906 20383 16532\n",
            "  5740 26227 36579  1839  6359  5468 24055 40736  4776 10546 23508 36954\n",
            " 39692 23809 15658 12613 14442  9694 18567 39889 23165 40834 33553  6334\n",
            " 40912 19150 15734  6718 35577  4044 20140 11220  8830 12019 40781 27628\n",
            " 40998  7485 24743 30189 40832  5326 15867 25936 35306 13007 16893 28386\n",
            " 22893 31747 33520 39910 39687 11894 18279 38481 13808  3804 37091 39698\n",
            " 32232 29391 24301 33513 27025 31108 31856 39567 29236 37594 25719 30250\n",
            " 40926 29287 18943 33515 13020 39584 40115 13118  6365 39686 16174 31087\n",
            "  4379 39744 39943  3821 39543   635  6309  3953 20454 26416 41052  3803\n",
            "   739 38377  1078 29431 39789 31412 27969 28018 30294 39706 19691 22703\n",
            " 17296 23921 24188 40687 10488 22614  5450 32589 39945   632 40840 11683\n",
            " 26980 20334   262 34076 39276 39848 39912 39886 26198 28548 38194  4684\n",
            "  2097 22383 32343  4148  9792  5491 23751  9137 24134 19144 20127 28640\n",
            " 26633 13218 11667 25430 31951 33109 15858 13224  8433 19097 25172  6669\n",
            "  4143 11843 39890 30306 28671  8477 33593 18702 28531  5364 20113 17299\n",
            " 12255 20109 22897 30246 39885 23304 27996 17916  7841 32320 25714 23684\n",
            " 22375 34216 27889 13364 32348 15326 24811  8897 25050 39901 10337  4601\n",
            " 15460  2356 29423 26610 39824  7388  7110  1534 11514 34408 39990  4922\n",
            " 30171  7712 10750  9009 12961 37882 10715 16860 34503  8692 30679  5406\n",
            " 19048 22413 26196 18160 11605 13129 35740 12045 37527 32712  7148 17275\n",
            " 22707 26020 40466 28937 39128  4007 14507  9942  7518 33228  2195 12014\n",
            " 36134 40837 31260  1148  6890 11377  1071  3276 23301  8869    19 22857\n",
            " 27698 27021 16637 19282 40107 10563 24201 21539 36399  1544 39938  9087\n",
            " 25346 11698 23303  4872 22177 30834 16290 36132  7068  1427 40972 29994\n",
            "  8258  5498 38342  5642  4630 39827 18458 33142 23883 40670 23848  9122\n",
            " 12758 24972 39762 33457  9796 22734 26254 15779 17341 33485   754 33800\n",
            "  8496  1470 40013 23307 36120 23211 37412 27644  5616 12285  6175 24004\n",
            " 15709 40084 33307 18634 22686 36123 23593  8090 22385 36618 29163 28452\n",
            "  8269 38840 36050 29235 26464 32323 11781  6335  7488 13009 39352 37418\n",
            " 41018  8153  7684  2657  7481  6892  1488 18052 40457  2832 19726  7210\n",
            " 34637  7560 27477 10351 18641 11064 17234 35951  5668  8900 38671  8080\n",
            " 22310 31631 34891 40975 34788 40042  6013 10728  3520  8169 32044 34574\n",
            " 13346 28601 33170  9260 20667  5834 26909 26889]\n",
            "\n",
            "Sorted SNR -  [12514  2415 29141 31676 17976 40675 40435 31606 18189 10697 39770  2152\n",
            " 10353  6302 12354 35309 39774   741 40413 36968 39651 22887 35279 39249\n",
            " 18991 25227 29456 14658 15944 23187 23885  8197 21237 39599 40278 21019\n",
            "  2995 31059 27650 30769 33148 14903 35827 33576 39867 39648 23212  6333\n",
            " 10695 12074 39887 39597 30254 40458  4606 26944 30206 24596 40734   219\n",
            " 40385 33298 32364  3966 22867  4861 40708 21263 39726 38303 39865 39513\n",
            " 40467 37769 10522 40420 27267 35278  2323 40970 39612 39601 33518 40702\n",
            "  8027 40231 23638 40441 38378 26476 36970 31091 25321  7856 31610  2903\n",
            " 39775 16815 28495 40162 23156  4146 19977 18279 39559  6911 31107 11562\n",
            " 39769 35800 34482 40393 30343 40102 20628 39533 35841  7312 39876  3921\n",
            " 25699 40565 27485 40703 39667  2269 39731 16426 40436 38575 28293 17759\n",
            " 40713 37925 40111 39725 30623 32152   386 39723  7380 39858 15682  2390\n",
            "  8477 25074 33225 39714  5498 24335 39685 39798 17283 39128 38514 14979\n",
            " 36484 20363  2894 34761  1839 29474 11355 32797 35292 15648 12284   794\n",
            " 36286  3155 40537  5158 13588 22565 23954 31863 18179  7739 40743 32258\n",
            " 40390 26915 30029 39843  4626 23817 20455 25428  3953 23122 40822 26946\n",
            " 38618 26250 36673 30250 30941 10546 29319 11570  4103 26138  1663 15674\n",
            " 39684  7415 40539  5631 39854 27636 13343 36410 17144  3702 25315 22413\n",
            " 25958  7741  5236 28850 31856 24446 27030  5301 34971 25841 24052  7367\n",
            " 40421 11681 33316  4661 26573 39979 39906 17293 12969 37327 21288 39645\n",
            " 32506  9395 21834  4863 39639 40704 39773 40015 18372 39953  7712  3801\n",
            " 26890  7426 18697 18216 26135 33708  7767 25050 31412  6224 36835 30912\n",
            " 25345 40012 40119 37692 33315 19125 11698 20334 22732  5491 10690 39856\n",
            "  8496 40449 13238 40905 40463 33635 39879 32572   635  1487 40736 12782\n",
            " 24303 30580 36816 37882  1991 31760 16335  3226 27041 23288  8964 30246\n",
            " 28640  1054 35672 38358 13381  9122 11970 40160 13068   632 39955 38342\n",
            " 25517  7355 19202  6850  8714 40971 15327 40041  5497 18169 27488 32605\n",
            "  5475 24055 21538 40045 28519 13258 34076 34913  4630 20588 29701  7518\n",
            "  3215 14769  6365 36809  9792 26125 34429 15460  4776 30117  5074 19691\n",
            "  6210 34842 27579 27001 33489 20737 22227  6279  3821 33513  6669 19045\n",
            " 25997 10712 27495  4386 39792 17843 16443  1090 20121 27557 23396 36969\n",
            " 36975 12131  5468 18549 40476 11894 12283 35799 19664 38671 13808  6718\n",
            " 19689 30739 18301 33455 26742 29168 39692 21494  9796 34398 19285  6122\n",
            " 38466 33379  4075 18316 35577 28531  4982 20109 22414    19 19219 24178\n",
            " 11843 37222  3146 40720  4906 26020 40960 22417 23509 19341 16812 40584\n",
            " 40952 36028 11678 35105 11226 27480 15757  2317 34503  3924 18159 13104\n",
            " 29431 24779 28386 38559 10290  6335 24430 32336 36698  6270 27628 40623\n",
            "   446 34163  2286   754 20012 26227 16368 11922 23809 34934 26001 27637\n",
            " 32861  8849 36946 31114 11683 17066 29172 40912 22440 30306   711 39567\n",
            " 17995 27889   262 28614 15867  5495 39756 34408 40999 15517  8848 15562\n",
            " 33553 31951 40538 18520 23947 30281 35766  2549  9406  3769 31747 27771\n",
            " 37297 37496 29012 16893 22893  4148 37759 34396 24743  9009  1435 26634\n",
            " 23477  8153 12242 25346  4053 31033 35710 10114 30294 12043 18052 33486\n",
            " 31764 36943 13520 31115  8830 22703 40687 15608  6359 30097 18641 11258\n",
            " 32646  4379 40494 17965 14442 28548 13364 35740 25172  3899 11217 34216\n",
            " 39744  6334 35306 39945 31813 14507 16174  4895 40600 33520 38952 40483\n",
            " 35884 35683 36579 13118  7485 13007  8090   569  7481 12490 31108 20113\n",
            " 26633 12613  8869 23894 11220 39687 31087 12019 25719  8812 20383 25170\n",
            " 30189 19150  1488 10563 23921 18567 22244 22894 28671 36050 40832  4044\n",
            " 33515 40007 10026   739 15658 27969 32327 28751 19282 25936 36134 33457\n",
            " 12014 10374 22375 13020 32343 23165  5740  1071 39370 36120  6309 17299\n",
            " 16532 21858 32232 23508 38377  3668   702 17275 25323 36954 20140 38840\n",
            " 21524 30208 25010  9694 37418 39889 33990 40834  3325 37091 28018 34390\n",
            " 15734 39910 24188  8748 23751  9145 18707 27498 34574 18943 12045 40781\n",
            " 28324 14714 10665 37006 23211 26284 20127  9176 40998 15326 40926 37594\n",
            "  2097  4872 22614 39598  5326 25714  8433 39698  2451 26416 13314 18458\n",
            "  7148 24301  1427 24811 16107 10488 27025 29391 22897 16637 26196 32589\n",
            " 29287 27471 28601 38481 30295  3804 40042 20563 20454 29236 22686 36212\n",
            " 40766 23301  8167 33228 11605  3803 23684 11514 39686 11104 28937 23883\n",
            " 31260 22177 39543 10750  1534  9942 39584 39055 32712  3276 23975 39943\n",
            " 40115 23304  4040  9850 26980 26610  8086 41052 30288 30679  1544 36950\n",
            " 30870 24732 26707 27729 20658 15858 39990 35545 25430   677 23307 17296\n",
            "  1078 11781 10351 10728  4143 40972 27109 10633  7684 39789 21285 13218\n",
            " 34131 33485 26708 38194 39848  5450 20757  4684 39706 31631 13224  5642\n",
            " 12255 33142 10337 39276 24134 26796 28857 27809 39912   801  7488 23210\n",
            " 40840  6892 17327 18702  2356  6912 11667 23593 26198 36123 19048 34993\n",
            " 31804 12961 39886 19144 26771 39258 18160  9087]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmapYaN54Hbh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}