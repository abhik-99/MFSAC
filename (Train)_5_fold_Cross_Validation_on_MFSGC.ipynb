{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "(Train) 5-fold Cross Validation on MFSGC.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abhik-99/MFSGC/blob/master/(Train)_5_fold_Cross_Validation_on_MFSGC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KulkCG_T2428"
      },
      "source": [
        "#Multi-filtering Supervised Gene Clustering.\n",
        "\n",
        "**(Train) (Using 5-fold Cross Validation) (Using Representational Genes generated from top 800 Genes)**\n",
        "##Current Status:-\n",
        "Completed",
        "\n",
        "**Please Run the Dataset Splitter before running this Notebook.** Provide the \n",
        "*DATASET_train.csv* generated from the Dataset Splitter Notebook as the \n",
        "input to this Notebook at cell 4 as an upload.\\\n",
        "\\\n",
        "*If you already have Gene Representatives from a previous iteration, you can load them and use them here. Loading can be done using the last two cells of this notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5LLEvRnaEAi",
        "outputId": "9c65fe0e-5d97-4900-c634-970cc4c385c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "!pip install skfeature-chappers"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting skfeature-chappers\n",
            "  Downloading https://files.pythonhosted.org/packages/e6/45/19bb801eb3b4a892534ab86468ad0669a68ff63578610f90051190e3622f/skfeature-chappers-1.0.3.tar.gz\n",
            "Building wheels for collected packages: skfeature-chappers\n",
            "  Building wheel for skfeature-chappers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for skfeature-chappers: filename=skfeature_chappers-1.0.3-py2.py3-none-any.whl size=59510 sha256=195357e067c684126ad7049ee555405dfb0d70f4333890767215d2a124c54e61\n",
            "  Stored in directory: /root/.cache/pip/wheels/ac/61/bf/1b3a8c232a0072409508c2ec4c12f316e95681ae72ba7315d2\n",
            "Successfully built skfeature-chappers\n",
            "Installing collected packages: skfeature-chappers\n",
            "Successfully installed skfeature-chappers-1.0.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zpGfAP5tOQd"
      },
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "from google.colab import files\n",
        "\n",
        "import json\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.feature_selection import chi2\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "\n",
        "from scipy.sparse import *"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubXXV5JXaM34",
        "outputId": "f1a98f6b-b1d7-40fc-e18b-c90b85373bc2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tPDn5sSHH55"
      },
      "source": [
        "## Creating Filter Methods for Scoring and filtering top rated genes\n",
        "The Filter Methods chosen for evaluation are:-\n",
        "\n",
        "1. Mutual Information.\n",
        "2. ReliefF.\n",
        "3. Chi Sq.\n",
        "4. Fisher Score.\n",
        "5. Signal To Noise Ratio (adapted for multi-class datasets).\n",
        "6. T-Test.\n",
        "7. Pearson Corelation Coefficient."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmPvz9Ke2tlb"
      },
      "source": [
        "#construction of ReliefF function\n",
        "\n",
        "\"\"\"\n",
        "Given a dataset, number of random instances to pick form the dataset and\n",
        "number of features to consider in each iteration (k), the function returns the weigths of the attributes\n",
        "of the dataset.\n",
        "These weigths can then be used as the final results out of the ReliefF algorithm\n",
        "\n",
        "Paper-\n",
        "\n",
        "Marko Robnik-ˇSikonja and Igor Kononenko. Theoretical and empirical analysis of relieff\n",
        "and rrelieff. Machine learning, 53(1-2):23–69, 2003.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "def hit_miss_calculator(target,instance,k = 10, hit = True, c = None, ):\n",
        "    m=len(target)\n",
        "    upper,lower=instance-1,instance+1\n",
        "    hits=[]\n",
        "    hit_flag=False\n",
        "    #finds k nearest hits\n",
        "    while(not hit_flag):\n",
        "      #print(upper,lower)\n",
        "      if(len(hits)>=k):\n",
        "        hit_flag = True\n",
        "        break\n",
        "      if upper < 0 and lower > m:\n",
        "        hit_flag = True\n",
        "        break\n",
        "      if(upper>=0):\n",
        "        if((target[upper]==target[instance]) and hit):\n",
        "          hits.append(upper)\n",
        "        elif((target[upper]!=target[instance]) and (not hit) and target[upper]==c):\n",
        "          hits.append(upper)\n",
        "        upper-=1          \n",
        "      if(lower<m):\n",
        "        if((target[lower]==target[instance]) and hit):\n",
        "          hits.append(lower)\n",
        "        elif((target[lower]!=target[instance]) and (not hit) and target[lower]==c):\n",
        "          hits.append(lower)\n",
        "        lower+=1\n",
        "    hits.sort()\n",
        "    return hits\n",
        "\n",
        "\n",
        "def reliefF(feature,target,k=10,repetitions=10, seed = 0):\n",
        "  np.random.seed(seed)\n",
        "  if len(feature.shape)>1:\n",
        "    m,n=feature.shape\n",
        "  else:\n",
        "    m=len(feature)\n",
        "    n=1\n",
        "  #print(m,n)\n",
        "  observations=list(range(m))\n",
        "  classes=np.unique(target)\n",
        "  weights=np.zeros(n)\n",
        "  d=(np.max(feature,axis=0)-np.min(feature,axis=0))*m*k\n",
        "\n",
        "  for i in range(repetitions):\n",
        "    instance=np.random.choice(observations,1)[0]\n",
        "    #print(\"Iteration\",i)\n",
        "    #print(instance)\n",
        "    hits=hit_miss_calculator(target,instance,k)\n",
        "    hit_class_prob=len(np.where(target==target[instance])[0])/m\n",
        "    #print(\"\\nHit Probability -\",hit_class_prob)\n",
        "    #print(\"Repetition\",i,\"Class\",target[instance],\"Hits -\",hits)\n",
        "\n",
        "    miss={}\n",
        "    miss_class_prob={}\n",
        "\n",
        "    for each_class in classes:\n",
        "      if(each_class != target[instance]):\n",
        "        miss[each_class]=hit_miss_calculator(target,instance,k,False,each_class)\n",
        "        class_prob=len(np.where(target==each_class)[0])/m\n",
        "        #print(each_class,class_prob)\n",
        "        miss_class_prob[each_class]=hit_class_prob/(1 - (class_prob))\n",
        "\n",
        "    #print(\"Repetition\",i,\"Miss-\",miss,\"Miss Class Probability -\",miss_class_prob)\n",
        "    \n",
        "    for hit in hits:\n",
        "      if len(feature.shape)>1:\n",
        "        weights-=np.subtract(feature.iloc[instance,:],feature.iloc[hit,:])/d\n",
        "      else:\n",
        "        weights-=np.subtract(feature.iloc[instance],feature.iloc[hit])/d\n",
        "    for each_class in miss:\n",
        "      for each_miss in miss[each_class]:\n",
        "        if len(feature.shape)>1:\n",
        "          weights+=(np.subtract(feature.iloc[instance,:],feature.iloc[each_miss,:])/d)*miss_class_prob[each_class]\n",
        "        else:\n",
        "          weights+=(np.subtract(feature.iloc[instance],feature.iloc[each_miss])/d)*miss_class_prob[each_class]\n",
        "    \n",
        "    \n",
        "  return weights.tolist()"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3Yq8gnsaRFw"
      },
      "source": [
        "#This function discretizes the given features into 3 categories\n",
        "def discretize_feature(feature):\n",
        "  \n",
        "  mean=np.mean(feature)\n",
        "  std=np.std(feature)\n",
        "  discretized=np.copy(feature)\n",
        "  \n",
        "  discretized[np.where(feature<(mean+std/2)) ,]=2#within 1/2 std div\n",
        "  discretized[np.where(feature>(mean-std/2)),]=2#within 1/2 std div\n",
        "  \n",
        "  discretized[np.where(feature>(mean+std/2)),]=0#greater than half\n",
        "  discretized[np.where(feature<(mean-std/2)),]=1#less than half\n",
        "  \n",
        "  return discretized\n",
        "\n",
        "def Xfreq(x):\n",
        "  xL={}\n",
        "  for e in x:\n",
        "    if e not in xL:\n",
        "      xL[e]=0\n",
        "    else:\n",
        "      xL[e]+=1\n",
        "  for e in xL:\n",
        "    xL[e]/=len(x)\n",
        "  return xL\n",
        "\n",
        "def XYfreq(x,y):\n",
        "  freq={}\n",
        "  \n",
        "  rX=np.unique(x)\n",
        "  rY=np.unique(y)\n",
        "      \n",
        "  for e in rX:\n",
        "    for f in rY:\n",
        "      freq[(e,f)]=round(len(np.where(y[np.where(x==e)[0]]==f)[0])/len(x),4)\n",
        "       \n",
        "  return freq\n",
        "\n",
        "def mutual_info(x,y):\n",
        "\n",
        "  xFreq=Xfreq(x)\n",
        "  yFreq=Xfreq(y)\n",
        "  joint=XYfreq(x,y)\n",
        "  \n",
        "  Xentropy=0\n",
        "  for e in xFreq:\n",
        "    if xFreq[e]!=0:\n",
        "      Xentropy-=xFreq[e]*np.log2(xFreq[e])\n",
        "      \n",
        "  Yentropy=0\n",
        "  for e in yFreq:\n",
        "    if yFreq[e]!=0:\n",
        "      Yentropy-=yFreq[e]*np.log2(yFreq[e])\n",
        "      \n",
        "  jentropy=0\n",
        "  for e in xFreq:\n",
        "    for f in yFreq:\n",
        "      if joint[(e,f)]!=0:\n",
        "        jentropy-=joint[(e,f)]*np.log2(joint[(e,f)])\n",
        "  \n",
        "  return (Xentropy+Yentropy-jentropy)\n",
        "\n",
        "def mutual_info_wrapper(features,target):\n",
        "\n",
        "  mi=np.array([])\n",
        "  for x in features:\n",
        "    # print(x)\n",
        "    discrete=discretize_feature(features[x])\n",
        "    mi=np.append(mi,mutual_info(discrete,target))\n",
        "  return np.array(mi)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2qREP_49tK_"
      },
      "source": [
        "\"\"\"\n",
        "This cell is used for defining the method for calculating the t-scores\n",
        "\"\"\"\n",
        "\n",
        "def t_test(df,target):\n",
        "  \"\"\"\n",
        "  Input:\n",
        "  df= Dataframe of features (n_samples,n_features)\n",
        "  target= Pandas Series/1D Numpy Array containing the class labels (n_samples)\n",
        "  \n",
        "  Output:\n",
        "  scores= Descendingly Sorted array of features based on t-test \n",
        "  \"\"\"\n",
        "  import numpy as np\n",
        "  from scipy.stats import ttest_ind\n",
        "  scores=ttest_ind(df[:][target==0],df[:][target==1])[0] #Storing just the t-test scores and discarding the p-values from the result.\n",
        "  \n",
        "  # scores=np.argsort(scores,0)\n",
        "  return [scores] if type(scores) != np.ndarray else scores\n",
        "\n",
        "  "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYCzFUqX9tjS"
      },
      "source": [
        "from scipy.sparse import *\n",
        "def fisher_score(X, y):\n",
        "    import numpy as np\n",
        "    \n",
        "    from skfeature.utility.construct_W import construct_W\n",
        "    \"\"\"\n",
        "    This function implements the fisher score feature selection, steps are as follows:\n",
        "    1. Construct the affinity matrix W in fisher score way\n",
        "    2. For the r-th feature, we define fr = X(:,r), D = diag(W*ones), ones = [1,...,1]', L = D - W\n",
        "    3. Let fr_hat = fr - (fr'*D*ones)*ones/(ones'*D*ones)\n",
        "    4. Fisher score for the r-th feature is score = (fr_hat'*D*fr_hat)/(fr_hat'*L*fr_hat)-1\n",
        "\n",
        "    Input\n",
        "    -----\n",
        "    X: {numpy array}, shape (n_samples, n_features)\n",
        "        input data\n",
        "    y: {numpy array}, shape (n_samples,)\n",
        "        input class labels\n",
        "\n",
        "    Output\n",
        "    ------\n",
        "    score: {numpy array}, shape (n_features,)\n",
        "        fisher score for each feature\n",
        "\n",
        "    Reference\n",
        "    ---------\n",
        "    He, Xiaofei et al. \"Laplacian Score for Feature Selection.\" NIPS 2005.\n",
        "    Duda, Richard et al. \"Pattern classification.\" John Wiley & Sons, 2012.\n",
        "    \"\"\"\n",
        "\n",
        "    # Construct weight matrix W in a fisherScore way\n",
        "    kwargs = {\"neighbor_mode\": \"supervised\", \"fisher_score\": True, 'y': y}\n",
        "    W = construct_W(X, **kwargs)\n",
        "\n",
        "    # build the diagonal D matrix from affinity matrix W\n",
        "    D = np.array(W.sum(axis=1))\n",
        "    L = W\n",
        "    tmp = np.dot(np.transpose(D), X)\n",
        "    D = diags(np.transpose(D), [0])\n",
        "    Xt = np.transpose(X)\n",
        "    t1 = np.transpose(np.dot(Xt, D.todense()))\n",
        "    t2 = np.transpose(np.dot(Xt, L.todense()))\n",
        "    # compute the numerator of Lr\n",
        "    D_prime = np.sum(np.multiply(t1, X), 0) - np.multiply(tmp, tmp)/D.sum()\n",
        "    # compute the denominator of Lr\n",
        "    L_prime = np.sum(np.multiply(t2, X), 0) - np.multiply(tmp, tmp)/D.sum()\n",
        "    # avoid the denominator of Lr to be 0\n",
        "    D_prime[D_prime < 1e-12] = 10000\n",
        "    lap_score = 1 - np.array(np.multiply(L_prime, 1/D_prime))[0, :]\n",
        "\n",
        "    # compute fisher score from laplacian score, where fisher_score = 1/lap_score - 1\n",
        "    score = 1.0/lap_score - 1\n",
        "    return np.transpose(score)\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tep2JSvp9s_9"
      },
      "source": [
        "\n",
        "#Pearson corelation\n",
        "def pearson_corr(feature,targetClass):\n",
        "  import numpy as np\n",
        "  coef=[np.abs(np.corrcoef(feature[i].values,targetClass)[0,1]) for i in feature.columns]\n",
        "  # range(feature.shape[1])\n",
        "  coef=[0 if np.isnan(i) else i for i in coef]\n",
        "  return coef\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6Jay5ItLozt"
      },
      "source": [
        "#gini_index "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6-JlRseRjYx"
      },
      "source": [
        "#signal to noise ratio\n",
        "#using weighted one-vs-all strategy for multi-class data\n",
        "def signaltonoise(feature, target, axis = 0, ddof = 0):\n",
        "  import numpy as np\n",
        "  classes = np.unique(target)\n",
        "  if len(feature.shape)<2:\n",
        "    feature = feature.reshape(-1,1)\n",
        "  row, _ = feature.shape\n",
        "  if len(classes) <= 2:\n",
        "    m = None\n",
        "    std = 0\n",
        "    for each in classes:\n",
        "      idx = np.where(target == each)[0]\n",
        "      #convinient way of doing m1-m2\n",
        "      if m is None:\n",
        "        m = feature.iloc[idx, :].mean(axis)\n",
        "      else:\n",
        "        m -= feature.iloc[idx, :].mean(axis)\n",
        "\n",
        "      #sd1+sd2\n",
        "      std += feature.iloc[idx, :].std(axis = axis, ddof = ddof)\n",
        "\n",
        "    return np.asanyarray(m/std)\n",
        "\n",
        "  else:\n",
        "    snr_scores = [] #for storing the weighted scores\n",
        "    #using the one vs all strategy for each class with\n",
        "    for each in classes:\n",
        "      idx = np.where(target == each)[0]\n",
        "      idxn = np.where(target != each)[0]\n",
        "      m = feature.iloc[idx, :].mean(axis) - feature.iloc[idxn, :].mean(axis)\n",
        "      std = feature.iloc[idx, :].std(axis = axis, ddof = ddof) + feature.iloc[idxn, :].std(axis = axis, ddof = ddof) \n",
        "      snr_scores.append((m/std) * len(idx)/row) #weighted snr\n",
        "\n",
        "    return np.asanyarray(snr_scores).sum(axis = axis)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3aJ2aexJCT3"
      },
      "source": [
        "#intentionally left blank!"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pOkMLeXaRCL"
      },
      "source": [
        "def feature_ranking(score):\n",
        "    \"\"\"\n",
        "    Rank features in descending order according to fisher score, the larger the fisher score, the more important the\n",
        "    feature is\n",
        "    \"\"\"\n",
        "    idx = np.argsort(score, 0)\n",
        "    return idx[::-1]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7xQeB2HHBdn"
      },
      "source": [
        "## Loading the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttRNIkTcURY8",
        "outputId": "15b0bf76-2ecf-4c1b-d96d-50414bc26918",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 378
        }
      },
      "source": [
        "files.upload()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-35526205-812c-40ed-bc0f-710aa90c2cbf\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-35526205-812c-40ed-bc0f-710aa90c2cbf\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving breast.txt to breast.txt\n",
            "Saving colon.txt to colon.txt\n",
            "Saving leukemia.txt to leukemia.txt\n",
            "Saving lung.txt to lung.txt\n",
            "Saving MLL.txt to MLL.txt\n",
            "Saving Prostate.csv to Prostate.csv\n",
            "Saving rahc.txt to rahc.txt\n",
            "Saving raoa.txt to raoa.txt\n",
            "Saving rbreast.txt to rbreast.txt\n",
            "Saving SRBCT.txt to SRBCT.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLN2islMJFb2"
      },
      "source": [
        "#DATASET is the name of the dataset being used.\n",
        "DATASET=\"Leukemia\"\n",
        "\n",
        "#NEIGHBOURS determines neighbours arg for ReliefF\n",
        "#for any dataset which contains any class sample \n",
        "# <10, make it less than 10. Eg of such dataset - SRBCT\n",
        "NEIGHBOURS = 2 \n",
        "\n",
        "#p is the number of top genes taken after sorting the filter scores\n",
        "p = 800\n",
        "\n",
        "#q is the number of top augmented genes chosen from each filter after running \n",
        "#SGC\n",
        "q = 5"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8f4If3BkUXhR",
        "outputId": "14d5798b-215d-4175-d6b7-25218b4fae67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "data_df=pd.read_csv(\"%s.txt\"%(DATASET),sep=\"\\t\", index_col=None, header=None)\n",
        "print(data_df.shape)\n",
        "target=data_df.iloc[:,-1]\n",
        "feature=pd.DataFrame(data_df.iloc[:,:-1].values,dtype='float')\n",
        "m,n=feature.shape\n",
        "print(m,n)\n",
        "print(feature.head())\n",
        "print(\"Number of classes - \")\n",
        "classes = np.unique(target)\n",
        "for x in classes:\n",
        "  print(\"Class -\",x,\"Number of Samples -\", len(np.where(target == x)[0]))\n",
        "\n",
        "feature_norm=pd.DataFrame(MinMaxScaler().fit_transform(feature))\n",
        "\n",
        "count_genes = dict(zip(map(int,feature.columns.tolist()), np.zeros(data_df.shape[1], dtype= np.int16)))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(72, 7071)\n",
            "72 7070\n",
            "    0     1      2     3      4     ...    7065   7066  7067   7068  7069\n",
            "0  151.0  72.0  281.0  36.0 -299.0  ...   793.0  329.0  36.0  191.0 -37.0\n",
            "1  263.0  21.0  250.0  43.0 -103.0  ...   782.0  295.0  11.0   76.0 -14.0\n",
            "2   88.0 -27.0  358.0  42.0  142.0  ...  1138.0  777.0  41.0  228.0 -41.0\n",
            "3  484.0  61.0  118.0  39.0  -11.0  ...   627.0  170.0 -50.0  126.0 -91.0\n",
            "4  118.0  16.0  197.0  39.0  237.0  ...   250.0  314.0  14.0   56.0 -25.0\n",
            "\n",
            "[5 rows x 7070 columns]\n",
            "Number of classes - \n",
            "Class - 0 Number of Samples - 25\n",
            "Class - 1 Number of Samples - 47\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NbrO8c-JniNE",
        "outputId": "81c9e522-20ca-4d34-f0ae-f0c513408161",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        }
      },
      "source": [
        "data_df.head()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>7031</th>\n",
              "      <th>7032</th>\n",
              "      <th>7033</th>\n",
              "      <th>7034</th>\n",
              "      <th>7035</th>\n",
              "      <th>7036</th>\n",
              "      <th>7037</th>\n",
              "      <th>7038</th>\n",
              "      <th>7039</th>\n",
              "      <th>7040</th>\n",
              "      <th>7041</th>\n",
              "      <th>7042</th>\n",
              "      <th>7043</th>\n",
              "      <th>7044</th>\n",
              "      <th>7045</th>\n",
              "      <th>7046</th>\n",
              "      <th>7047</th>\n",
              "      <th>7048</th>\n",
              "      <th>7049</th>\n",
              "      <th>7050</th>\n",
              "      <th>7051</th>\n",
              "      <th>7052</th>\n",
              "      <th>7053</th>\n",
              "      <th>7054</th>\n",
              "      <th>7055</th>\n",
              "      <th>7056</th>\n",
              "      <th>7057</th>\n",
              "      <th>7058</th>\n",
              "      <th>7059</th>\n",
              "      <th>7060</th>\n",
              "      <th>7061</th>\n",
              "      <th>7062</th>\n",
              "      <th>7063</th>\n",
              "      <th>7064</th>\n",
              "      <th>7065</th>\n",
              "      <th>7066</th>\n",
              "      <th>7067</th>\n",
              "      <th>7068</th>\n",
              "      <th>7069</th>\n",
              "      <th>7070</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>151</td>\n",
              "      <td>72</td>\n",
              "      <td>281</td>\n",
              "      <td>36</td>\n",
              "      <td>-299</td>\n",
              "      <td>57</td>\n",
              "      <td>186</td>\n",
              "      <td>1647</td>\n",
              "      <td>137</td>\n",
              "      <td>803</td>\n",
              "      <td>-894</td>\n",
              "      <td>-632</td>\n",
              "      <td>378</td>\n",
              "      <td>-26</td>\n",
              "      <td>-691</td>\n",
              "      <td>2</td>\n",
              "      <td>-156</td>\n",
              "      <td>155</td>\n",
              "      <td>355</td>\n",
              "      <td>1149</td>\n",
              "      <td>-131</td>\n",
              "      <td>158</td>\n",
              "      <td>1084</td>\n",
              "      <td>87</td>\n",
              "      <td>125</td>\n",
              "      <td>11</td>\n",
              "      <td>553</td>\n",
              "      <td>152</td>\n",
              "      <td>759</td>\n",
              "      <td>551</td>\n",
              "      <td>34</td>\n",
              "      <td>588</td>\n",
              "      <td>129</td>\n",
              "      <td>1128</td>\n",
              "      <td>919</td>\n",
              "      <td>399</td>\n",
              "      <td>-206</td>\n",
              "      <td>20</td>\n",
              "      <td>271</td>\n",
              "      <td>78</td>\n",
              "      <td>...</td>\n",
              "      <td>-763</td>\n",
              "      <td>172</td>\n",
              "      <td>149</td>\n",
              "      <td>341</td>\n",
              "      <td>788</td>\n",
              "      <td>21210</td>\n",
              "      <td>13771</td>\n",
              "      <td>598</td>\n",
              "      <td>396</td>\n",
              "      <td>245</td>\n",
              "      <td>14476</td>\n",
              "      <td>10882</td>\n",
              "      <td>701</td>\n",
              "      <td>2762</td>\n",
              "      <td>-325</td>\n",
              "      <td>-67</td>\n",
              "      <td>346</td>\n",
              "      <td>-68</td>\n",
              "      <td>229</td>\n",
              "      <td>-14</td>\n",
              "      <td>108</td>\n",
              "      <td>28</td>\n",
              "      <td>349</td>\n",
              "      <td>61</td>\n",
              "      <td>273</td>\n",
              "      <td>384</td>\n",
              "      <td>-306</td>\n",
              "      <td>-1827</td>\n",
              "      <td>1582</td>\n",
              "      <td>185</td>\n",
              "      <td>511</td>\n",
              "      <td>-125</td>\n",
              "      <td>389</td>\n",
              "      <td>-37</td>\n",
              "      <td>793</td>\n",
              "      <td>329</td>\n",
              "      <td>36</td>\n",
              "      <td>191</td>\n",
              "      <td>-37</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>263</td>\n",
              "      <td>21</td>\n",
              "      <td>250</td>\n",
              "      <td>43</td>\n",
              "      <td>-103</td>\n",
              "      <td>169</td>\n",
              "      <td>219</td>\n",
              "      <td>2043</td>\n",
              "      <td>188</td>\n",
              "      <td>756</td>\n",
              "      <td>-812</td>\n",
              "      <td>-700</td>\n",
              "      <td>249</td>\n",
              "      <td>-242</td>\n",
              "      <td>-369</td>\n",
              "      <td>-14</td>\n",
              "      <td>-98</td>\n",
              "      <td>131</td>\n",
              "      <td>431</td>\n",
              "      <td>941</td>\n",
              "      <td>-95</td>\n",
              "      <td>328</td>\n",
              "      <td>1215</td>\n",
              "      <td>53</td>\n",
              "      <td>-81</td>\n",
              "      <td>20</td>\n",
              "      <td>215</td>\n",
              "      <td>104</td>\n",
              "      <td>1656</td>\n",
              "      <td>739</td>\n",
              "      <td>37</td>\n",
              "      <td>781</td>\n",
              "      <td>182</td>\n",
              "      <td>944</td>\n",
              "      <td>759</td>\n",
              "      <td>219</td>\n",
              "      <td>-87</td>\n",
              "      <td>13</td>\n",
              "      <td>595</td>\n",
              "      <td>142</td>\n",
              "      <td>...</td>\n",
              "      <td>51</td>\n",
              "      <td>154</td>\n",
              "      <td>418</td>\n",
              "      <td>433</td>\n",
              "      <td>736</td>\n",
              "      <td>21059</td>\n",
              "      <td>15097</td>\n",
              "      <td>563</td>\n",
              "      <td>171</td>\n",
              "      <td>-149</td>\n",
              "      <td>13686</td>\n",
              "      <td>11789</td>\n",
              "      <td>76</td>\n",
              "      <td>1567</td>\n",
              "      <td>-191</td>\n",
              "      <td>-88</td>\n",
              "      <td>290</td>\n",
              "      <td>14</td>\n",
              "      <td>194</td>\n",
              "      <td>56</td>\n",
              "      <td>303</td>\n",
              "      <td>-242</td>\n",
              "      <td>214</td>\n",
              "      <td>-28</td>\n",
              "      <td>143</td>\n",
              "      <td>231</td>\n",
              "      <td>-336</td>\n",
              "      <td>-2380</td>\n",
              "      <td>624</td>\n",
              "      <td>169</td>\n",
              "      <td>837</td>\n",
              "      <td>-36</td>\n",
              "      <td>442</td>\n",
              "      <td>-17</td>\n",
              "      <td>782</td>\n",
              "      <td>295</td>\n",
              "      <td>11</td>\n",
              "      <td>76</td>\n",
              "      <td>-14</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>88</td>\n",
              "      <td>-27</td>\n",
              "      <td>358</td>\n",
              "      <td>42</td>\n",
              "      <td>142</td>\n",
              "      <td>359</td>\n",
              "      <td>237</td>\n",
              "      <td>1997</td>\n",
              "      <td>91</td>\n",
              "      <td>2514</td>\n",
              "      <td>-1715</td>\n",
              "      <td>-603</td>\n",
              "      <td>362</td>\n",
              "      <td>-31</td>\n",
              "      <td>-1385</td>\n",
              "      <td>-374</td>\n",
              "      <td>-213</td>\n",
              "      <td>270</td>\n",
              "      <td>603</td>\n",
              "      <td>1924</td>\n",
              "      <td>94</td>\n",
              "      <td>301</td>\n",
              "      <td>1281</td>\n",
              "      <td>128</td>\n",
              "      <td>70</td>\n",
              "      <td>12</td>\n",
              "      <td>460</td>\n",
              "      <td>-3</td>\n",
              "      <td>1130</td>\n",
              "      <td>885</td>\n",
              "      <td>141</td>\n",
              "      <td>1044</td>\n",
              "      <td>423</td>\n",
              "      <td>1019</td>\n",
              "      <td>1019</td>\n",
              "      <td>650</td>\n",
              "      <td>-183</td>\n",
              "      <td>-33</td>\n",
              "      <td>457</td>\n",
              "      <td>205</td>\n",
              "      <td>...</td>\n",
              "      <td>-474</td>\n",
              "      <td>180</td>\n",
              "      <td>272</td>\n",
              "      <td>591</td>\n",
              "      <td>959</td>\n",
              "      <td>24292</td>\n",
              "      <td>17378</td>\n",
              "      <td>1808</td>\n",
              "      <td>363</td>\n",
              "      <td>325</td>\n",
              "      <td>6560</td>\n",
              "      <td>5023</td>\n",
              "      <td>804</td>\n",
              "      <td>1090</td>\n",
              "      <td>-258</td>\n",
              "      <td>9</td>\n",
              "      <td>220</td>\n",
              "      <td>-58</td>\n",
              "      <td>294</td>\n",
              "      <td>95</td>\n",
              "      <td>143</td>\n",
              "      <td>-25</td>\n",
              "      <td>464</td>\n",
              "      <td>513</td>\n",
              "      <td>238</td>\n",
              "      <td>720</td>\n",
              "      <td>-204</td>\n",
              "      <td>-1772</td>\n",
              "      <td>753</td>\n",
              "      <td>315</td>\n",
              "      <td>1199</td>\n",
              "      <td>33</td>\n",
              "      <td>168</td>\n",
              "      <td>52</td>\n",
              "      <td>1138</td>\n",
              "      <td>777</td>\n",
              "      <td>41</td>\n",
              "      <td>228</td>\n",
              "      <td>-41</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>484</td>\n",
              "      <td>61</td>\n",
              "      <td>118</td>\n",
              "      <td>39</td>\n",
              "      <td>-11</td>\n",
              "      <td>274</td>\n",
              "      <td>245</td>\n",
              "      <td>2128</td>\n",
              "      <td>-82</td>\n",
              "      <td>1489</td>\n",
              "      <td>-969</td>\n",
              "      <td>-909</td>\n",
              "      <td>266</td>\n",
              "      <td>-181</td>\n",
              "      <td>-900</td>\n",
              "      <td>-237</td>\n",
              "      <td>-156</td>\n",
              "      <td>115</td>\n",
              "      <td>255</td>\n",
              "      <td>1078</td>\n",
              "      <td>-24</td>\n",
              "      <td>238</td>\n",
              "      <td>1316</td>\n",
              "      <td>112</td>\n",
              "      <td>41</td>\n",
              "      <td>34</td>\n",
              "      <td>512</td>\n",
              "      <td>-147</td>\n",
              "      <td>1062</td>\n",
              "      <td>654</td>\n",
              "      <td>90</td>\n",
              "      <td>652</td>\n",
              "      <td>147</td>\n",
              "      <td>904</td>\n",
              "      <td>614</td>\n",
              "      <td>761</td>\n",
              "      <td>-254</td>\n",
              "      <td>-9</td>\n",
              "      <td>414</td>\n",
              "      <td>142</td>\n",
              "      <td>...</td>\n",
              "      <td>-336</td>\n",
              "      <td>325</td>\n",
              "      <td>149</td>\n",
              "      <td>173</td>\n",
              "      <td>431</td>\n",
              "      <td>17558</td>\n",
              "      <td>13818</td>\n",
              "      <td>576</td>\n",
              "      <td>455</td>\n",
              "      <td>594</td>\n",
              "      <td>8955</td>\n",
              "      <td>9567</td>\n",
              "      <td>367</td>\n",
              "      <td>1708</td>\n",
              "      <td>-357</td>\n",
              "      <td>45</td>\n",
              "      <td>430</td>\n",
              "      <td>-35</td>\n",
              "      <td>128</td>\n",
              "      <td>42</td>\n",
              "      <td>22</td>\n",
              "      <td>-131</td>\n",
              "      <td>342</td>\n",
              "      <td>142</td>\n",
              "      <td>277</td>\n",
              "      <td>307</td>\n",
              "      <td>-320</td>\n",
              "      <td>-2022</td>\n",
              "      <td>743</td>\n",
              "      <td>240</td>\n",
              "      <td>835</td>\n",
              "      <td>218</td>\n",
              "      <td>174</td>\n",
              "      <td>-110</td>\n",
              "      <td>627</td>\n",
              "      <td>170</td>\n",
              "      <td>-50</td>\n",
              "      <td>126</td>\n",
              "      <td>-91</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>118</td>\n",
              "      <td>16</td>\n",
              "      <td>197</td>\n",
              "      <td>39</td>\n",
              "      <td>237</td>\n",
              "      <td>311</td>\n",
              "      <td>186</td>\n",
              "      <td>1608</td>\n",
              "      <td>204</td>\n",
              "      <td>322</td>\n",
              "      <td>-444</td>\n",
              "      <td>-254</td>\n",
              "      <td>554</td>\n",
              "      <td>16</td>\n",
              "      <td>-58</td>\n",
              "      <td>-78</td>\n",
              "      <td>-95</td>\n",
              "      <td>45</td>\n",
              "      <td>569</td>\n",
              "      <td>501</td>\n",
              "      <td>-15</td>\n",
              "      <td>181</td>\n",
              "      <td>296</td>\n",
              "      <td>-39</td>\n",
              "      <td>-1</td>\n",
              "      <td>-2</td>\n",
              "      <td>514</td>\n",
              "      <td>-29</td>\n",
              "      <td>822</td>\n",
              "      <td>756</td>\n",
              "      <td>159</td>\n",
              "      <td>999</td>\n",
              "      <td>243</td>\n",
              "      <td>1037</td>\n",
              "      <td>691</td>\n",
              "      <td>263</td>\n",
              "      <td>-122</td>\n",
              "      <td>-17</td>\n",
              "      <td>397</td>\n",
              "      <td>85</td>\n",
              "      <td>...</td>\n",
              "      <td>-56</td>\n",
              "      <td>279</td>\n",
              "      <td>183</td>\n",
              "      <td>259</td>\n",
              "      <td>605</td>\n",
              "      <td>18530</td>\n",
              "      <td>15619</td>\n",
              "      <td>65</td>\n",
              "      <td>122</td>\n",
              "      <td>126</td>\n",
              "      <td>8443</td>\n",
              "      <td>8512</td>\n",
              "      <td>182</td>\n",
              "      <td>1503</td>\n",
              "      <td>-78</td>\n",
              "      <td>29</td>\n",
              "      <td>159</td>\n",
              "      <td>18</td>\n",
              "      <td>71</td>\n",
              "      <td>42</td>\n",
              "      <td>44</td>\n",
              "      <td>-33</td>\n",
              "      <td>159</td>\n",
              "      <td>71</td>\n",
              "      <td>134</td>\n",
              "      <td>178</td>\n",
              "      <td>-182</td>\n",
              "      <td>-179</td>\n",
              "      <td>626</td>\n",
              "      <td>156</td>\n",
              "      <td>649</td>\n",
              "      <td>57</td>\n",
              "      <td>504</td>\n",
              "      <td>-26</td>\n",
              "      <td>250</td>\n",
              "      <td>314</td>\n",
              "      <td>14</td>\n",
              "      <td>56</td>\n",
              "      <td>-25</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 7071 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   0     1     2     3     4     5     ...  7065  7066  7067  7068  7069  7070\n",
              "0   151    72   281    36  -299    57  ...   793   329    36   191   -37     1\n",
              "1   263    21   250    43  -103   169  ...   782   295    11    76   -14     1\n",
              "2    88   -27   358    42   142   359  ...  1138   777    41   228   -41     1\n",
              "3   484    61   118    39   -11   274  ...   627   170   -50   126   -91     1\n",
              "4   118    16   197    39   237   311  ...   250   314    14    56   -25     1\n",
              "\n",
              "[5 rows x 7071 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akTt6mw0SHA9"
      },
      "source": [
        "#utility function\n",
        "def plot_feature(feature, target, c = ['r', 'b', 'g', 'y']):\n",
        "  import matplotlib.pyplot as plt\n",
        "  from matplotlib import style\n",
        "  import numpy as np\n",
        "  style.use('ggplot')\n",
        "  for idx, each in enumerate(np.unique(target)):\n",
        "    y = feature[np.where(target == each)[0]]\n",
        "    x = len(y)\n",
        "    plt.scatter(range(1, x+1), y, color = c[idx])\n",
        "    plt.plot(range(1, x+1), y, color = c[idx])"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JT1P7jFvgq5I",
        "outputId": "871ee7c7-4997-4c2d-d9df-691704e0acbb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(count_genes))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7070\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUg7-Cy5Uwzf"
      },
      "source": [
        "\"\"\"\n",
        "Loading the Cluster JSON files from memory\n",
        "\"\"\"\n",
        "\n",
        "with open('%s_p%s_q%smi_cluster.json'%(DATASET, p, q), 'r') as fp:\n",
        "  mi_cluster=json.load(fp)\n",
        "\n",
        "with open('%s_p%s_q%srelief_cluster.json'%(DATASET, p, q), 'r') as fp:\n",
        "  chi_cluster=json.load(fp)\n",
        "\n",
        "\n",
        "with open('%s_p%s_q%schi_cluster.json'%(DATASET, p, q), 'r') as fp:\n",
        "  relief_cluster=json.load(fp)\n",
        "\n",
        "with open('%s_p%s_q%spc_cluster.json'%(DATASET, p, q), 'r') as fp:\n",
        "  pc_cluster=json.load(fp)\n",
        "\n",
        "with open('%s_p%s_q%sfs_cluster.json'%(DATASET, p, q), 'r') as fp:\n",
        "  fs_cluster=json.load(fp)\n",
        "\n",
        "with open('%s_p%s_q%stt_cluster.json'%(DATASET, p, q), 'r') as fp:\n",
        "  tt_cluster=json.load(fp)\n",
        "\n",
        "with open('%s_p%s_q%ssnr_cluster.json'%(DATASET, p, q), 'r') as fp:\n",
        "  snr_cluster=json.load(fp)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfmCMag6fhUM"
      },
      "source": [
        "\"\"\"\n",
        "Loading Representative Genes from Memory\n",
        "\"\"\"\n",
        "gene_repre_1 = pd.read_csv(\"%s_p%s_q%sRepresentative_Genes_1.csv\"%(DATASET, p, q),index_col = None)\n",
        "gene_repre_2 = pd.read_csv(\"%s_p%s_q%sRepresentative_Genes_2.csv\"%(DATASET, p, q),index_col = None)\n",
        "gene_repre_3 = pd.read_csv(\"%s_p%s_q%sRepresentative_Genes_3.csv\"%(DATASET, p, q),index_col = None)\n",
        "gene_repre_4 = pd.read_csv(\"%s_p%s_q%sRepresentative_Genes_4.csv\"%(DATASET, p, q),index_col = None)\n",
        "gene_repre_5 = pd.read_csv(\"%s_p%s_q%sRepresentative_Genes_5.csv\"%(DATASET, p, q),index_col = None)\n",
        "gene_repre_6 = pd.read_csv(\"%s_p%s_q%sRepresentative_Genes_6.csv\"%(DATASET, p, q),index_col = None)\n",
        "gene_repre_7 = pd.read_csv(\"%s_p%s_q%sRepresentative_Genes_7.csv\"%(DATASET, p, q),index_col = None)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6JttvAePkb6",
        "outputId": "2276ddfd-0631-428b-fdd8-80fa64a03bda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "#Can Skip this cell\n",
        "print(gene_repre_1.shape)\n",
        "print(gene_repre_2.shape)\n",
        "print(gene_repre_3.shape)\n",
        "print(gene_repre_4.shape)\n",
        "print(gene_repre_5.head())\n",
        "print(gene_repre_6.head())\n",
        "print(gene_repre_7.head())"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(72, 50)\n",
            "(72, 7)\n",
            "(72, 21)\n",
            "(72, 6)\n",
            "      4787    1822     6743     1983     2126    6285\n",
            "0 -10105.0  -178.0 -36011.0  -9359.0  24738.0  5642.0\n",
            "1 -10565.0  1788.0 -33324.0  18524.0  39818.0  4858.0\n",
            "2 -11940.0  3021.0 -49194.0   3105.0  37881.0  -398.0\n",
            "3 -13170.0  3431.0 -38118.0   -218.0  23339.0  -121.0\n",
            "4 -10161.0  2072.0 -31341.0   9250.0  27976.0   687.0\n",
            "     4787     1822     6125     6907     2188     6149    6945\n",
            "0  1000.0  16183.0   9010.0  55364.0  19677.0  29982.0   783.0\n",
            "1   914.0  15363.0  18909.0  54113.0  33295.0  35320.0  4514.0\n",
            "2  -466.0  13833.0  14862.0  44653.0  25203.0  27204.0   401.0\n",
            "3  -560.0  12355.0  13337.0  46064.0  11296.0  24707.0   395.0\n",
            "4   609.0  14253.0  11874.0  51216.0   9510.0  27443.0  1393.0\n",
            "     4787    1822     1614     6737     5916     3301     1053\n",
            "0  3412.0  8236.0  49301.0  21955.0  67450.0  33592.0   7693.0\n",
            "1  5425.0  6058.0  58357.0  25545.0  82825.0  35900.0   8757.0\n",
            "2  3268.0  6631.0  54494.0  18467.0  69772.0  28581.0    541.0\n",
            "3  2095.0  5143.0  56350.0  22707.0  73721.0  25053.0  11863.0\n",
            "4  4025.0  5353.0  60503.0  26480.0  78706.0  29113.0  16854.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unmgoPcqGrdZ",
        "outputId": "7a5934bc-26be-43a5-be95-71d757fc4529",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "print(\"Number of MI Clusters formed -\",len(mi_cluster))\n",
        "print(\"Number of ReliefF Clusters formed -\",len(relief_cluster))\n",
        "print(\"Number of ChiSq. Clusters formed -\",len(chi_cluster))\n",
        "print(\"Number of Pearson Clusters formed -\",len(pc_cluster))\n",
        "print(\"Number of Fisher Score Clusters formed -\",len(fs_cluster))\n",
        "print(\"Number of T-Test Clusters formed -\",len(tt_cluster))\n",
        "print(\"Number of SNR Clusters formed -\", len(snr_cluster))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of MI Clusters formed - 50\n",
            "Number of ReliefF Clusters formed - 21\n",
            "Number of ChiSq. Clusters formed - 7\n",
            "Number of Pearson Clusters formed - 6\n",
            "Number of Fisher Score Clusters formed - 6\n",
            "Number of T-Test Clusters formed - 7\n",
            "Number of SNR Clusters formed - 7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLC-totaX3q8"
      },
      "source": [
        "def sort_keys(scores,gene_repre,target,flag=True):\n",
        "  score_dict={}\n",
        "  x=0\n",
        "  for i in gene_repre.columns:\n",
        "    # print(x)\n",
        "    score_dict[i]=scores[x]\n",
        "    x+=1\n",
        "  return [k for k, v in sorted(score_dict.items(), key=lambda item: item[1], reverse = True)]"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YoGkKYQbSZWA",
        "outputId": "e281fb4a-3037-4c98-ed39-855c3ba11ac4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "\"\"\"\n",
        "feature_ranking cannot be used here because it sorts and returns the indices from 0-1\n",
        "They need to be sorted using a different function\n",
        "\"\"\"\n",
        "sorted_mi_keys=sort_keys(mutual_info_wrapper(gene_repre_1,target),gene_repre_1,target,True)[:q]\n",
        "\n",
        "sorted_relief_keys=sort_keys(reliefF(gene_repre_2,target,k=NEIGHBOURS,repetitions=5),gene_repre_2,target,True)[:q]\n",
        "\n",
        "mms=MinMaxScaler()\n",
        "nfeature=mms.fit_transform(gene_repre_3)\n",
        "chi_score,p_val=chi2(nfeature,target)\n",
        "sorted_chi_keys=sort_keys(chi_score,gene_repre_3,target,False)[:q]\n",
        "\n",
        "sorted_pc_keys=sort_keys(pearson_corr(gene_repre_4,target),gene_repre_4,target,True)[:q]\n",
        "\n",
        "sorted_fs_keys=sort_keys(fisher_score(gene_repre_5.values,target),gene_repre_5,target,True)[:q]\n",
        "\n",
        "sorted_tt_keys=sort_keys(t_test(gene_repre_6,target),gene_repre_6,target,True)[:q]\n",
        "\n",
        "sorted_snr_keys = sort_keys(signaltonoise(gene_repre_7, target), gene_repre_7, target, True)[:q]"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/skfeature/utility/construct_W.py:194: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
            "  class_idx_all = (class_idx[:, np.newaxis] & class_idx[np.newaxis, :])\n",
            "/usr/local/lib/python3.6/dist-packages/skfeature/utility/construct_W.py:194: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
            "  class_idx_all = (class_idx[:, np.newaxis] & class_idx[np.newaxis, :])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FlViCrKzCuax",
        "outputId": "252b153c-bc5e-4004-c1b8-d2e71b751f5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "print(\"MI cluster after sorting - \",sorted_mi_keys)\n",
        "print(\"Relief cluster after sorting - \",sorted_relief_keys)\n",
        "print(\"Chi cluster after sorting - \",sorted_chi_keys)\n",
        "print(\"Pearson cluster after sorting - \",sorted_pc_keys)\n",
        "print(\"Fisher cluster after sorting - \",sorted_fs_keys)\n",
        "print(\"T-Test cluster after sorting - \",sorted_tt_keys)\n",
        "print(\"SNR cluster after sorting - \",sorted_snr_keys)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MI cluster after sorting -  ['2061', '4979', '1827', '2566', '3192']\n",
            "Relief cluster after sorting -  ['2729', '6780', '6158', '4664', '215']\n",
            "Chi cluster after sorting -  ['2228', '1822', '6746', '4313', '5916']\n",
            "Pearson cluster after sorting -  ['4787', '1822', '6743', '1983', '2126']\n",
            "Fisher cluster after sorting -  ['4787', '1822', '6743', '1983', '2126']\n",
            "T-Test cluster after sorting -  ['4787', '1822', '6125', '6907', '2188']\n",
            "SNR cluster after sorting -  ['4787', '1822', '1614', '6737', '5916']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "To00JAH2Hfh6"
      },
      "source": [
        "## Testing Classification of the Augmented Genes.\n",
        "Here the classfication accuracy is tested using **KNN, Decision Tree, Naive Bayes** and **SVM** as well as the **Ensemble** of them.\\\n",
        "\\\n",
        "Top i (where i ranges from 1 to q) are chosen from each augmented dataset of filters and a new dataset is created using these augmented genes. This dataset is used for classification."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3QaPc-XqNSj"
      },
      "source": [
        ""
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqtp-7IbCWNk"
      },
      "source": [
        "LOOCV=LeaveOneOut()\n",
        "data_KNN = KNeighborsClassifier(n_neighbors= int(feature.shape[0] ** 0.5))\n",
        "data_SVM = SVC(kernel='rbf',gamma='scale')\n",
        "data_NB = GaussianNB()\n",
        "data_Tree = DecisionTreeClassifier()\n",
        "rows = feature.shape[0]\n",
        "\n",
        "classifiers=[\"NB\",\"KNN\",\"Tree\",\"SVM\"]\n",
        "classifier_dict = { \"NB\": GaussianNB(), \n",
        "                   \"KNN\": KNeighborsClassifier(n_neighbors= int(feature.shape[0] ** 0.5)), \n",
        "                   \"Tree\": DecisionTreeClassifier(), \n",
        "                   \"SVM\": SVC(kernel='rbf',gamma='scale')}\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "keys_list={\"MI\":sorted_mi_keys, \"ReliefF\":sorted_relief_keys, \n",
        "           \"Chi\":sorted_chi_keys,  \n",
        "           \"Fisher\":sorted_fs_keys, \"Pearson\":sorted_pc_keys, \"tTest\":sorted_tt_keys, \n",
        "           \"SNR\":sorted_snr_keys}\n",
        "\"\"\"\n",
        "   \n",
        "\"\"\"\n",
        "cluster_list={\"MI\":gene_repre_1, \"ReliefF\":gene_repre_2,\n",
        "              \"Chi\":gene_repre_3, \"Pearson\":gene_repre_4, \n",
        "              \"Fisher\":gene_repre_5,\"tTest\":gene_repre_6, \n",
        "              \"SNR\":gene_repre_7}"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYBLMbUOkc_n"
      },
      "source": [
        "## MFSGC-EC"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69xHGbuKQzOY"
      },
      "source": [
        "## LOOCV\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_mRSWxQQPqD",
        "outputId": "6332aa8f-70dc-41f4-e5ac-544a74c35776",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "acc_df = []\n",
        "for i in range(1, q+1):  \n",
        "  #Ensemble of same type classifiers for each filter\n",
        "\n",
        "  #records the ensemble classifier accuracy of each classifier with i genes\n",
        "  classifier_accuracy = [] \n",
        "\n",
        "  for each_classifier in classifier_dict:\n",
        "    #creating confusion matrix.\n",
        "    confusion_matrix = np.zeros(classes.shape[0]*2).reshape(2,2)\n",
        "    #records the accuracy of the current classifier\n",
        "    acc=0\n",
        "    for train_index, test_index in LOOCV.split(range(rows)):\n",
        "      \"\"\"\n",
        "      Data is divided into train-test splits and then polling method is used \n",
        "      to find the classification results (ensemble of KNN,SVM,NB,Decision Tree)\n",
        "      \"\"\"\n",
        "      \n",
        "      filter_result = []\n",
        "      for filter_name in keys_list:\n",
        "\n",
        "        #taking the train-test split from each filter\n",
        "        train_data,train_labels = cluster_list[filter_name].iloc[train_index,:i],target[train_index]\n",
        "        test_data,test_labels = cluster_list[filter_name].iloc[test_index,:i],target[test_index].values.tolist()[0]\n",
        "\n",
        "        #filter wise fit and predict from the same type of classifier\n",
        "        classifier_dict[each_classifier].fit(train_data, train_labels)\n",
        "        filter_result.append(classifier_dict[each_classifier].predict(test_data)[0])\n",
        "\n",
        "      #generating the polling result of all filters' classifiers\n",
        "      polling_result = None\n",
        "      max_freq = 0\n",
        "      for each in set(filter_result):\n",
        "        freq = filter_result.count(each)\n",
        "        if freq>max_freq:\n",
        "          max_freq = freq\n",
        "          polling_result = each\n",
        "      # print(polling_result, test_labels)\n",
        "      confusion_matrix[test_labels, polling_result] += 1\n",
        "      if polling_result == test_labels:\n",
        "        acc+=1\n",
        "    \n",
        "    acc = np.round(acc/rows,4)\n",
        "    classifier_accuracy.append(acc)\n",
        "    # print(\"Confusion Matrix for %s with %s genes:-\\n\"%(each_classifier, i), confusion_matrix)\n",
        "    pd.DataFrame(confusion_matrix, index = classes, columns = classes).to_csv(\"LOOCV_confusion_matrix_%s_%s_%s.csv\"%(DATASET, each_classifier, i))\n",
        "\n",
        "  #records the ensemble classifier accuracy from 1 to q genes for each classifier\n",
        "  acc_df.append(classifier_accuracy)    \n",
        "acc_df = pd.DataFrame(acc_df, columns= classifier_dict.keys())\n",
        "acc_df.to_csv(\"Train-EC-Multi-SGC-%s_p%s_q%s_Accuracy_Matrix.csv\"%(DATASET, p, q))\n",
        "print(acc_df)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    NB     KNN    Tree  SVM\n",
            "0  1.0  1.0000  1.0000  1.0\n",
            "1  1.0  1.0000  1.0000  1.0\n",
            "2  1.0  1.0000  1.0000  1.0\n",
            "3  1.0  0.9861  1.0000  1.0\n",
            "4  1.0  0.9722  0.9861  1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UcFCr4xoULtw"
      },
      "source": [
        "## 5 Fold Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vAfQKCQUTpY"
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "\n",
        "kfcv = KFold(5, True, random_state = 0)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLRWid7KUKqI",
        "outputId": "753271ad-ecba-4697-f0c1-b7e47614724a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "acc_df = []\n",
        "for i in range(1, q+1):  \n",
        "  #Ensemble of same type classifiers for each filter\n",
        "\n",
        "  #records the ensemble classifier accuracy of each classifier with i genes\n",
        "  classifier_accuracy = [] \n",
        "\n",
        "  for each_classifier in classifier_dict:\n",
        "    #creating confusion matrix.\n",
        "    confusion_matrix = np.zeros(classes.shape[0]*2).reshape(2,2)\n",
        "    #records the accuracy of the current classifier\n",
        "    acc=0\n",
        "    for train_index, test_index in kfcv.split(range(rows)):\n",
        "      \"\"\"\n",
        "      Data is divided into train-test splits and then polling method is used \n",
        "      to find the classification results (ensemble of KNN,SVM,NB,Decision Tree)\n",
        "      \"\"\"\n",
        "      \n",
        "      filter_result = np.zeros((len(keys_list), len(test_index)))\n",
        "      # print(filter_result)\n",
        "      for idx1, filter_name in enumerate(keys_list):\n",
        "\n",
        "        #taking the train-test split from each filter\n",
        "        train_data,train_labels = cluster_list[filter_name].iloc[train_index,:i],target[train_index]\n",
        "        test_data,test_labels = cluster_list[filter_name].iloc[test_index,:i].values,target[test_index].values\n",
        "        # print(\"Test Label\",test_labels)\n",
        "        #filter wise fit and predict from the same type of classifier\n",
        "        classifier_dict[each_classifier].fit(train_data, train_labels)\n",
        "        for idx2, tst_data in enumerate(test_data):\n",
        "          # print(idx2,tst_data)\n",
        "          filter_result[idx1, idx2] = classifier_dict[each_classifier].predict(tst_data.reshape(1,-1))[0]\n",
        "\n",
        "      #generating the polling result of all filters' classifiers\n",
        "      for each_col in range(filter_result.shape[1]):\n",
        "\n",
        "        polling_result = None\n",
        "        max_freq = 0\n",
        "        data_col = filter_result[:,each_col]\n",
        "        for each in set(data_col):\n",
        "          freq = data_col.tolist().count(each)\n",
        "          if freq>max_freq:\n",
        "            max_freq = freq\n",
        "            polling_result = each\n",
        "        # print(polling_result)\n",
        "        confusion_matrix[test_labels[each_col], int(polling_result)] += 1\n",
        "        if polling_result == test_labels[each_col]:\n",
        "          acc+=1\n",
        "    \n",
        "    acc = np.round(acc/rows,4)\n",
        "    classifier_accuracy.append(acc)\n",
        "    # print(\"Confusion Matrix for %s with %s genes:-\\n\"%(each_classifier, i), confusion_matrix)\n",
        "    pd.DataFrame(confusion_matrix, index = classes, columns = classes).to_csv(\"5-Fold-CV_confusion_matrix_%s_%s_%s.csv\"%(DATASET, each_classifier, i))\n",
        "\n",
        "  #records the ensemble classifier accuracy from 1 to q genes for each classifier\n",
        "  acc_df.append(classifier_accuracy)    \n",
        "acc_df = pd.DataFrame(acc_df, columns= classifier_dict.keys())\n",
        "acc_df.to_csv(\"Train-EC-Multi-SGC-%s_p%s_q%s_Accuracy_Matrix.csv\"%(DATASET, p, q))\n",
        "print(acc_df)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    NB     KNN    Tree  SVM\n",
            "0  1.0  1.0000  1.0000  1.0\n",
            "1  1.0  1.0000  1.0000  1.0\n",
            "2  1.0  1.0000  0.9861  1.0\n",
            "3  1.0  0.9861  1.0000  1.0\n",
            "4  1.0  0.9722  1.0000  1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HlDNFl95iVSG"
      },
      "source": [
        "## Copying Confusion Matrix to Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ksurmixr74v"
      },
      "source": [
        "!cp LOOCV_confusion_matrix*.* \"/content/drive/My Drive/For Sir and Ma'am/MFSGC Results/Confusion Matrix/LOOCV/\"\n",
        "!cp 5-Fold-CV_confusion_matrix*.* \"/content/drive/My Drive/For Sir and Ma'am/MFSGC Results/Confusion Matrix/5-Fold/\""
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1O3y0q_fkU24"
      },
      "source": [
        "## Downloading the Files\n",
        "Downloads all the Files generated for this dataset. Please note: The dataset name must be specified in the DATASET \n",
        "variable before proceeding with the steps below.\n",
        "\n",
        "Incase of 'failed to fetch' error, please rerun these cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7OZl3asfnx2"
      },
      "source": [
        "#Download the MFSGC and MFSGC-EC Results\n",
        "files.download(\"Train-Multi-SGC-%s_p%s_q%s_Accuracy_Matrix.csv\"%(DATASET, p, q))\n",
        "files.download(\"Train-EC-Multi-SGC-%s_p%s_q%s_Accuracy_Matrix.csv\"%(DATASET, p, q))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ak6twT5NG3A4"
      },
      "source": [
        "#Downloading the Cluster Formation Sequence\n",
        "for x in ['mi','chi','relief', 'pc', 'fs', 'tt', 'snr']:\n",
        "  files.download(\"%s_p%s_q%s%s_cluster.json\"%(DATASET, p, q, x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2XKtNshS_iS"
      },
      "source": [
        "#Download Representative Genes Formed\n",
        "for x in range(1,8):\n",
        "  files.download(\"%s_p%s_q%sRepresentative_Genes_%d.csv\"%(DATASET, p, q, x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-j7hyxWTo6o"
      },
      "source": [
        "#*****************-----Notebook Training Code Ends Here. Below are cells for loading pre-calculated values for Representative Genes and Cluster Sequences.-------*****************************"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzDPRjeJWJ-0"
      },
      "source": [
        "#Cell Left Empty Intentionally."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91VP3IJ_F6Hv"
      },
      "source": [
        "## Loading Gene Representatives and Clusters\n",
        "The below cells can be run to load gene representatives and clusters if you already have them prepared."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76pXgWiqP7Uo"
      },
      "source": [
        "\"\"\"\n",
        "Loading the Cluster JSON files from memory\n",
        "\"\"\"\n",
        "\n",
        "with open('%s_p%s_q%smi_cluster.json'%(DATASET, p, q), 'r') as fp:\n",
        "  mi_cluster=json.load(fp)\n",
        "\n",
        "with open('%s_p%s_q%srelief_cluster.json'%(DATASET, p, q), 'r') as fp:\n",
        "  chi_cluster=json.load(fp)\n",
        "\n",
        "\n",
        "with open('%s_p%s_q%schi_cluster.json'%(DATASET, p, q), 'r') as fp:\n",
        "  relief_cluster=json.load(fp)\n",
        "\n",
        "with open('%s_p%s_q%spc_cluster.json'%(DATASET, p, q), 'r') as fp:\n",
        "  pc_cluster=json.load(fp)\n",
        "\n",
        "with open('%s_p%s_q%sfs_cluster.json'%(DATASET, p, q), 'r') as fp:\n",
        "  fs_cluster=json.load(fp)\n",
        "\n",
        "with open('%s_p%s_q%stt_cluster.json'%(DATASET, p, q), 'r') as fp:\n",
        "  tt_cluster=json.load(fp)\n",
        "\n",
        "with open('%s_p%s_q%ssnr_cluster.json'%(DATASET, p, q), 'r') as fp:\n",
        "  snr_cluster=json.load(fp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qd9hWyXQbXV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
